{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /Users/arthurj/.pyenv/versions/3.11.9/lib/python3.11/site-packages (1.6.0)\n",
      "Requirement already satisfied: load_dotenv in /Users/arthurj/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.1.0)\n",
      "Requirement already satisfied: python-dotenv in /Users/arthurj/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from load_dotenv) (1.0.1)\n",
      "\u001b[33mDEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nest_asyncio load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/arthurj/Git_Repos/LightRAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import pdfplumber\n",
    "import nest_asyncio\n",
    "from bs4 import BeautifulSoup\n",
    "from load_dotenv import load_dotenv\n",
    "from dataclasses import asdict, dataclass\n",
    "from lightrag.lightrag import LightRAG, QueryParam\n",
    "from lightrag.llm import gpt_4o_mini_complete, gpt_4o_complete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enviroment setup\n",
    "\n",
    "WORKING_DIR = \"/Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory\"\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)\n",
    "\n",
    "dotenv_path = '/Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/.env'\n",
    "load_dotenv(dotenv_path)\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Logger initialized for working directory: /Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory\n",
      "INFO:lightrag:Load KV llm_response_cache with 0 data\n",
      "INFO:lightrag:Load KV full_docs with 0 data\n",
      "INFO:lightrag:Load KV text_chunks with 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '/Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '/Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 1536, 'metric': 'cosine', 'storage_file': '/Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory/vdb_chunks.json'} 0 data\n"
     ]
    }
   ],
   "source": [
    "# model using 4o, text-embedding-3-small & moodys specific prompt to match banking inputs \n",
    "\n",
    "rag = LightRAG(\n",
    "    working_dir=WORKING_DIR,\n",
    "    llm_model_func=gpt_4o_complete\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up ingesiton method for SnP data\n",
    "\n",
    "def process_files_in_folder(folder_path):\n",
    "\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        folder = os.path.basename(folder_path)\n",
    "        rag.logger.info(f\"Processing folder: {folder}\")\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        if os.path.isfile(file_path) and filename.endswith('.txt') or filename.endswith('.html'):\n",
    "           \n",
    "            rag.set_current_file_info(folder, filename)\n",
    "\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "\n",
    "                if filename.endswith('.html'):\n",
    "                    soup = BeautifulSoup(content, 'html.parser')\n",
    "                    content = soup.get_text()\n",
    "\n",
    "                rag.insert(content)\n",
    "\n",
    "            print(f\"Processed: {filename}\")\n",
    "            rag.logger.info(f\"Processed: {filename}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/MERCK & CO., INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/MERCK & CO., INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/MERCK & CO., INC..txt. Total tokens used: 0\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.44batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1436, Output: 1436, Total: 2872\n",
      "INFO:lightrag:Processing file: Ratings/MERCK & CO., INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 616, Total: 6587\n",
      "INFO:lightrag:Processing file: Ratings/MERCK & CO., INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2862, Output: 660, Total: 10109\n",
      "INFO:lightrag:Processing file: Ratings/MERCK & CO., INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3742, Output: 303, Total: 14154\n",
      "INFO:lightrag:Processing file: Ratings/MERCK & CO., INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3549, Output: 304, Total: 18007\n",
      "INFO:lightrag:Processing file: Ratings/MERCK & CO., INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.57s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 19/19 [00:00<00:00, 5097.66entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 4514.25relationship/s]\n",
      "INFO:lightrag:Inserting 19 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.73s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.08batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/MERCK & CO., INC..txt. Total tokens used: 18007\n",
      "INFO:lightrag:Writing graph with 19 nodes, 8 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 18007\n",
      "INFO:lightrag:Processed: MERCK & CO., INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ELI LILLY AND COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/ELI LILLY AND COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ELI LILLY AND COMPANY.txt. Total tokens used: 18007\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: MERCK & CO., INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1521, Output: 1521, Total: 21049\n",
      "INFO:lightrag:Processing file: Ratings/ELI LILLY AND COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2984, Output: 395, Total: 24428\n",
      "INFO:lightrag:Processing file: Ratings/ELI LILLY AND COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 835, Total: 28362\n",
      "INFO:lightrag:Processing file: Ratings/ELI LILLY AND COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3406, Output: 431, Total: 32199\n",
      "INFO:lightrag:Processing file: Ratings/ELI LILLY AND COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3961, Output: 661, Total: 36821\n",
      "INFO:lightrag:Processing file: Ratings/ELI LILLY AND COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 32 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:21<00:00, 10.91s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 24/24 [00:00<00:00, 2680.99entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 7812.24relationship/s]\n",
      "INFO:lightrag:Inserting 24 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.40s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.10s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/ELI LILLY AND COMPANY.txt. Total tokens used: 36821\n",
      "INFO:lightrag:Writing graph with 44 nodes, 17 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 36821\n",
      "INFO:lightrag:Processed: ELI LILLY AND COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:lightrag:Inserting content from Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/TEXAS INSTRUMENTS INCORPORATED.txt. Total tokens used: 36821\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ELI LILLY AND COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1992, Output: 1992, Total: 40805\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2285, Output: 151, Total: 43241\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 179, Total: 46518\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 398, Total: 50015\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3524, Output: 456, Total: 53995\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 14 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:11<00:22, 11.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2463, Output: 788, Total: 57246\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 25 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:11<00:04,  4.99s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3304, Output: 878, Total: 61428\n",
      "INFO:lightrag:Processing file: Ratings/TEXAS INSTRUMENTS INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 35 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:13<00:00,  4.62s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 29/29 [00:00<00:00, 1842.56entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 20/20 [00:00<00:00, 2034.19relationship/s]\n",
      "INFO:lightrag:Inserting 29 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.88s/batch]\n",
      "INFO:lightrag:Inserting 20 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/TEXAS INSTRUMENTS INCORPORATED.txt. Total tokens used: 61428\n",
      "INFO:lightrag:Writing graph with 72 nodes, 37 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 61428\n",
      "INFO:lightrag:Processed: TEXAS INSTRUMENTS INCORPORATED.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/TESLA, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/TESLA, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/TESLA, INC..txt. Total tokens used: 61428\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: TEXAS INSTRUMENTS INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1484, Output: 1484, Total: 64396\n",
      "INFO:lightrag:Processing file: Ratings/TESLA, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 265, Total: 67760\n",
      "INFO:lightrag:Processing file: Ratings/TESLA, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3391, Output: 538, Total: 71689\n",
      "INFO:lightrag:Processing file: Ratings/TESLA, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2714, Output: 405, Total: 74808\n",
      "INFO:lightrag:Processing file: Ratings/TESLA, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3146, Output: 631, Total: 78585\n",
      "INFO:lightrag:Processing file: Ratings/TESLA, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 25 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [04:13<00:00, 126.67s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 22/22 [00:00<00:00, 2150.52entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 12997.84relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.70s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/TESLA, INC..txt. Total tokens used: 78585\n",
      "INFO:lightrag:Writing graph with 91 nodes, 50 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 78585\n",
      "INFO:lightrag:Processed: TESLA, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/STARBUCKS CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/STARBUCKS CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/STARBUCKS CORPORATION.txt. Total tokens used: 78585\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: TESLA, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1576, Output: 1576, Total: 81737\n",
      "INFO:lightrag:Processing file: Ratings/STARBUCKS CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 346, Total: 85182\n",
      "INFO:lightrag:Processing file: Ratings/STARBUCKS CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2828, Output: 433, Total: 88443\n",
      "INFO:lightrag:Processing file: Ratings/STARBUCKS CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3288, Output: 611, Total: 92342\n",
      "INFO:lightrag:Processing file: Ratings/STARBUCKS CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 14 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:19<00:19, 19.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3472, Output: 930, Total: 96744\n",
      "INFO:lightrag:Processing file: Ratings/STARBUCKS CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 28 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:21<00:00, 10.95s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 22/22 [00:00<00:00, 3322.70entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 21/21 [00:00<00:00, 7516.03relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:04<00:00,  4.44s/batch]\n",
      "INFO:lightrag:Inserting 21 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/STARBUCKS CORPORATION.txt. Total tokens used: 96744\n",
      "INFO:lightrag:Writing graph with 111 nodes, 71 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 96744\n",
      "INFO:lightrag:Processed: STARBUCKS CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE BOEING COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE BOEING COMPANY.txt. Total tokens used: 96744\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: STARBUCKS CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1882, Output: 1882, Total: 100508\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2182, Output: 293, Total: 102983\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 477, Total: 106558\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 610, Total: 110266\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2502, Output: 395, Total: 113163\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:11<00:23, 11.58s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3735, Output: 486, Total: 117384\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 25 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:17<00:08,  8.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3602, Output: 616, Total: 121602\n",
      "INFO:lightrag:Processing file: Ratings/THE BOEING COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 41 entities(duplicated), 18 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:17<00:00,  5.94s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 36/36 [00:00<00:00, 6827.41entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 16/16 [00:00<00:00, 9661.51relationship/s]\n",
      "INFO:lightrag:Inserting 36 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.21batch/s]\n",
      "INFO:lightrag:Inserting 16 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.10s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE BOEING COMPANY.txt. Total tokens used: 121602\n",
      "INFO:lightrag:Writing graph with 147 nodes, 87 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 121602\n",
      "INFO:lightrag:Processed: THE BOEING COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/COSTCO WHOLESALE CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/COSTCO WHOLESALE CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/COSTCO WHOLESALE CORPORATION.txt. Total tokens used: 121602\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE BOEING COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1296, Output: 1296, Total: 124194\n",
      "INFO:lightrag:Processing file: Ratings/COSTCO WHOLESALE CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2462, Output: 191, Total: 126847\n",
      "INFO:lightrag:Processing file: Ratings/COSTCO WHOLESALE CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2680, Output: 382, Total: 129909\n",
      "INFO:lightrag:Processing file: Ratings/COSTCO WHOLESALE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 6 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:09<00:09,  9.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 659, Total: 133667\n",
      "INFO:lightrag:Processing file: Ratings/COSTCO WHOLESALE CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3785, Output: 704, Total: 138156\n",
      "INFO:lightrag:Processing file: Ratings/COSTCO WHOLESALE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 22 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:20<00:00, 10.33s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 17/17 [00:00<00:00, 5594.16entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 8291.32relationship/s]\n",
      "INFO:lightrag:Inserting 17 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.09s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/COSTCO WHOLESALE CORPORATION.txt. Total tokens used: 138156\n",
      "INFO:lightrag:Writing graph with 163 nodes, 102 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 138156\n",
      "INFO:lightrag:Processed: COSTCO WHOLESALE CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/APPLE INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/APPLE INC..txt. Total tokens used: 138156\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: COSTCO WHOLESALE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.01batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 2492, Output: 2492, Total: 143140\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2664, Output: 204, Total: 146008\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 299, Total: 149406\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 386, Total: 152891\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3425, Output: 485, Total: 156801\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:11<00:23, 11.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 444, Total: 160757\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 26 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:13<00:05,  5.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2895, Output: 804, Total: 164456\n",
      "INFO:lightrag:Processing file: Ratings/APPLE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 38 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:15<00:00,  5.01s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 32/32 [00:00<00:00, 6606.18entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 12/12 [00:00<00:00, 12258.07relationship/s]\n",
      "INFO:lightrag:Inserting 32 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.75s/batch]\n",
      "INFO:lightrag:Inserting 12 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/APPLE INC..txt. Total tokens used: 164456\n",
      "INFO:lightrag:Writing graph with 191 nodes, 114 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 164456\n",
      "INFO:lightrag:Processed: APPLE INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ABBVIE INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/ABBVIE INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ABBVIE INC..txt. Total tokens used: 164456\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: APPLE INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.21batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1373, Output: 1373, Total: 167202\n",
      "INFO:lightrag:Processing file: Ratings/ABBVIE INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2646, Output: 320, Total: 170168\n",
      "INFO:lightrag:Processing file: Ratings/ABBVIE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2993, Output: 367, Total: 173528\n",
      "INFO:lightrag:Processing file: Ratings/ABBVIE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:10<00:10, 10.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 769, Total: 177396\n",
      "INFO:lightrag:Processing file: Ratings/ABBVIE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3895, Output: 1066, Total: 182357\n",
      "INFO:lightrag:Processing file: Ratings/ABBVIE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 26 entities(duplicated), 24 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:25<00:00, 12.86s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 20/20 [00:00<00:00, 5163.81entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 18/18 [00:00<00:00, 15477.14relationship/s]\n",
      "INFO:lightrag:Inserting 20 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/batch]\n",
      "INFO:lightrag:Inserting 18 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.34s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/ABBVIE INC..txt. Total tokens used: 182357\n",
      "INFO:lightrag:Writing graph with 209 nodes, 132 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 182357\n",
      "INFO:lightrag:Processed: ABBVIE INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/3M COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/3M COMPANY.txt. Total tokens used: 182357\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ABBVIE INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.26batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1919, Output: 1919, Total: 186195\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2066, Output: 176, Total: 188437\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 284, Total: 191820\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 351, Total: 195270\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2269, Output: 261, Total: 197800\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:07<00:14,  7.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3410, Output: 313, Total: 201523\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:09<00:04,  4.55s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3477, Output: 265, Total: 205265\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 27 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:10<00:00,  3.35s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/21 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 627, Output: 312, Total: 206204\n",
      "INFO:lightrag:Processing file: Ratings/3M COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 21/21 [00:07<00:00,  2.94entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 5/5 [00:00<00:00, 4026.02relationship/s]\n",
      "INFO:lightrag:Inserting 21 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Inserting 5 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.29s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/3M COMPANY.txt. Total tokens used: 206204\n",
      "INFO:lightrag:Writing graph with 227 nodes, 137 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 206204\n",
      "INFO:lightrag:Processed: 3M COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CONOCOPHILLIPS.txt\n",
      "INFO:lightrag:Inserting content from Ratings/CONOCOPHILLIPS.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CONOCOPHILLIPS.txt. Total tokens used: 206204\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 3M COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.27batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1296, Output: 1296, Total: 208796\n",
      "INFO:lightrag:Processing file: Ratings/CONOCOPHILLIPS.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2612, Output: 245, Total: 211653\n",
      "INFO:lightrag:Processing file: Ratings/CONOCOPHILLIPS.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2884, Output: 417, Total: 214954\n",
      "INFO:lightrag:Processing file: Ratings/CONOCOPHILLIPS.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:09<00:09,  9.25s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 995, Total: 219047\n",
      "INFO:lightrag:Processing file: Ratings/CONOCOPHILLIPS.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4120, Output: 577, Total: 223744\n",
      "INFO:lightrag:Processing file: Ratings/CONOCOPHILLIPS.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 30 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:21<00:00, 10.64s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 26/26 [00:00<00:00, 3339.72entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 11083.01relationship/s]\n",
      "INFO:lightrag:Inserting 26 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.44s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.14s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/CONOCOPHILLIPS.txt. Total tokens used: 223744\n",
      "INFO:lightrag:Writing graph with 249 nodes, 146 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 223744\n",
      "INFO:lightrag:Processed: CONOCOPHILLIPS.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN TOWER CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/AMERICAN TOWER CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/AMERICAN TOWER CORPORATION.txt. Total tokens used: 223744\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CONOCOPHILLIPS.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.28batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1660, Output: 1660, Total: 227064\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN TOWER CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 323, Total: 230486\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN TOWER CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2986, Output: 365, Total: 233837\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN TOWER CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3449, Output: 634, Total: 237920\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN TOWER CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:15<00:15, 15.12s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3378, Output: 609, Total: 241907\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN TOWER CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 20 entities(duplicated), 22 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.71s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 15/15 [00:00<00:00, 2026.49entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 6132.71relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.30s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.20s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/AMERICAN TOWER CORPORATION.txt. Total tokens used: 241907\n",
      "INFO:lightrag:Writing graph with 262 nodes, 159 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 241907\n",
      "INFO:lightrag:Processed: AMERICAN TOWER CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/VERIZON COMMUNICATIONS INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/VERIZON COMMUNICATIONS INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/VERIZON COMMUNICATIONS INC..txt. Total tokens used: 241907\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AMERICAN TOWER CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.49batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1641, Output: 1641, Total: 245189\n",
      "INFO:lightrag:Processing file: Ratings/VERIZON COMMUNICATIONS INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 432, Total: 248720\n",
      "INFO:lightrag:Processing file: Ratings/VERIZON COMMUNICATIONS INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2971, Output: 639, Total: 252330\n",
      "INFO:lightrag:Processing file: Ratings/VERIZON COMMUNICATIONS INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3637, Output: 433, Total: 256400\n",
      "INFO:lightrag:Processing file: Ratings/VERIZON COMMUNICATIONS INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 16 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:16<00:16, 17.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3558, Output: 669, Total: 260627\n",
      "INFO:lightrag:Processing file: Ratings/VERIZON COMMUNICATIONS INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:18<00:00,  9.35s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 22/22 [00:00<00:00, 2571.26entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 12715.52relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.27s/batch]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.15batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/VERIZON COMMUNICATIONS INC..txt. Total tokens used: 260627\n",
      "INFO:lightrag:Writing graph with 279 nodes, 173 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 260627\n",
      "INFO:lightrag:Processed: VERIZON COMMUNICATIONS INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/JOHNSON & JOHNSON.txt\n",
      "INFO:lightrag:Inserting content from Ratings/JOHNSON & JOHNSON.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/JOHNSON & JOHNSON.txt. Total tokens used: 260627\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: VERIZON COMMUNICATIONS INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1547, Output: 1547, Total: 263721\n",
      "INFO:lightrag:Processing file: Ratings/JOHNSON & JOHNSON.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2936, Output: 702, Total: 267359\n",
      "INFO:lightrag:Processing file: Ratings/JOHNSON & JOHNSON.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 569, Total: 271027\n",
      "INFO:lightrag:Processing file: Ratings/JOHNSON & JOHNSON.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3665, Output: 457, Total: 275149\n",
      "INFO:lightrag:Processing file: Ratings/JOHNSON & JOHNSON.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:18<00:18, 18.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3695, Output: 366, Total: 279210\n",
      "INFO:lightrag:Processing file: Ratings/JOHNSON & JOHNSON.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 23 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:19<00:00,  9.61s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 15/15 [00:00<00:00, 2235.13entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 11744.05relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/batch]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.23s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/JOHNSON & JOHNSON.txt. Total tokens used: 279210\n",
      "INFO:lightrag:Writing graph with 291 nodes, 187 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 279210\n",
      "INFO:lightrag:Processed: JOHNSON & JOHNSON.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/AMAZON.COM, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/AMAZON.COM, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/AMAZON.COM, INC..txt. Total tokens used: 279210\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: JOHNSON & JOHNSON.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.08batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1351, Output: 1351, Total: 281912\n",
      "INFO:lightrag:Processing file: Ratings/AMAZON.COM, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2587, Output: 222, Total: 284721\n",
      "INFO:lightrag:Processing file: Ratings/AMAZON.COM, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 490, Total: 288309\n",
      "INFO:lightrag:Processing file: Ratings/AMAZON.COM, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2836, Output: 640, Total: 291785\n",
      "INFO:lightrag:Processing file: Ratings/AMAZON.COM, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:11<00:11, 11.52s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3615, Output: 613, Total: 296013\n",
      "INFO:lightrag:Processing file: Ratings/AMAZON.COM, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 29 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:14<00:00,  7.23s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 23/23 [00:00<00:00, 3405.91entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 10/10 [00:00<00:00, 8718.15relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.10s/batch]\n",
      "INFO:lightrag:Inserting 10 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.43batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/AMAZON.COM, INC..txt. Total tokens used: 296013\n",
      "INFO:lightrag:Writing graph with 311 nodes, 197 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 296013\n",
      "INFO:lightrag:Processed: AMAZON.COM, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/QUALCOMM INCORPORATED.txt\n",
      "INFO:lightrag:Inserting content from Ratings/QUALCOMM INCORPORATED.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/QUALCOMM INCORPORATED.txt. Total tokens used: 296013\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AMAZON.COM, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.15batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1648, Output: 1648, Total: 299309\n",
      "INFO:lightrag:Processing file: Ratings/QUALCOMM INCORPORATED.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2953, Output: 117, Total: 302379\n",
      "INFO:lightrag:Processing file: Ratings/QUALCOMM INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 260, Total: 305737\n",
      "INFO:lightrag:Processing file: Ratings/QUALCOMM INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 156, Total: 308990\n",
      "INFO:lightrag:Processing file: Ratings/QUALCOMM INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 4 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:06<00:06,  6.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3385, Output: 476, Total: 312851\n",
      "INFO:lightrag:Processing file: Ratings/QUALCOMM INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 10 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:13<00:00,  6.88s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 9/9 [00:00<00:00, 1547.52entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 5/5 [00:00<00:00, 1582.40relationship/s]\n",
      "INFO:lightrag:Inserting 9 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.10s/batch]\n",
      "INFO:lightrag:Inserting 5 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.25s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/QUALCOMM INCORPORATED.txt. Total tokens used: 312851\n",
      "INFO:lightrag:Writing graph with 318 nodes, 202 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 312851\n",
      "INFO:lightrag:Processed: QUALCOMM INCORPORATED.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/BLACKROCK, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/BLACKROCK, INC..txt. Total tokens used: 312851\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: QUALCOMM INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1425, Output: 1425, Total: 315701\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2719, Output: 454, Total: 318874\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 537, Total: 322510\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3200, Output: 454, Total: 326164\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:16<00:16, 16.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3663, Output: 432, Total: 330259\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 13 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:16<00:00,  8.34s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/12 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 650, Output: 394, Total: 331303\n",
      "INFO:lightrag:Processing file: Ratings/BLACKROCK, INC..txt\n",
      "Inserting entities: 100%|██████████| 12/12 [00:08<00:00,  1.33entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 4650.00relationship/s]\n",
      "INFO:lightrag:Inserting 12 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.49s/batch]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.65s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/BLACKROCK, INC..txt. Total tokens used: 331303\n",
      "INFO:lightrag:Writing graph with 331 nodes, 216 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 331303\n",
      "INFO:lightrag:Processed: BLACKROCK, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CHARTER COMMUNICATIONS, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/CHARTER COMMUNICATIONS, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CHARTER COMMUNICATIONS, INC..txt. Total tokens used: 331303\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BLACKROCK, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.42batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1554, Output: 1554, Total: 334411\n",
      "INFO:lightrag:Processing file: Ratings/CHARTER COMMUNICATIONS, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2880, Output: 756, Total: 338047\n",
      "INFO:lightrag:Processing file: Ratings/CHARTER COMMUNICATIONS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 769, Total: 341914\n",
      "INFO:lightrag:Processing file: Ratings/CHARTER COMMUNICATIONS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3663, Output: 380, Total: 345957\n",
      "INFO:lightrag:Processing file: Ratings/CHARTER COMMUNICATIONS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 16 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:18<00:18, 18.35s/chunk]INFO:openai._base_client:Retrying request to /chat/completions in 0.425715 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3894, Output: 694, Total: 350545\n",
      "INFO:lightrag:Processing file: Ratings/CHARTER COMMUNICATIONS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 38 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [10:25<00:00, 312.80s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 33/33 [00:00<00:00, 4249.81entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 12/12 [00:00<00:00, 9091.70relationship/s]\n",
      "INFO:lightrag:Inserting 33 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.94batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.15batch/s]\n",
      "INFO:lightrag:Inserting 12 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.27s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/CHARTER COMMUNICATIONS, INC..txt. Total tokens used: 350545\n",
      "INFO:lightrag:Writing graph with 361 nodes, 228 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 350545\n",
      "INFO:lightrag:Processed: CHARTER COMMUNICATIONS, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt. Total tokens used: 350545\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CHARTER COMMUNICATIONS, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.33batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1306, Output: 1306, Total: 353157\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2521, Output: 378, Total: 356056\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 516, Total: 359671\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2926, Output: 312, Total: 362909\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:10<00:10, 10.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3642, Output: 308, Total: 366859\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:11<00:00,  5.86s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 15/15 [00:00<00:00, 4549.79entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 10/10 [00:00<00:00, 3632.38relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/batch]\n",
      "INFO:lightrag:Inserting 10 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.00s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/AMERICAN INTERNATIONAL GROUP, INC..txt. Total tokens used: 366859\n",
      "INFO:lightrag:Writing graph with 372 nodes, 238 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 366859\n",
      "INFO:lightrag:Processed: AMERICAN INTERNATIONAL GROUP, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE HOME DEPOT, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE HOME DEPOT, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE HOME DEPOT, INC..txt. Total tokens used: 366859\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AMERICAN INTERNATIONAL GROUP, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.07batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1653, Output: 1653, Total: 370165\n",
      "INFO:lightrag:Processing file: Ratings/THE HOME DEPOT, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 227, Total: 373491\n",
      "INFO:lightrag:Processing file: Ratings/THE HOME DEPOT, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2990, Output: 285, Total: 376766\n",
      "INFO:lightrag:Processing file: Ratings/THE HOME DEPOT, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3353, Output: 443, Total: 380562\n",
      "INFO:lightrag:Processing file: Ratings/THE HOME DEPOT, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:09<00:09,  9.94s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3302, Output: 449, Total: 384313\n",
      "INFO:lightrag:Processing file: Ratings/THE HOME DEPOT, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:11<00:00,  5.70s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 19/19 [00:00<00:00, 4321.21entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 5260.14relationship/s]\n",
      "INFO:lightrag:Inserting 19 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.44s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.20s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE HOME DEPOT, INC..txt. Total tokens used: 384313\n",
      "INFO:lightrag:Writing graph with 388 nodes, 246 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 384313\n",
      "INFO:lightrag:Processed: THE HOME DEPOT, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n",
      "INFO:lightrag:Inserting content from Ratings/JPMORGAN CHASE & CO..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/JPMORGAN CHASE & CO..txt. Total tokens used: 384313\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE HOME DEPOT, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.38batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1679, Output: 1679, Total: 387671\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2896, Output: 319, Total: 390886\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 478, Total: 394463\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3604, Output: 597, Total: 398664\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.89s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3242, Output: 753, Total: 402659\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.97s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/21 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 667, Output: 409, Total: 403735\n",
      "INFO:lightrag:Processing file: Ratings/JPMORGAN CHASE & CO..txt\n",
      "Inserting entities: 100%|██████████| 21/21 [00:08<00:00,  2.41entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 3569.62relationship/s]\n",
      "INFO:lightrag:Inserting 21 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.09batch/s]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.78s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/JPMORGAN CHASE & CO..txt. Total tokens used: 403735\n",
      "INFO:lightrag:Writing graph with 406 nodes, 259 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 403735\n",
      "INFO:lightrag:Processed: JPMORGAN CHASE & CO..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/CITIGROUP INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CITIGROUP INC..txt. Total tokens used: 403735\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: JPMORGAN CHASE & CO..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 2265, Output: 2265, Total: 408265\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 218, Total: 411582\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 516, Total: 415197\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2506, Output: 731, Total: 418434\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3344, Output: 680, Total: 422458\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:14<00:29, 14.71s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3264, Output: 346, Total: 426068\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 26 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:17<00:07,  7.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3642, Output: 543, Total: 430253\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 41 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:18<00:00,  6.09s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/28 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 693, Output: 431, Total: 431377\n",
      "INFO:lightrag:Processing file: Ratings/CITIGROUP INC..txt\n",
      "Inserting entities: 100%|██████████| 28/28 [00:12<00:00,  2.19entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 10640.04relationship/s]\n",
      "INFO:lightrag:Inserting 28 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.14s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.04batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/CITIGROUP INC..txt. Total tokens used: 431377\n",
      "INFO:lightrag:Writing graph with 431 nodes, 274 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 431377\n",
      "INFO:lightrag:Processed: CITIGROUP INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE GOLDMAN SACHS GROUP, INC..txt. Total tokens used: 431377\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CITIGROUP INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1671, Output: 1671, Total: 434719\n",
      "INFO:lightrag:Processing file: Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2856, Output: 552, Total: 438127\n",
      "INFO:lightrag:Processing file: Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3435, Output: 325, Total: 441887\n",
      "INFO:lightrag:Processing file: Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 4 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1038, Total: 446024\n",
      "INFO:lightrag:Processing file: Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4164, Output: 545, Total: 450733\n",
      "INFO:lightrag:Processing file: Ratings/THE GOLDMAN SACHS GROUP, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:28<00:00, 14.01s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 18/18 [00:00<00:00, 5782.15entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 18/18 [00:00<00:00, 13032.53relationship/s]\n",
      "INFO:lightrag:Inserting 18 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.92s/batch]\n",
      "INFO:lightrag:Inserting 18 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.08s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE GOLDMAN SACHS GROUP, INC..txt. Total tokens used: 450733\n",
      "INFO:lightrag:Writing graph with 447 nodes, 292 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 450733\n",
      "INFO:lightrag:Processed: THE GOLDMAN SACHS GROUP, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/MCDONALD'S CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/MCDONALD'S CORPORATION.txt. Total tokens used: 450733\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE GOLDMAN SACHS GROUP, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.48batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1553, Output: 1553, Total: 453839\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 313, Total: 457250\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2839, Output: 427, Total: 460516\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3438, Output: 354, Total: 464308\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3293, Output: 644, Total: 468245\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 23 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:18<00:00,  9.02s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/22 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 678, Output: 462, Total: 469385\n",
      "INFO:lightrag:Processing file: Ratings/MCDONALD'S CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 22/22 [00:09<00:00,  2.37entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 3/3 [00:00<00:00, 1616.30relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.38s/batch]\n",
      "INFO:lightrag:Inserting 3 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/MCDONALD'S CORPORATION.txt. Total tokens used: 469385\n",
      "INFO:lightrag:Writing graph with 463 nodes, 295 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 469385\n",
      "INFO:lightrag:Processed: MCDONALD'S CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n",
      "INFO:lightrag:Inserting content from Ratings/ABBOTT LABORATORIES.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ABBOTT LABORATORIES.txt. Total tokens used: 469385\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: MCDONALD'S CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.34batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1416, Output: 1416, Total: 472217\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2597, Output: 262, Total: 475076\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 342, Total: 478517\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2886, Output: 387, Total: 481790\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:11<00:11, 11.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3468, Output: 456, Total: 485714\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:14<00:00,  7.15s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/16 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 657, Output: 482, Total: 486853\n",
      "INFO:lightrag:Processing file: Ratings/ABBOTT LABORATORIES.txt\n",
      "Inserting entities: 100%|██████████| 16/16 [00:10<00:00,  1.59entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 6/6 [00:00<00:00, 3097.71relationship/s]\n",
      "INFO:lightrag:Inserting 16 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.57s/batch]\n",
      "INFO:lightrag:Inserting 6 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.45batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/ABBOTT LABORATORIES.txt. Total tokens used: 486853\n",
      "INFO:lightrag:Writing graph with 475 nodes, 301 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 486853\n",
      "INFO:lightrag:Processed: ABBOTT LABORATORIES.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/GENERAL MOTORS COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/GENERAL MOTORS COMPANY.txt. Total tokens used: 486853\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ABBOTT LABORATORIES.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1617, Output: 1617, Total: 490087\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 386, Total: 493572\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2930, Output: 457, Total: 496959\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 428, Total: 500899\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 14 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:17<00:17, 17.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3414, Output: 698, Total: 505011\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 29 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:19<00:00,  9.71s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/22 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 708, Output: 484, Total: 506203\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL MOTORS COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 22/22 [00:11<00:00,  1.89entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 6/6 [00:00<00:00, 4084.04relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.95s/batch]\n",
      "INFO:lightrag:Inserting 6 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/GENERAL MOTORS COMPANY.txt. Total tokens used: 506203\n",
      "INFO:lightrag:Writing graph with 491 nodes, 307 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 506203\n",
      "INFO:lightrag:Processed: GENERAL MOTORS COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/ORACLE CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ORACLE CORPORATION.txt. Total tokens used: 506203\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: GENERAL MOTORS COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1736, Output: 1736, Total: 509675\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1927, Output: 44, Total: 511646\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 129, Total: 514874\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3027, Output: 214, Total: 518115\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1998, Output: 105, Total: 520218\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 0 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:04<00:09,  4.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3255, Output: 335, Total: 523808\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 8 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:07<00:03,  3.71s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3268, Output: 326, Total: 527402\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 9 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:09<00:00,  3.06s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/8 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 667, Output: 496, Total: 528565\n",
      "INFO:lightrag:Processing file: Ratings/ORACLE CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 8/8 [00:14<00:00,  1.75s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 0relationship [00:00, ?relationship/s]\n",
      "WARNING:lightrag:Didn't extract any relationships\n",
      "INFO:lightrag:Inserting 8 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/batch]\n",
      "INFO:lightrag:Inserting 0 vectors to relationships\n",
      "WARNING:lightrag:You insert an empty data to vector DB\n",
      "INFO:lightrag:Finished processing Ratings/ORACLE CORPORATION.txt. Total tokens used: 528565\n",
      "INFO:lightrag:Writing graph with 498 nodes, 307 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 528565\n",
      "INFO:lightrag:Processed: ORACLE CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/DEERE & COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/DEERE & COMPANY.txt. Total tokens used: 528565\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ORACLE CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.64batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1709, Output: 1709, Total: 531983\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2998, Output: 194, Total: 535175\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 336, Total: 538609\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3219, Output: 527, Total: 542355\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.99s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3461, Output: 559, Total: 546375\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.69s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/15 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 702, Output: 388, Total: 547465\n",
      "INFO:lightrag:Processing file: Ratings/DEERE & COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 15/15 [00:08<00:00,  1.82entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 4265.88relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.66s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.01s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/DEERE & COMPANY.txt. Total tokens used: 547465\n",
      "INFO:lightrag:Writing graph with 510 nodes, 316 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 547465\n",
      "INFO:lightrag:Processed: DEERE & COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt. Total tokens used: 547465\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: DEERE & COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.08batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1900, Output: 1900, Total: 551265\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2106, Output: 163, Total: 553534\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 395, Total: 557028\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 390, Total: 560517\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2296, Output: 241, Total: 563054\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:14<00:28, 14.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3521, Output: 479, Total: 567054\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:24<00:11, 11.81s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3516, Output: 550, Total: 571120\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 24 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:26<00:00,  8.78s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/22 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 691, Output: 479, Total: 572290\n",
      "INFO:lightrag:Processing file: Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 22/22 [00:11<00:00,  1.90entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 7142.28relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.20s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.40s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/CAPITAL ONE FINANCIAL CORPORATION.txt. Total tokens used: 572290\n",
      "INFO:lightrag:Writing graph with 531 nodes, 324 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 572290\n",
      "INFO:lightrag:Processed: CAPITAL ONE FINANCIAL CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/PFIZER INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/PFIZER INC..txt. Total tokens used: 572290\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CAPITAL ONE FINANCIAL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.66batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1511, Output: 1511, Total: 575312\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 459, Total: 578870\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2868, Output: 507, Total: 582245\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3402, Output: 310, Total: 585957\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 14 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:17<00:17, 17.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3585, Output: 594, Total: 590136\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 26 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:21<00:00, 10.70s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/18 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 643, Output: 466, Total: 591245\n",
      "INFO:lightrag:Processing file: Ratings/PFIZER INC..txt\n",
      "Inserting entities: 100%|██████████| 18/18 [00:14<00:00,  1.24entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 6349.83relationship/s]\n",
      "INFO:lightrag:Inserting 18 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.43s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/PFIZER INC..txt. Total tokens used: 591245\n",
      "INFO:lightrag:Writing graph with 544 nodes, 337 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 591245\n",
      "INFO:lightrag:Processed: PFIZER INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/GILEAD SCIENCES, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/GILEAD SCIENCES, INC..txt. Total tokens used: 591245\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: PFIZER INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.29batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1448, Output: 1448, Total: 594141\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 197, Total: 597437\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2901, Output: 355, Total: 600693\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3283, Output: 370, Total: 604346\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 6 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3323, Output: 622, Total: 608291\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 14 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:14<00:00,  7.36s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/11 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 644, Output: 500, Total: 609435\n",
      "INFO:lightrag:Processing file: Ratings/GILEAD SCIENCES, INC..txt\n",
      "Inserting entities: 100%|██████████| 11/11 [00:14<00:00,  1.28s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 2156.82relationship/s]\n",
      "INFO:lightrag:Inserting 11 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.47s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.50s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/GILEAD SCIENCES, INC..txt. Total tokens used: 609435\n",
      "INFO:lightrag:Writing graph with 552 nodes, 346 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 609435\n",
      "INFO:lightrag:Processed: GILEAD SCIENCES, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE CHARLES SCHWAB CORPORATION.txt. Total tokens used: 609435\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: GILEAD SCIENCES, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.15batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 2214, Output: 2214, Total: 613863\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2552, Output: 187, Total: 616602\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 194, Total: 619895\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 498, Total: 623492\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3320, Output: 480, Total: 627292\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:12<00:25, 12.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2766, Output: 535, Total: 630593\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:13<00:05,  5.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3624, Output: 731, Total: 634948\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 41 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:21<00:00,  7.09s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/32 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 757, Output: 500, Total: 636205\n",
      "INFO:lightrag:Processing file: Ratings/THE CHARLES SCHWAB CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 32/32 [00:14<00:00,  2.25entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 5/5 [00:00<00:00, 4401.16relationship/s]\n",
      "INFO:lightrag:Inserting 32 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.49s/batch]\n",
      "INFO:lightrag:Inserting 5 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.08batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/THE CHARLES SCHWAB CORPORATION.txt. Total tokens used: 636205\n",
      "INFO:lightrag:Writing graph with 578 nodes, 351 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 636205\n",
      "INFO:lightrag:Processed: THE CHARLES SCHWAB CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt. Total tokens used: 636205\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE CHARLES SCHWAB CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 2417, Output: 2417, Total: 641039\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2908, Output: 170, Total: 644117\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 407, Total: 647623\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3105, Output: 522, Total: 651250\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 0 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:18<00:37, 18.71s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 996, Total: 655345\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3532, Output: 655, Total: 659532\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:24<00:11, 11.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4122, Output: 1007, Total: 664661\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 36 entities(duplicated), 23 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:39<00:00, 13.29s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/35 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 694, Output: 500, Total: 665855\n",
      "INFO:lightrag:Processing file: Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 35/35 [00:12<00:00,  2.88entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 23/23 [00:00<00:00, 9326.98relationship/s]\n",
      "INFO:lightrag:Inserting 35 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.03batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.14batch/s]\n",
      "INFO:lightrag:Inserting 23 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.08s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE BANK OF NEW YORK MELLON CORPORATION.txt. Total tokens used: 665855\n",
      "INFO:lightrag:Writing graph with 609 nodes, 374 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 665855\n",
      "INFO:lightrag:Processed: THE BANK OF NEW YORK MELLON CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/GENERAL DYNAMICS CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/GENERAL DYNAMICS CORPORATION.txt. Total tokens used: 665855\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE BANK OF NEW YORK MELLON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1410, Output: 1410, Total: 668675\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2656, Output: 208, Total: 671539\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 306, Total: 674944\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3432, Output: 457, Total: 678833\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:13<00:13, 13.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2891, Output: 875, Total: 682599\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:17<00:00,  8.81s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/23 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 688, Output: 500, Total: 683787\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL DYNAMICS CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 23/23 [00:11<00:00,  1.95entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 12/12 [00:00<00:00, 4044.33relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/batch]\n",
      "INFO:lightrag:Inserting 12 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.87s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/GENERAL DYNAMICS CORPORATION.txt. Total tokens used: 683787\n",
      "INFO:lightrag:Writing graph with 627 nodes, 386 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 683787\n",
      "INFO:lightrag:Processed: GENERAL DYNAMICS CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE SOUTHERN COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE SOUTHERN COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE SOUTHERN COMPANY.txt. Total tokens used: 683787\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: GENERAL DYNAMICS CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.16batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1420, Output: 1420, Total: 686627\n",
      "INFO:lightrag:Processing file: Ratings/THE SOUTHERN COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2566, Output: 589, Total: 689782\n",
      "INFO:lightrag:Processing file: Ratings/THE SOUTHERN COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 689, Total: 693570\n",
      "INFO:lightrag:Processing file: Ratings/THE SOUTHERN COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3182, Output: 141, Total: 696893\n",
      "INFO:lightrag:Processing file: Ratings/THE SOUTHERN COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3815, Output: 691, Total: 701399\n",
      "INFO:lightrag:Processing file: Ratings/THE SOUTHERN COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:21<00:00, 10.88s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 23/23 [00:00<00:00, 5768.99entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 20/20 [00:00<00:00, 11594.48relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.51s/batch]\n",
      "INFO:lightrag:Inserting 20 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.34s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE SOUTHERN COMPANY.txt. Total tokens used: 701399\n",
      "INFO:lightrag:Writing graph with 647 nodes, 406 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 701399\n",
      "INFO:lightrag:Processed: THE SOUTHERN COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/VISA INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/VISA INC..txt. Total tokens used: 701399\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE SOUTHERN COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.52s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1083, Output: 1083, Total: 703565\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2216, Output: 193, Total: 705974\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 498, Total: 709571\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2436, Output: 311, Total: 712318\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:08<00:08,  8.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3624, Output: 548, Total: 716490\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:16<00:00,  8.16s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/16 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 734, Output: 394, Total: 717618\n",
      "INFO:lightrag:Processing file: Ratings/VISA INC..txt\n",
      "Inserting entities: 100%|██████████| 16/16 [00:09<00:00,  1.77entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 5/5 [00:00<00:00, 3423.92relationship/s]\n",
      "INFO:lightrag:Inserting 16 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.22s/batch]\n",
      "INFO:lightrag:Inserting 5 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.04batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/VISA INC..txt. Total tokens used: 717618\n",
      "INFO:lightrag:Writing graph with 659 nodes, 411 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 717618\n",
      "INFO:lightrag:Processed: VISA INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/GENERAL ELECTRIC COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/GENERAL ELECTRIC COMPANY.txt. Total tokens used: 717618\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: VISA INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.23batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1317, Output: 1317, Total: 720252\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 312, Total: 723661\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2607, Output: 446, Total: 726714\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3080, Output: 317, Total: 730111\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3436, Output: 654, Total: 734201\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:14<00:00,  7.50s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/15 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 676, Output: 500, Total: 735377\n",
      "INFO:lightrag:Processing file: Ratings/GENERAL ELECTRIC COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 15/15 [00:14<00:00,  1.07entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 2992.64relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.09s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/GENERAL ELECTRIC COMPANY.txt. Total tokens used: 735377\n",
      "INFO:lightrag:Writing graph with 672 nodes, 424 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 735377\n",
      "INFO:lightrag:Processed: GENERAL ELECTRIC COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/PAYPAL HOLDINGS, INC..txt. Total tokens used: 735377\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: GENERAL ELECTRIC COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1816, Output: 1816, Total: 739009\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2016, Output: 156, Total: 741181\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 240, Total: 744519\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2199, Output: 199, Total: 746917\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:07<00:14,  7.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 427, Total: 750443\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3365, Output: 450, Total: 754258\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:12<00:05,  5.95s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3553, Output: 699, Total: 758510\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 25 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:19<00:00,  6.57s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/19 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 727, Output: 500, Total: 759737\n",
      "INFO:lightrag:Processing file: Ratings/PAYPAL HOLDINGS, INC..txt\n",
      "Inserting entities: 100%|██████████| 19/19 [00:10<00:00,  1.81entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 10/10 [00:00<00:00, 3269.14relationship/s]\n",
      "INFO:lightrag:Inserting 19 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.53s/batch]\n",
      "INFO:lightrag:Inserting 10 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.03batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/PAYPAL HOLDINGS, INC..txt. Total tokens used: 759737\n",
      "INFO:lightrag:Writing graph with 683 nodes, 434 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 759737\n",
      "INFO:lightrag:Processed: PAYPAL HOLDINGS, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/WELLS FARGO & COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/WELLS FARGO & COMPANY.txt. Total tokens used: 759737\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: PAYPAL HOLDINGS, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.14batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 2319, Output: 2319, Total: 764375\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2626, Output: 232, Total: 767233\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 413, Total: 770744\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 448, Total: 774291\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2885, Output: 377, Total: 777553\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:11<00:23, 11.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3538, Output: 387, Total: 781478\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:15<00:07,  7.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3574, Output: 667, Total: 785719\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 35 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:20<00:00,  6.77s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/30 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 669, Output: 500, Total: 786888\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "Inserting entities:  97%|█████████▋| 29/30 [00:10<00:00,  2.68entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 686, Output: 500, Total: 788074\n",
      "INFO:lightrag:Processing file: Ratings/WELLS FARGO & COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 30/30 [00:11<00:00,  2.64entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 4418.16relationship/s]\n",
      "INFO:lightrag:Inserting 30 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.61s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.08s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/WELLS FARGO & COMPANY.txt. Total tokens used: 788074\n",
      "INFO:lightrag:Writing graph with 703 nodes, 443 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 788074\n",
      "INFO:lightrag:Processed: WELLS FARGO & COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "INFO:lightrag:Inserting content from Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/UNITEDHEALTH GROUP INCORPORATED.txt. Total tokens used: 788074\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: WELLS FARGO & COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.16batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1540, Output: 1540, Total: 791154\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2994, Output: 437, Total: 794585\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 709, Total: 798393\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3458, Output: 380, Total: 802231\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.95s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3835, Output: 613, Total: 806679\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 22 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:20<00:00, 10.10s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/17 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 668, Output: 500, Total: 807847\n",
      "INFO:lightrag:Processing file: Ratings/UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "Inserting entities: 100%|██████████| 17/17 [00:17<00:00,  1.01s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 16/16 [00:00<00:00, 8425.47relationship/s]\n",
      "INFO:lightrag:Inserting 17 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/batch]\n",
      "INFO:lightrag:Inserting 16 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.50s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/UNITEDHEALTH GROUP INCORPORATED.txt. Total tokens used: 807847\n",
      "INFO:lightrag:Writing graph with 716 nodes, 459 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 807847\n",
      "INFO:lightrag:Processed: UNITEDHEALTH GROUP INCORPORATED.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/BANK OF AMERICA CORPORATION.txt. Total tokens used: 807847\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: UNITEDHEALTH GROUP INCORPORATED.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.62s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 2211, Output: 2211, Total: 812269\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2426, Output: 148, Total: 814843\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 172, Total: 818114\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 464, Total: 821677\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.413268 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2601, Output: 414, Total: 824692\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 5 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:10<00:21, 10.80s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3298, Output: 373, Total: 828363\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:16<00:07,  7.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3590, Output: 650, Total: 832603\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 32 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:19<00:00,  6.52s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/28 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 792, Output: 500, Total: 833895\n",
      "INFO:lightrag:Processing file: Ratings/BANK OF AMERICA CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 28/28 [00:11<00:00,  2.53entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 3123.42relationship/s]\n",
      "INFO:lightrag:Inserting 28 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.60s/batch]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/BANK OF AMERICA CORPORATION.txt. Total tokens used: 833895\n",
      "INFO:lightrag:Writing graph with 736 nodes, 466 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 833895\n",
      "INFO:lightrag:Processed: BANK OF AMERICA CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/INTEL CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/INTEL CORPORATION.txt. Total tokens used: 833895\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BANK OF AMERICA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.99s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1878, Output: 1878, Total: 837651\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2055, Output: 210, Total: 839916\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 218, Total: 843233\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 226, Total: 846558\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2292, Output: 250, Total: 849100\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:08<00:16,  8.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3352, Output: 535, Total: 852987\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:13<00:06,  6.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3344, Output: 850, Total: 857181\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 30 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:17<00:00,  5.90s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/25 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 721, Output: 485, Total: 858387\n",
      "INFO:lightrag:Processing file: Ratings/INTEL CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 25/25 [00:10<00:00,  2.45entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 2105.86relationship/s]\n",
      "INFO:lightrag:Inserting 25 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.55s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.40s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/INTEL CORPORATION.txt. Total tokens used: 858387\n",
      "INFO:lightrag:Writing graph with 757 nodes, 481 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 858387\n",
      "INFO:lightrag:Processed: INTEL CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/BROADCOM INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/BROADCOM INC..txt. Total tokens used: 858387\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: INTEL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.19s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 2234, Output: 2234, Total: 862855\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2709, Output: 272, Total: 865836\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 334, Total: 869269\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 353, Total: 872721\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3008, Output: 491, Total: 876220\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 2 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:12<00:25, 12.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3460, Output: 606, Total: 880286\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 12 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:15<00:06,  6.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3479, Output: 601, Total: 884366\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 29 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:15<00:00,  5.18s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/25 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 698, Output: 500, Total: 885564\n",
      "INFO:lightrag:Processing file: Ratings/BROADCOM INC..txt\n",
      "Inserting entities: 100%|██████████| 25/25 [00:10<00:00,  2.30entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 5322.72relationship/s]\n",
      "INFO:lightrag:Inserting 25 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.43s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.08batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/BROADCOM INC..txt. Total tokens used: 885564\n",
      "INFO:lightrag:Writing graph with 774 nodes, 489 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 885564\n",
      "INFO:lightrag:Processed: BROADCOM INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/MORGAN STANLEY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/MORGAN STANLEY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/MORGAN STANLEY.txt. Total tokens used: 885564\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BROADCOM INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.56batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1208, Output: 1208, Total: 887980\n",
      "INFO:lightrag:Processing file: Ratings/MORGAN STANLEY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2319, Output: 164, Total: 890463\n",
      "INFO:lightrag:Processing file: Ratings/MORGAN STANLEY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 301, Total: 893863\n",
      "INFO:lightrag:Processing file: Ratings/MORGAN STANLEY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2510, Output: 340, Total: 896713\n",
      "INFO:lightrag:Processing file: Ratings/MORGAN STANLEY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:11<00:11, 11.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3427, Output: 891, Total: 901031\n",
      "INFO:lightrag:Processing file: Ratings/MORGAN STANLEY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 26 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:26<00:00, 13.24s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 25/25 [00:00<00:00, 8509.79entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 15855.18relationship/s]\n",
      "INFO:lightrag:Inserting 25 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.53s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.22s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/MORGAN STANLEY.txt. Total tokens used: 901031\n",
      "INFO:lightrag:Writing graph with 800 nodes, 502 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 901031\n",
      "INFO:lightrag:Processed: MORGAN STANLEY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/NETFLIX, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/NETFLIX, INC..txt. Total tokens used: 901031\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: MORGAN STANLEY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1484, Output: 1484, Total: 903999\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 640, Total: 907738\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2933, Output: 687, Total: 911358\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3766, Output: 274, Total: 915398\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:25<00:25, 25.92s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3647, Output: 465, Total: 919510\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 35 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:34<00:00, 17.22s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/27 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 681, Output: 500, Total: 920691\n",
      "INFO:lightrag:Processing file: Ratings/NETFLIX, INC..txt\n",
      "Inserting entities: 100%|██████████| 27/27 [00:12<00:00,  2.12entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 5467.66relationship/s]\n",
      "INFO:lightrag:Inserting 27 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:05<00:00,  5.50s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/NETFLIX, INC..txt. Total tokens used: 920691\n",
      "INFO:lightrag:Writing graph with 822 nodes, 511 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 920691\n",
      "INFO:lightrag:Processed: NETFLIX, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n",
      "INFO:lightrag:Inserting content from Ratings/Philip Morris International Inc..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/Philip Morris International Inc..txt. Total tokens used: 920691\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: NETFLIX, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.90batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1487, Output: 1487, Total: 923665\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2705, Output: 295, Total: 926665\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 429, Total: 930193\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3555, Output: 330, Total: 934078\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.88s/chunk]INFO:lightrag:Updated token count - Input: 3027, Output: 490, Total: 937595\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 24 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:12<00:00,  6.44s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/22 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 678, Output: 500, Total: 938773\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n",
      "Inserting entities:  95%|█████████▌| 21/22 [00:14<00:00,  1.49entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 700, Output: 500, Total: 939973\n",
      "INFO:lightrag:Processing file: Ratings/Philip Morris International Inc..txt\n",
      "Inserting entities: 100%|██████████| 22/22 [00:14<00:00,  1.54entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 5/5 [00:00<00:00, 3394.55relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/batch]\n",
      "INFO:lightrag:Inserting 5 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.40batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/Philip Morris International Inc..txt. Total tokens used: 939973\n",
      "INFO:lightrag:Writing graph with 838 nodes, 516 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 939973\n",
      "INFO:lightrag:Processed: Philip Morris International Inc..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/COLGATE-PALMOLIVE COMPANY.txt. Total tokens used: 939973\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Philip Morris International Inc..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.55batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1732, Output: 1732, Total: 943437\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1956, Output: 101, Total: 945494\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2084, Output: 72, Total: 947650\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 1 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:04<00:08,  4.12s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3056, Output: 452, Total: 951158\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 454, Total: 954710\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3535, Output: 871, Total: 959116\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 25 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:20<00:11, 11.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3579, Output: 977, Total: 963672\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 39 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:21<00:00,  7.24s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/31 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 685, Output: 464, Total: 964821\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "Inserting entities:  97%|█████████▋| 30/31 [00:10<00:00,  2.75entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 675, Output: 500, Total: 965996\n",
      "INFO:lightrag:Processing file: Ratings/COLGATE-PALMOLIVE COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 31/31 [00:11<00:00,  2.67entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 5660.87relationship/s]\n",
      "INFO:lightrag:Inserting 31 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.79s/batch]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.25s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/COLGATE-PALMOLIVE COMPANY.txt. Total tokens used: 965996\n",
      "INFO:lightrag:Writing graph with 866 nodes, 530 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 965996\n",
      "INFO:lightrag:Processed: COLGATE-PALMOLIVE COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ADVANCED MICRO DEVICES, INC..txt. Total tokens used: 965996\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: COLGATE-PALMOLIVE COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1731, Output: 1731, Total: 969458\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1928, Output: 53, Total: 971439\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2008, Output: 77, Total: 973524\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 0 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:03<00:06,  3.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3028, Output: 530, Total: 977082\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 595, Total: 980776\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3585, Output: 800, Total: 985161\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 24 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:18<00:10, 10.60s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3721, Output: 829, Total: 989711\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 51 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:20<00:00,  6.80s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/48 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 671, Output: 500, Total: 990882\n",
      "INFO:lightrag:Processing file: Ratings/ADVANCED MICRO DEVICES, INC..txt\n",
      "Inserting entities: 100%|██████████| 48/48 [00:11<00:00,  4.08entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 3914.63relationship/s]\n",
      "INFO:lightrag:Inserting 48 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.25batch/s]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/ADVANCED MICRO DEVICES, INC..txt. Total tokens used: 990882\n",
      "INFO:lightrag:Writing graph with 900 nodes, 539 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 990882\n",
      "INFO:lightrag:Processed: ADVANCED MICRO DEVICES, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/AMERICAN EXPRESS COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/AMERICAN EXPRESS COMPANY.txt. Total tokens used: 990882\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ADVANCED MICRO DEVICES, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.07batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1410, Output: 1410, Total: 993702\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2691, Output: 271, Total: 996664\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 602, Total: 1000365\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2989, Output: 404, Total: 1003758\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3728, Output: 569, Total: 1008055\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 29 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:24<00:00, 12.13s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/28 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 679, Output: 500, Total: 1009234\n",
      "INFO:lightrag:Processing file: Ratings/AMERICAN EXPRESS COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 28/28 [00:18<00:00,  1.48entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 5798.04relationship/s]\n",
      "INFO:lightrag:Inserting 28 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.71s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/AMERICAN EXPRESS COMPANY.txt. Total tokens used: 1009234\n",
      "INFO:lightrag:Writing graph with 918 nodes, 554 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1009234\n",
      "INFO:lightrag:Processed: AMERICAN EXPRESS COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/DANAHER CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/DANAHER CORPORATION.txt. Total tokens used: 1009234\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AMERICAN EXPRESS COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.20s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1419, Output: 1419, Total: 1012072\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 227, Total: 1015397\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2643, Output: 156, Total: 1018196\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2826, Output: 452, Total: 1021474\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 5 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:13<00:13, 13.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3352, Output: 478, Total: 1025304\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 13 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:14<00:00,  7.31s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/12 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 634, Output: 358, Total: 1026296\n",
      "INFO:lightrag:Processing file: Ratings/DANAHER CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 12/12 [00:09<00:00,  1.23entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 10/10 [00:00<00:00, 3821.34relationship/s]\n",
      "INFO:lightrag:Inserting 12 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Inserting 10 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.33s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/DANAHER CORPORATION.txt. Total tokens used: 1026296\n",
      "INFO:lightrag:Writing graph with 927 nodes, 564 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1026296\n",
      "INFO:lightrag:Processed: DANAHER CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n",
      "INFO:lightrag:Inserting content from Ratings/MASTERCARD INCORPORATED..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/MASTERCARD INCORPORATED..txt. Total tokens used: 1026296\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: DANAHER CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.12batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1604, Output: 1604, Total: 1029504\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 212, Total: 1032815\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2936, Output: 434, Total: 1036185\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3338, Output: 452, Total: 1039975\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:16<00:16, 16.33s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3397, Output: 1015, Total: 1044387\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 36 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:28<00:00, 14.31s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/32 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 708, Output: 500, Total: 1045595\n",
      "INFO:lightrag:Processing file: Ratings/MASTERCARD INCORPORATED..txt\n",
      "Inserting entities: 100%|██████████| 32/32 [00:12<00:00,  2.54entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 3584.49relationship/s]\n",
      "INFO:lightrag:Inserting 32 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.24s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.10batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/MASTERCARD INCORPORATED..txt. Total tokens used: 1045595\n",
      "INFO:lightrag:Writing graph with 952 nodes, 572 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1045595\n",
      "INFO:lightrag:Processed: MASTERCARD INCORPORATED..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/BOOKING HOLDINGS INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/BOOKING HOLDINGS INC..txt. Total tokens used: 1045595\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: MASTERCARD INCORPORATED..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.00batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1865, Output: 1865, Total: 1049325\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2289, Output: 281, Total: 1051895\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 400, Total: 1055394\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 464, Total: 1058956\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3526, Output: 162, Total: 1062644\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:12<00:25, 12.80s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2597, Output: 415, Total: 1065656\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:15<00:06,  6.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3589, Output: 722, Total: 1069967\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 39 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:24<00:00,  8.30s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/30 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 751, Output: 500, Total: 1071218\n",
      "INFO:lightrag:Processing file: Ratings/BOOKING HOLDINGS INC..txt\n",
      "Inserting entities: 100%|██████████| 30/30 [00:11<00:00,  2.53entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 3429.52relationship/s]\n",
      "INFO:lightrag:Inserting 30 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.51s/batch]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.49s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/BOOKING HOLDINGS INC..txt. Total tokens used: 1071218\n",
      "INFO:lightrag:Writing graph with 970 nodes, 579 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1071218\n",
      "INFO:lightrag:Processed: BOOKING HOLDINGS INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/CVS HEALTH CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CVS HEALTH CORPORATION.txt. Total tokens used: 1071218\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BOOKING HOLDINGS INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.04batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1812, Output: 1812, Total: 1074842\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2021, Output: 217, Total: 1077080\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 382, Total: 1080561\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2265, Output: 170, Total: 1082996\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:08<00:16,  8.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 470, Total: 1086565\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3508, Output: 546, Total: 1090619\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:18<00:09,  9.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3596, Output: 587, Total: 1094802\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 27 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:21<00:00,  7.02s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/21 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 681, Output: 500, Total: 1095983\n",
      "INFO:lightrag:Processing file: Ratings/CVS HEALTH CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 21/21 [00:10<00:00,  1.92entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 16/16 [00:00<00:00, 5374.30relationship/s]\n",
      "INFO:lightrag:Inserting 21 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.11s/batch]\n",
      "INFO:lightrag:Inserting 16 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/CVS HEALTH CORPORATION.txt. Total tokens used: 1095983\n",
      "INFO:lightrag:Writing graph with 986 nodes, 595 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1095983\n",
      "INFO:lightrag:Processed: CVS HEALTH CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/AT&T INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/AT&T INC..txt. Total tokens used: 1095983\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CVS HEALTH CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1534, Output: 1534, Total: 1099051\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2872, Output: 222, Total: 1102145\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 387, Total: 1105630\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3121, Output: 369, Total: 1109120\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:13<00:13, 13.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 695, Total: 1113327\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 25 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:23<00:00, 11.55s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/22 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 735, Output: 500, Total: 1114562\n",
      "INFO:lightrag:Processing file: Ratings/AT&T INC..txt\n",
      "Inserting entities: 100%|██████████| 22/22 [00:13<00:00,  1.63entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 12/12 [00:00<00:00, 5735.80relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.43s/batch]\n",
      "INFO:lightrag:Inserting 12 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.72s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/AT&T INC..txt. Total tokens used: 1114562\n",
      "INFO:lightrag:Writing graph with 1003 nodes, 607 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1114562\n",
      "INFO:lightrag:Processed: AT&T INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/DUKE ENERGY CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/DUKE ENERGY CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/DUKE ENERGY CORPORATION.txt. Total tokens used: 1114562\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AT&T INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.78batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1331, Output: 1331, Total: 1117224\n",
      "INFO:lightrag:Processing file: Ratings/DUKE ENERGY CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2428, Output: 470, Total: 1120122\n",
      "INFO:lightrag:Processing file: Ratings/DUKE ENERGY CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2925, Output: 358, Total: 1123405\n",
      "INFO:lightrag:Processing file: Ratings/DUKE ENERGY CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:18<00:18, 18.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 892, Total: 1127396\n",
      "INFO:lightrag:Processing file: Ratings/DUKE ENERGY CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4018, Output: 585, Total: 1131999\n",
      "INFO:lightrag:Processing file: Ratings/DUKE ENERGY CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 40 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:31<00:00, 15.67s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 36/36 [00:00<00:00, 6610.12entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 10424.33relationship/s]\n",
      "INFO:lightrag:Inserting 36 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.36batch/s]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/DUKE ENERGY CORPORATION.txt. Total tokens used: 1131999\n",
      "INFO:lightrag:Writing graph with 1034 nodes, 621 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1131999\n",
      "INFO:lightrag:Processed: DUKE ENERGY CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt. Total tokens used: 1131999\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: DUKE ENERGY CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.39batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1537, Output: 1537, Total: 1135073\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 303, Total: 1138475\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2882, Output: 563, Total: 1141920\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3429, Output: 660, Total: 1146009\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:21<00:21, 21.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3472, Output: 448, Total: 1149929\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 24 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:22<00:00, 11.19s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/20 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 709, Output: 500, Total: 1151138\n",
      "INFO:lightrag:Processing file: Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 20/20 [00:10<00:00,  1.84entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 11/11 [00:00<00:00, 9785.23relationship/s]\n",
      "INFO:lightrag:Inserting 20 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.15s/batch]\n",
      "INFO:lightrag:Inserting 11 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.33s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/BRISTOL-MYERS SQUIBB COMPANY.txt. Total tokens used: 1151138\n",
      "INFO:lightrag:Writing graph with 1044 nodes, 632 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1151138\n",
      "INFO:lightrag:Processed: BRISTOL-MYERS SQUIBB COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/CISCO SYSTEMS, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CISCO SYSTEMS, INC..txt. Total tokens used: 1151138\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BRISTOL-MYERS SQUIBB COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1510, Output: 1510, Total: 1154158\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2676, Output: 249, Total: 1157083\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 364, Total: 1160546\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3490, Output: 498, Total: 1164534\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:20<00:20, 20.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2952, Output: 680, Total: 1168166\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 24 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:22<00:00, 11.14s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/23 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 684, Output: 472, Total: 1169322\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n",
      "Inserting entities:  96%|█████████▌| 22/23 [00:11<00:00,  1.90entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 672, Output: 500, Total: 1170494\n",
      "INFO:lightrag:Processing file: Ratings/CISCO SYSTEMS, INC..txt\n",
      "Inserting entities: 100%|██████████| 23/23 [00:12<00:00,  1.89entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 11/11 [00:00<00:00, 4923.42relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.58s/batch]\n",
      "INFO:lightrag:Inserting 11 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.01batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/CISCO SYSTEMS, INC..txt. Total tokens used: 1170494\n",
      "INFO:lightrag:Writing graph with 1059 nodes, 643 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1170494\n",
      "INFO:lightrag:Processed: CISCO SYSTEMS, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/PEPSICO, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/PEPSICO, INC..txt. Total tokens used: 1170494\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CISCO SYSTEMS, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.62batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1554, Output: 1554, Total: 1173602\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2967, Output: 167, Total: 1176736\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 361, Total: 1180196\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3487, Output: 404, Total: 1184087\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 14 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:17<00:17, 17.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3161, Output: 649, Total: 1187897\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 29 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:18<00:00,  9.09s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/17 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 673, Output: 498, Total: 1189068\n",
      "INFO:lightrag:Processing file: Ratings/PEPSICO, INC..txt\n",
      "Inserting entities: 100%|██████████| 17/17 [00:11<00:00,  1.49entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 2/2 [00:00<00:00, 1881.28relationship/s]\n",
      "INFO:lightrag:Inserting 17 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.14s/batch]\n",
      "INFO:lightrag:Inserting 2 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/PEPSICO, INC..txt. Total tokens used: 1189068\n",
      "INFO:lightrag:Writing graph with 1074 nodes, 645 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1189068\n",
      "INFO:lightrag:Processed: PEPSICO, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE WALT DISNEY COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE WALT DISNEY COMPANY.txt. Total tokens used: 1189068\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: PEPSICO, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.05batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1671, Output: 1671, Total: 1192410\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2969, Output: 241, Total: 1195620\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 254, Total: 1198973\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3380, Output: 532, Total: 1202885\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:19<00:19, 19.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3237, Output: 643, Total: 1206765\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:21<00:00, 10.64s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/15 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 724, Output: 500, Total: 1207989\n",
      "INFO:lightrag:Processing file: Ratings/THE WALT DISNEY COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 15/15 [00:11<00:00,  1.35entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 3923.01relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.06s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.35s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE WALT DISNEY COMPANY.txt. Total tokens used: 1207989\n",
      "INFO:lightrag:Writing graph with 1086 nodes, 658 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1207989\n",
      "INFO:lightrag:Processed: THE WALT DISNEY COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/WALMART INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/WALMART INC..txt. Total tokens used: 1207989\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE WALT DISNEY COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.27batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1334, Output: 1334, Total: 1210657\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 329, Total: 1214085\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2443, Output: 416, Total: 1216944\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2886, Output: 292, Total: 1220122\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.95s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3455, Output: 395, Total: 1223972\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.66s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/14 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 671, Output: 354, Total: 1224997\n",
      "INFO:lightrag:Processing file: Ratings/WALMART INC..txt\n",
      "Inserting entities: 100%|██████████| 14/14 [00:09<00:00,  1.52entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 13/13 [00:00<00:00, 6053.06relationship/s]\n",
      "INFO:lightrag:Inserting 14 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.84s/batch]\n",
      "INFO:lightrag:Inserting 13 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/WALMART INC..txt. Total tokens used: 1224997\n",
      "INFO:lightrag:Writing graph with 1096 nodes, 671 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1224997\n",
      "INFO:lightrag:Processed: WALMART INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/ADOBE INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ADOBE INC..txt. Total tokens used: 1224997\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: WALMART INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1733, Output: 1733, Total: 1228463\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 440, Total: 1232002\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2991, Output: 475, Total: 1235468\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3566, Output: 517, Total: 1239551\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 17 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:24<00:24, 24.38s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3493, Output: 493, Total: 1243537\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 29 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:25<00:00, 12.65s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/22 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 693, Output: 500, Total: 1244730\n",
      "INFO:lightrag:Processing file: Ratings/ADOBE INC..txt\n",
      "Inserting entities: 100%|██████████| 22/22 [00:09<00:00,  2.25entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 7795.07relationship/s]\n",
      "INFO:lightrag:Inserting 22 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.71s/batch]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.24s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/ADOBE INC..txt. Total tokens used: 1244730\n",
      "INFO:lightrag:Writing graph with 1115 nodes, 685 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1244730\n",
      "INFO:lightrag:Processed: ADOBE INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/NIKE, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/NIKE, INC..txt. Total tokens used: 1244730\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ADOBE INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.39batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1324, Output: 1324, Total: 1247378\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2528, Output: 248, Total: 1250154\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 364, Total: 1253616\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2803, Output: 440, Total: 1256859\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:19<00:19, 19.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3489, Output: 429, Total: 1260777\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:24<00:00, 12.04s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/17 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 689, Output: 500, Total: 1261966\n",
      "INFO:lightrag:Processing file: Ratings/NIKE, INC..txt\n",
      "Inserting entities: 100%|██████████| 17/17 [00:12<00:00,  1.36entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 1646.58relationship/s]\n",
      "INFO:lightrag:Inserting 17 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.00s/batch]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.55s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/NIKE, INC..txt. Total tokens used: 1261966\n",
      "INFO:lightrag:Writing graph with 1126 nodes, 692 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1261966\n",
      "INFO:lightrag:Processed: NIKE, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/METLIFE, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/METLIFE, INC..txt. Total tokens used: 1261966\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: NIKE, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.02batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1668, Output: 1668, Total: 1265302\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1972, Output: 46, Total: 1267320\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2045, Output: 124, Total: 1269489\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 5 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:05<00:11,  5.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3072, Output: 264, Total: 1272825\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 584, Total: 1276508\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3710, Output: 382, Total: 1280600\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:20<00:10, 10.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3363, Output: 1106, Total: 1285069\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 37 entities(duplicated), 22 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:27<00:00,  9.11s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/29 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 690, Output: 500, Total: 1286259\n",
      "INFO:lightrag:Processing file: Ratings/METLIFE, INC..txt\n",
      "Inserting entities: 100%|██████████| 29/29 [00:16<00:00,  1.80entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 21/21 [00:00<00:00, 1795.95relationship/s]\n",
      "INFO:lightrag:Inserting 29 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.71s/batch]\n",
      "INFO:lightrag:Inserting 21 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.40s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/METLIFE, INC..txt. Total tokens used: 1286259\n",
      "INFO:lightrag:Writing graph with 1148 nodes, 713 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1286259\n",
      "INFO:lightrag:Processed: METLIFE, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE PROCTER & GAMBLE COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE PROCTER & GAMBLE COMPANY.txt. Total tokens used: 1286259\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: METLIFE, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.24batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1370, Output: 1370, Total: 1288999\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2572, Output: 228, Total: 1291799\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 389, Total: 1295287\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2827, Output: 535, Total: 1298649\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.33s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3515, Output: 484, Total: 1302648\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.96s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/11 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 729, Output: 484, Total: 1303861\n",
      "INFO:lightrag:Processing file: Ratings/THE PROCTER & GAMBLE COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 11/11 [00:10<00:00,  1.05entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 6030.92relationship/s]\n",
      "INFO:lightrag:Inserting 11 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.21s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE PROCTER & GAMBLE COMPANY.txt. Total tokens used: 1303861\n",
      "INFO:lightrag:Writing graph with 1157 nodes, 728 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1303861\n",
      "INFO:lightrag:Processed: THE PROCTER & GAMBLE COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/ALPHABET INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/ALPHABET INC..txt. Total tokens used: 1303861\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE PROCTER & GAMBLE COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.53batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1896, Output: 1896, Total: 1307653\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 371, Total: 1311123\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2123, Output: 466, Total: 1313712\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 545, Total: 1317356\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2616, Output: 280, Total: 1320252\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:15<00:30, 15.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3671, Output: 563, Total: 1324486\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 21 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:21<00:10, 10.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3497, Output: 604, Total: 1328587\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 31 entities(duplicated), 28 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [01:38<00:00, 32.82s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/23 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 762, Output: 500, Total: 1329849\n",
      "INFO:lightrag:Processing file: Ratings/ALPHABET INC..txt\n",
      "Inserting entities: 100%|██████████| 23/23 [00:10<00:00,  2.29entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 27/27 [00:00<00:00, 9246.85relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.47s/batch]\n",
      "INFO:lightrag:Inserting 27 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.27s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/ALPHABET INC..txt. Total tokens used: 1329849\n",
      "INFO:lightrag:Writing graph with 1175 nodes, 755 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1329849\n",
      "INFO:lightrag:Processed: ALPHABET INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/COMCAST CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/COMCAST CORPORATION.txt. Total tokens used: 1329849\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: ALPHABET INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.23batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1558, Output: 1558, Total: 1332965\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2856, Output: 215, Total: 1336036\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 609, Total: 1339743\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3734, Output: 610, Total: 1344087\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 19 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:27<00:27, 27.93s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 672, Total: 1347857\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 36 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:37<00:00, 18.59s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/33 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 654, Output: 339, Total: 1348850\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n",
      "Inserting entities:  97%|█████████▋| 32/33 [00:07<00:00,  4.56entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 667, Output: 500, Total: 1350017\n",
      "INFO:lightrag:Processing file: Ratings/COMCAST CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 33/33 [00:10<00:00,  3.24entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 3661.32relationship/s]\n",
      "INFO:lightrag:Inserting 33 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.73batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.06batch/s]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.13batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/COMCAST CORPORATION.txt. Total tokens used: 1350017\n",
      "INFO:lightrag:Writing graph with 1200 nodes, 762 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1350017\n",
      "INFO:lightrag:Processed: COMCAST CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/UNION PACIFIC CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/UNION PACIFIC CORPORATION.txt. Total tokens used: 1350017\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: COMCAST CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.14s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1313, Output: 1313, Total: 1352643\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2570, Output: 226, Total: 1355439\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2823, Output: 495, Total: 1358757\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:12<00:12, 12.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 544, Total: 1362400\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3670, Output: 662, Total: 1366732\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 24 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:32<00:00, 16.34s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/23 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 665, Output: 500, Total: 1367897\n",
      "INFO:lightrag:Processing file: Ratings/UNION PACIFIC CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 23/23 [00:09<00:00,  2.32entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 11/11 [00:00<00:00, 4908.23relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/batch]\n",
      "INFO:lightrag:Inserting 11 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.76s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/UNION PACIFIC CORPORATION.txt. Total tokens used: 1367897\n",
      "INFO:lightrag:Writing graph with 1215 nodes, 773 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1367897\n",
      "INFO:lightrag:Processed: UNION PACIFIC CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n",
      "INFO:lightrag:Inserting content from Ratings/U.S. BANCORP.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/U.S. BANCORP.txt. Total tokens used: 1367897\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: UNION PACIFIC CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1995, Output: 1995, Total: 1371887\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2246, Output: 87, Total: 1374220\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 314, Total: 1377632\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2360, Output: 257, Total: 1380249\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:06<00:13,  6.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 678, Total: 1384026\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3804, Output: 559, Total: 1388389\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 22 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:20<00:11, 11.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3439, Output: 863, Total: 1392691\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 34 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:21<00:00,  7.24s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/29 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 671, Output: 500, Total: 1393862\n",
      "INFO:lightrag:Processing file: Ratings/U.S. BANCORP.txt\n",
      "Inserting entities: 100%|██████████| 29/29 [00:09<00:00,  3.11entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 17/17 [00:00<00:00, 5781.96relationship/s]\n",
      "INFO:lightrag:Inserting 29 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:03<00:00,  3.27s/batch]\n",
      "INFO:lightrag:Inserting 17 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.06s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/U.S. BANCORP.txt. Total tokens used: 1393862\n",
      "INFO:lightrag:Writing graph with 1235 nodes, 790 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1393862\n",
      "INFO:lightrag:Processed: U.S. BANCORP.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/MICROSOFT CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/MICROSOFT CORPORATION.txt. Total tokens used: 1393862\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: U.S. BANCORP.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.33batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1417, Output: 1417, Total: 1396696\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2521, Output: 239, Total: 1399456\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 491, Total: 1403046\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2787, Output: 375, Total: 1406208\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 6 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3617, Output: 411, Total: 1410236\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 13 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:20<00:00, 10.27s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/10 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 689, Output: 461, Total: 1411386\n",
      "INFO:lightrag:Processing file: Ratings/MICROSOFT CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 10/10 [00:12<00:00,  1.24s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 7292.86relationship/s]\n",
      "INFO:lightrag:Inserting 10 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/MICROSOFT CORPORATION.txt. Total tokens used: 1411386\n",
      "INFO:lightrag:Writing graph with 1243 nodes, 798 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1411386\n",
      "INFO:lightrag:Processed: MICROSOFT CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n",
      "INFO:lightrag:Inserting content from Ratings/Meta Platforms, Inc..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/Meta Platforms, Inc..txt. Total tokens used: 1411386\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: MICROSOFT CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.25s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1866, Output: 1866, Total: 1415118\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2142, Output: 150, Total: 1417410\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 262, Total: 1420771\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 267, Total: 1424137\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3388, Output: 353, Total: 1427878\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:19<00:39, 19.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3393, Output: 277, Total: 1431548\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 20 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:20<00:08,  8.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2319, Output: 511, Total: 1434378\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 27 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:21<00:00,  7.16s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/25 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 717, Output: 500, Total: 1435595\n",
      "INFO:lightrag:Processing file: Ratings/Meta Platforms, Inc..txt\n",
      "Inserting entities: 100%|██████████| 25/25 [00:22<00:00,  1.11entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 9/9 [00:00<00:00, 3980.67relationship/s]\n",
      "INFO:lightrag:Inserting 25 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.51s/batch]\n",
      "INFO:lightrag:Inserting 9 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/Meta Platforms, Inc..txt. Total tokens used: 1435595\n",
      "INFO:lightrag:Writing graph with 1257 nodes, 807 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1435595\n",
      "INFO:lightrag:Processed: Meta Platforms, Inc..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/LOWE'S COMPANIES, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/LOWE'S COMPANIES, INC..txt. Total tokens used: 1435595\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Meta Platforms, Inc..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.71batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1188, Output: 1188, Total: 1437971\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 252, Total: 1441321\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2585, Output: 363, Total: 1444269\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3377, Output: 676, Total: 1448322\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:17<00:17, 17.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2975, Output: 765, Total: 1452062\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 23 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:20<00:00, 10.25s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/20 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 653, Output: 494, Total: 1453209\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n",
      "Inserting entities:  95%|█████████▌| 19/20 [00:10<00:00,  1.87entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 690, Output: 500, Total: 1454399\n",
      "INFO:lightrag:Processing file: Ratings/LOWE'S COMPANIES, INC..txt\n",
      "Inserting entities: 100%|██████████| 20/20 [00:22<00:00,  1.12s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 14/14 [00:00<00:00, 6965.63relationship/s]\n",
      "INFO:lightrag:Inserting 20 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.31s/batch]\n",
      "INFO:lightrag:Inserting 14 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.43s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/LOWE'S COMPANIES, INC..txt. Total tokens used: 1454399\n",
      "INFO:lightrag:Writing graph with 1268 nodes, 821 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1454399\n",
      "INFO:lightrag:Processed: LOWE'S COMPANIES, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/EXXON MOBIL CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/EXXON MOBIL CORPORATION.txt. Total tokens used: 1454399\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: LOWE'S COMPANIES, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.09s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 2183, Output: 2183, Total: 1458765\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2324, Output: 242, Total: 1461331\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 444, Total: 1464874\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 515, Total: 1468487\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2593, Output: 400, Total: 1471480\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 3 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:13<00:26, 13.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3640, Output: 170, Total: 1475290\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 12 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:13<00:05,  5.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3570, Output: 385, Total: 1479245\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 23 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:16<00:00,  5.49s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/18 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 671, Output: 500, Total: 1480416\n",
      "INFO:lightrag:Processing file: Ratings/EXXON MOBIL CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 18/18 [00:23<00:00,  1.31s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 10/10 [00:00<00:00, 6313.87relationship/s]\n",
      "INFO:lightrag:Inserting 18 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.73s/batch]\n",
      "INFO:lightrag:Inserting 10 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/EXXON MOBIL CORPORATION.txt. Total tokens used: 1480416\n",
      "INFO:lightrag:Writing graph with 1281 nodes, 831 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1480416\n",
      "INFO:lightrag:Processed: EXXON MOBIL CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/LOCKHEED MARTIN CORPORATION.txt. Total tokens used: 1480416\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: EXXON MOBIL CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.54batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1166, Output: 1166, Total: 1482748\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2298, Output: 311, Total: 1485357\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 303, Total: 1488759\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2636, Output: 709, Total: 1492104\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:19<00:19, 19.93s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3429, Output: 448, Total: 1495981\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:24<00:00, 12.35s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/16 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 673, Output: 485, Total: 1497139\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "Inserting entities:  94%|█████████▍| 15/16 [00:13<00:00,  1.14entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 680, Output: 325, Total: 1498144\n",
      "INFO:lightrag:Processing file: Ratings/LOCKHEED MARTIN CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 16/16 [00:16<00:00,  1.03s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 5594.89relationship/s]\n",
      "INFO:lightrag:Inserting 16 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.63s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/LOCKHEED MARTIN CORPORATION.txt. Total tokens used: 1498144\n",
      "INFO:lightrag:Writing graph with 1290 nodes, 846 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1498144\n",
      "INFO:lightrag:Processed: LOCKHEED MARTIN CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/NVIDIA CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/NVIDIA CORPORATION.txt. Total tokens used: 1498144\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: LOCKHEED MARTIN CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.17batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1790, Output: 1790, Total: 1501724\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1955, Output: 55, Total: 1503734\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2037, Output: 35, Total: 1505806\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 1 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:06<00:12,  6.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3055, Output: 404, Total: 1509265\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 713, Total: 1513076\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3486, Output: 518, Total: 1517080\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 13 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:25<00:13, 13.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3838, Output: 337, Total: 1521255\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 28 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:27<00:00,  9.21s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/24 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 643, Output: 495, Total: 1522393\n",
      "INFO:lightrag:Processing file: Ratings/NVIDIA CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 24/24 [00:24<00:00,  1.04s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 5426.01relationship/s]\n",
      "INFO:lightrag:Inserting 24 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.66s/batch]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.18batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/NVIDIA CORPORATION.txt. Total tokens used: 1522393\n",
      "INFO:lightrag:Writing graph with 1306 nodes, 853 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1522393\n",
      "INFO:lightrag:Processed: NVIDIA CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/BERKSHIRE HATHAWAY INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/BERKSHIRE HATHAWAY INC..txt. Total tokens used: 1522393\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: NVIDIA CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.80batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1653, Output: 1653, Total: 1525699\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2954, Output: 222, Total: 1528875\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 955, Total: 1532929\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3203, Output: 708, Total: 1536840\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:17<00:17, 17.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4081, Output: 430, Total: 1541351\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:28<00:00, 14.37s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/24 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 672, Output: 500, Total: 1542523\n",
      "INFO:lightrag:Processing file: Ratings/BERKSHIRE HATHAWAY INC..txt\n",
      "Inserting entities: 100%|██████████| 24/24 [00:12<00:00,  1.90entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 15/15 [00:00<00:00, 6744.70relationship/s]\n",
      "INFO:lightrag:Inserting 24 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.50s/batch]\n",
      "INFO:lightrag:Inserting 15 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/BERKSHIRE HATHAWAY INC..txt. Total tokens used: 1542523\n",
      "INFO:lightrag:Writing graph with 1327 nodes, 868 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1542523\n",
      "INFO:lightrag:Processed: BERKSHIRE HATHAWAY INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n",
      "INFO:lightrag:Inserting content from Ratings/EMERSON ELECTRIC CO..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/EMERSON ELECTRIC CO..txt. Total tokens used: 1542523\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BERKSHIRE HATHAWAY INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.09batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1809, Output: 1809, Total: 1546141\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2000, Output: 223, Total: 1548364\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 414, Total: 1551877\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 444, Total: 1555420\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2250, Output: 309, Total: 1557979\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:10<00:20, 10.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3570, Output: 443, Total: 1561992\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:18<00:08,  8.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3540, Output: 534, Total: 1566066\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 32 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:18<00:00,  6.32s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/26 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 702, Output: 500, Total: 1567268\n",
      "INFO:lightrag:Processing file: Ratings/EMERSON ELECTRIC CO..txt\n",
      "Inserting entities: 100%|██████████| 26/26 [00:12<00:00,  2.05entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 11/11 [00:00<00:00, 5886.37relationship/s]\n",
      "INFO:lightrag:Inserting 26 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.93s/batch]\n",
      "INFO:lightrag:Inserting 11 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.38s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/EMERSON ELECTRIC CO..txt. Total tokens used: 1567268\n",
      "INFO:lightrag:Writing graph with 1346 nodes, 879 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1567268\n",
      "INFO:lightrag:Processed: EMERSON ELECTRIC CO..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/SALESFORCE, INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/SALESFORCE, INC..txt. Total tokens used: 1567268\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: EMERSON ELECTRIC CO..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.79batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1705, Output: 1705, Total: 1570678\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2990, Output: 267, Total: 1573935\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 322, Total: 1577355\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3284, Output: 426, Total: 1581065\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 2 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:15<00:15, 15.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3447, Output: 614, Total: 1585126\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 10 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [07:18<00:00, 219.13s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/10 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 708, Output: 500, Total: 1586334\n",
      "INFO:lightrag:Processing file: Ratings/SALESFORCE, INC..txt\n",
      "Inserting entities: 100%|██████████| 10/10 [00:09<00:00,  1.08entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 3970.27relationship/s]\n",
      "INFO:lightrag:Inserting 10 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.31s/batch]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.13s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/SALESFORCE, INC..txt. Total tokens used: 1586334\n",
      "INFO:lightrag:Writing graph with 1353 nodes, 886 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1586334\n",
      "INFO:lightrag:Processed: SALESFORCE, INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/THE COCA-COLA COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/THE COCA-COLA COMPANY.txt. Total tokens used: 1586334\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: SALESFORCE, INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.06batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 2035, Output: 2035, Total: 1590404\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2314, Output: 213, Total: 1592931\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 339, Total: 1596369\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 776, Total: 1600243\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3465, Output: 610, Total: 1604318\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:22<00:45, 22.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2554, Output: 699, Total: 1607571\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:22<00:09,  9.55s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3901, Output: 311, Total: 1611783\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 37 entities(duplicated), 23 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:25<00:00,  8.40s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/33 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 690, Output: 500, Total: 1612973\n",
      "INFO:lightrag:Processing file: Ratings/THE COCA-COLA COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 33/33 [00:13<00:00,  2.43entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 23/23 [00:00<00:00, 6365.91relationship/s]\n",
      "INFO:lightrag:Inserting 33 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.50batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.75batch/s]\n",
      "INFO:lightrag:Inserting 23 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.49s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/THE COCA-COLA COMPANY.txt. Total tokens used: 1612973\n",
      "INFO:lightrag:Writing graph with 1379 nodes, 909 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1612973\n",
      "INFO:lightrag:Processed: THE COCA-COLA COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/INTUIT INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/INTUIT INC..txt. Total tokens used: 1612973\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: THE COCA-COLA COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.50batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1275, Output: 1275, Total: 1615523\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 275, Total: 1618896\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2527, Output: 486, Total: 1621909\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3040, Output: 450, Total: 1625399\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:26<00:26, 26.95s/chunk]INFO:openai._base_client:Retrying request to /chat/completions in 0.388495 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3400, Output: 616, Total: 1629415\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 24 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [10:18<00:00, 309.18s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/17 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 669, Output: 500, Total: 1630584\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n",
      "Inserting entities:  94%|█████████▍| 16/17 [00:08<00:00,  1.87entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 665, Output: 500, Total: 1631749\n",
      "INFO:lightrag:Processing file: Ratings/INTUIT INC..txt\n",
      "Inserting entities: 100%|██████████| 17/17 [00:15<00:00,  1.11entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 12/12 [00:00<00:00, 4222.45relationship/s]\n",
      "INFO:lightrag:Inserting 17 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.05s/batch]\n",
      "INFO:lightrag:Inserting 12 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.16s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/INTUIT INC..txt. Total tokens used: 1631749\n",
      "INFO:lightrag:Writing graph with 1389 nodes, 921 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1631749\n",
      "INFO:lightrag:Processed: INTUIT INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/CATERPILLAR INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CATERPILLAR INC..txt. Total tokens used: 1631749\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: INTUIT INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.32batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1332, Output: 1332, Total: 1634413\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2460, Output: 193, Total: 1637066\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 312, Total: 1640476\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3437, Output: 419, Total: 1644332\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:15<00:15, 15.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2680, Output: 504, Total: 1647516\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 20 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:15<00:00,  7.93s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/15 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 681, Output: 468, Total: 1648665\n",
      "INFO:lightrag:Processing file: Ratings/CATERPILLAR INC..txt\n",
      "Inserting entities: 100%|██████████| 15/15 [00:11<00:00,  1.27entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 6/6 [00:00<00:00, 2946.82relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.30s/batch]\n",
      "INFO:lightrag:Inserting 6 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11batch/s]\n",
      "INFO:lightrag:Finished processing Ratings/CATERPILLAR INC..txt. Total tokens used: 1648665\n",
      "INFO:lightrag:Writing graph with 1397 nodes, 927 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1648665\n",
      "INFO:lightrag:Processed: CATERPILLAR INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt. Total tokens used: 1648665\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CATERPILLAR INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.30batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1827, Output: 1827, Total: 1652319\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2016, Output: 352, Total: 1654687\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 391, Total: 1658177\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 592, Total: 1661868\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2395, Output: 397, Total: 1664660\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 10 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:16<00:32, 16.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3517, Output: 528, Total: 1668705\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 20 entities(duplicated), 18 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:19<00:08,  8.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3718, Output: 687, Total: 1673110\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 20 entities(duplicated), 22 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:27<00:00,  9.08s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/18 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 713, Output: 500, Total: 1674323\n",
      "INFO:lightrag:Processing file: Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 18/18 [00:14<00:00,  1.20entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 21/21 [00:00<00:00, 5714.31relationship/s]\n",
      "INFO:lightrag:Inserting 18 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.65s/batch]\n",
      "INFO:lightrag:Inserting 21 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.32s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/INTERNATIONAL BUSINESS MACHINES CORPORATION.txt. Total tokens used: 1674323\n",
      "INFO:lightrag:Writing graph with 1412 nodes, 948 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1674323\n",
      "INFO:lightrag:Processed: INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n",
      "INFO:lightrag:Inserting content from Ratings/FORD MOTOR COMPANY.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/FORD MOTOR COMPANY.txt. Total tokens used: 1674323\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: INTERNATIONAL BUSINESS MACHINES CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.89batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1469, Output: 1469, Total: 1677261\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2670, Output: 241, Total: 1680172\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 627, Total: 1683898\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2938, Output: 407, Total: 1687243\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:14<00:14, 14.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3753, Output: 393, Total: 1691389\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 23 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:20<00:00, 10.23s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/19 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.499136 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 724, Output: 414, Total: 1692527\n",
      "INFO:lightrag:Processing file: Ratings/FORD MOTOR COMPANY.txt\n",
      "Inserting entities: 100%|██████████| 19/19 [01:06<00:00,  3.51s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 7/7 [00:00<00:00, 686.27relationship/s]\n",
      "INFO:lightrag:Inserting 19 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.37s/batch]\n",
      "INFO:lightrag:Inserting 7 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.48s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/FORD MOTOR COMPANY.txt. Total tokens used: 1692527\n",
      "INFO:lightrag:Writing graph with 1423 nodes, 955 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1692527\n",
      "INFO:lightrag:Processed: FORD MOTOR COMPANY.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/TARGET CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/TARGET CORPORATION.txt. Total tokens used: 1692527\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: FORD MOTOR COMPANY.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.00s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 1459, Output: 1459, Total: 1695445\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2681, Output: 463, Total: 1698589\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 557, Total: 1702245\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3171, Output: 842, Total: 1706258\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 17 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:44<00:44, 44.32s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3683, Output: 625, Total: 1710566\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 24 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [01:00<00:00, 30.04s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/23 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 683, Output: 500, Total: 1711749\n",
      "INFO:lightrag:Processing file: Ratings/TARGET CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 23/23 [00:16<00:00,  1.40entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 21/21 [00:00<00:00, 1117.02relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.42s/batch]\n",
      "INFO:lightrag:Inserting 21 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.18s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/TARGET CORPORATION.txt. Total tokens used: 1711749\n",
      "INFO:lightrag:Writing graph with 1438 nodes, 976 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1711749\n",
      "INFO:lightrag:Processed: TARGET CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "INFO:lightrag:Inserting content from Ratings/Altria Group, Inc..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/Altria Group, Inc..txt. Total tokens used: 1711749\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: TARGET CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 2174, Output: 2174, Total: 1716097\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2476, Output: 200, Total: 1718773\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 386, Total: 1722258\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 671, Total: 1726028\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2703, Output: 635, Total: 1729366\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:18<00:36, 18.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 714, Total: 1733592\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:29<00:13, 13.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3797, Output: 591, Total: 1737980\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 33 entities(duplicated), 30 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [00:35<00:00, 11.67s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/23 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 657, Output: 439, Total: 1739076\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "Inserting entities:  96%|█████████▌| 22/23 [00:08<00:00,  2.49entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 747, Output: 500, Total: 1740323\n",
      "INFO:lightrag:Processing file: Ratings/Altria Group, Inc..txt\n",
      "Inserting entities: 100%|██████████| 23/23 [00:10<00:00,  2.14entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 23/23 [00:00<00:00, 6122.29relationship/s]\n",
      "INFO:lightrag:Inserting 23 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.36s/batch]\n",
      "INFO:lightrag:Inserting 23 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.24s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/Altria Group, Inc..txt. Total tokens used: 1740323\n",
      "INFO:lightrag:Writing graph with 1462 nodes, 999 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1740323\n",
      "INFO:lightrag:Processed: Altria Group, Inc..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n",
      "INFO:lightrag:Inserting content from Ratings/AMGEN INC..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/AMGEN INC..txt. Total tokens used: 1740323\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Altria Group, Inc..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.06batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1437, Output: 1437, Total: 1743197\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2760, Output: 424, Total: 1746381\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 585, Total: 1750065\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3211, Output: 532, Total: 1753808\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:22<00:22, 22.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3711, Output: 1006, Total: 1758525\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 28 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:34<00:00, 17.47s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/26 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 674, Output: 500, Total: 1759699\n",
      "INFO:lightrag:Processing file: Ratings/AMGEN INC..txt\n",
      "Inserting entities: 100%|██████████| 26/26 [00:09<00:00,  2.82entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 26/26 [00:00<00:00, 2172.65relationship/s]\n",
      "INFO:lightrag:Inserting 26 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.69s/batch]\n",
      "INFO:lightrag:Inserting 26 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.48s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/AMGEN INC..txt. Total tokens used: 1759699\n",
      "INFO:lightrag:Writing graph with 1482 nodes, 1025 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1759699\n",
      "INFO:lightrag:Processed: AMGEN INC..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/CHEVRON CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/CHEVRON CORPORATION.txt. Total tokens used: 1759699\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AMGEN INC..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.45batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1500, Output: 1500, Total: 1762699\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2632, Output: 186, Total: 1765517\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2845, Output: 248, Total: 1768610\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:10<00:10, 10.29s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 413, Total: 1772122\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3539, Output: 390, Total: 1776051\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:44<00:00, 22.38s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/15 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 673, Output: 415, Total: 1777139\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n",
      "Inserting entities:  93%|█████████▎| 14/15 [00:13<00:00,  1.01entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 679, Output: 500, Total: 1778318\n",
      "INFO:lightrag:Processing file: Ratings/CHEVRON CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 15/15 [00:16<00:00,  1.10s/entity]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 8/8 [00:00<00:00, 2581.71relationship/s]\n",
      "INFO:lightrag:Inserting 15 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Inserting 8 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.27s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/CHEVRON CORPORATION.txt. Total tokens used: 1778318\n",
      "INFO:lightrag:Writing graph with 1487 nodes, 1033 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1778318\n",
      "INFO:lightrag:Processed: CHEVRON CORPORATION.txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/Mondelez International, Inc..txt\n",
      "INFO:lightrag:Inserting content from Ratings/Mondelez International, Inc..txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/Mondelez International, Inc..txt. Total tokens used: 1778318\n",
      "INFO:lightrag:[New Chunks] inserting 2 chunks\n",
      "INFO:lightrag:Inserting 2 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CHEVRON CORPORATION.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.18batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1600, Output: 1600, Total: 1781518\n",
      "INFO:lightrag:Processing file: Ratings/Mondelez International, Inc..txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/2 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2982, Output: 833, Total: 1785333\n",
      "INFO:lightrag:Processing file: Ratings/Mondelez International, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1007, Total: 1789439\n",
      "INFO:lightrag:Processing file: Ratings/Mondelez International, Inc..txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3842, Output: 310, Total: 1793591\n",
      "INFO:lightrag:Processing file: Ratings/Mondelez International, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 15 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 1/2 [00:24<00:24, 24.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4133, Output: 580, Total: 1798304\n",
      "INFO:lightrag:Processing file: Ratings/Mondelez International, Inc..txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 40 entities(duplicated), 18 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 2/2 [00:32<00:00, 16.02s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 29/29 [00:00<00:00, 1514.13entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 10/10 [00:00<00:00, 5345.11relationship/s]\n",
      "INFO:lightrag:Inserting 29 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.26s/batch]\n",
      "INFO:lightrag:Inserting 10 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.11s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/Mondelez International, Inc..txt. Total tokens used: 1798304\n",
      "INFO:lightrag:Writing graph with 1506 nodes, 1043 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1798304\n",
      "INFO:lightrag:Processed: Mondelez International, Inc..txt\n",
      "INFO:lightrag:Processing folder: Ratings\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n",
      "INFO:lightrag:Inserting content from Ratings/RTX CORPORATION.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Ratings/RTX CORPORATION.txt. Total tokens used: 1798304\n",
      "INFO:lightrag:[New Chunks] inserting 3 chunks\n",
      "INFO:lightrag:Inserting 3 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Mondelez International, Inc..txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.36batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 1924, Output: 1924, Total: 1802152\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/3 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2225, Output: 276, Total: 1804653\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 718, Total: 1808469\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2528, Output: 534, Total: 1811531\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 1/3 [00:17<00:35, 17.78s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3843, Output: 300, Total: 1815674\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 2/3 [00:21<00:09,  9.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 683, Total: 1819456\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3809, Output: 394, Total: 1823659\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 42 entities(duplicated), 23 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 3/3 [01:51<00:00, 37.02s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/33 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 744, Output: 500, Total: 1824903\n",
      "INFO:lightrag:Processing file: Ratings/RTX CORPORATION.txt\n",
      "Inserting entities: 100%|██████████| 33/33 [00:10<00:00,  3.15entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 17/17 [00:00<00:00, 6599.70relationship/s]\n",
      "INFO:lightrag:Inserting 33 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.58batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.18batch/s]\n",
      "INFO:lightrag:Inserting 17 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.32s/batch]\n",
      "INFO:lightrag:Finished processing Ratings/RTX CORPORATION.txt. Total tokens used: 1824903\n",
      "INFO:lightrag:Writing graph with 1530 nodes, 1060 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 1824903\n",
      "INFO:lightrag:Processed: RTX CORPORATION.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: RTX CORPORATION.txt\n"
     ]
    }
   ],
   "source": [
    "ratings_file_path = \"/Users/arthurj/Library/CloudStorage/OneDrive-moodys.com/Desktop/LightRag_Data/KG_data/Ratings\"\n",
    "\n",
    "process_files_in_folder(ratings_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt. Total tokens used: 1824903\n",
      "INFO:lightrag:[New Chunks] inserting 32 chunks\n",
      "INFO:lightrag:Inserting 32 vectors to chunks\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.97s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 23051, Output: 23051, Total: 1871005\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/32 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 161, Total: 1874265\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 147, Total: 1877510\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 341, Total: 1880950\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 362, Total: 1884410\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 468, Total: 1887977\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 399, Total: 1891475\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 531, Total: 1895106\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 297, Total: 1898500\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 396, Total: 1901995\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 774, Total: 1905868\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 772, Total: 1909739\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3525, Output: 534, Total: 1913798\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/32 [00:17<09:11, 17.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 814, Total: 1917711\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3421, Output: 511, Total: 1921643\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 29 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/32 [00:18<03:55,  7.87s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3287, Output: 624, Total: 1925554\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 40 entities(duplicated), 22 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/32 [00:18<02:06,  4.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 865, Total: 1929518\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3467, Output: 496, Total: 1933481\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 55 entities(duplicated), 25 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▎        | 4/32 [00:19<01:21,  2.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3900, Output: 345, Total: 1937726\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 72 entities(duplicated), 31 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/32 [00:20<00:55,  2.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3658, Output: 344, Total: 1941728\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 86 entities(duplicated), 36 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 6/32 [00:20<00:42,  1.62s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 1003, Total: 1945829\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3272, Output: 593, Total: 1949694\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 95 entities(duplicated), 44 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 7/32 [00:23<00:50,  2.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3991, Output: 288, Total: 1953973\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 109 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 8/32 [00:24<00:40,  1.68s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 338, Total: 1957410\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3898, Output: 269, Total: 1961577\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 126 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 9/32 [00:26<00:36,  1.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3522, Output: 417, Total: 1965516\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 137 entities(duplicated), 64 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 10/32 [00:26<00:24,  1.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 476, Total: 1969090\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 529, Total: 1972718\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 157, Total: 1975974\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 615, Total: 1979688\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 968, Total: 1983755\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 502, Total: 1987356\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3594, Output: 822, Total: 1991772\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 152 entities(duplicated), 74 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 11/32 [00:30<00:47,  2.25s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3940, Output: 661, Total: 1996373\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 173 entities(duplicated), 90 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 12/32 [00:34<00:50,  2.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4094, Output: 431, Total: 2000898\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 194 entities(duplicated), 100 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 13/32 [00:37<00:53,  2.81s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3741, Output: 405, Total: 2005044\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 209 entities(duplicated), 106 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 14/32 [00:37<00:35,  1.99s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3601, Output: 639, Total: 2009284\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 221 entities(duplicated), 119 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 684, Total: 2013067\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 529, Total: 2016695\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3628, Output: 245, Total: 2020568\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 232 entities(duplicated), 124 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 16/32 [00:39<00:25,  1.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3464, Output: 606, Total: 2024638\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 243 entities(duplicated), 134 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 17/32 [00:40<00:18,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3655, Output: 445, Total: 2028738\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 254 entities(duplicated), 144 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▋    | 18/32 [00:40<00:14,  1.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 915, Total: 2032752\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 445, Total: 2036296\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 333, Total: 2039727\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 517, Total: 2043344\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 771, Total: 2047213\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3655, Output: 379, Total: 2051247\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 265 entities(duplicated), 152 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 19/32 [00:44<00:24,  1.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3283, Output: 722, Total: 2055252\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 275 entities(duplicated), 161 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▎   | 20/32 [00:45<00:19,  1.62s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4128, Output: 1098, Total: 2060478\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 298 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 21/32 [00:45<00:13,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3810, Output: 455, Total: 2064743\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 317 entities(duplicated), 191 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 22/32 [00:46<00:10,  1.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 686, Total: 2068528\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4041, Output: 354, Total: 2072923\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 333 entities(duplicated), 199 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 23/32 [00:48<00:12,  1.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3458, Output: 414, Total: 2076795\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 346 entities(duplicated), 202 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 24/32 [00:49<00:11,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2713, Output: 578, Total: 2080086\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3896, Output: 265, Total: 2084247\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 359 entities(duplicated), 209 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 25/32 [00:51<00:09,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3571, Output: 477, Total: 2088295\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 369 entities(duplicated), 218 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 637, Total: 2092031\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3812, Output: 469, Total: 2096312\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 383 entities(duplicated), 232 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 27/32 [00:56<00:10,  2.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3644, Output: 652, Total: 2100608\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 395 entities(duplicated), 242 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 28/32 [00:57<00:06,  1.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3318, Output: 522, Total: 2104448\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 409 entities(duplicated), 253 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 29/32 [01:00<00:06,  2.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3763, Output: 607, Total: 2108818\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 411 entities(duplicated), 255 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 30/32 [01:07<00:06,  3.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3487, Output: 284, Total: 2112589\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 423 entities(duplicated), 259 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 31/32 [01:42<00:12, 12.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 665, Total: 2116352\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3790, Output: 401, Total: 2120543\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 443 entities(duplicated), 265 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 32/32 [08:17<00:00, 15.54s/chunk] \n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/247 [00:00<00:28,  8.72entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 799, Output: 257, Total: 2121599\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 244/247 [00:05<00:00, 44.99entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1329, Output: 400, Total: 2123328\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 684, Output: 418, Total: 2124430\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 690, Output: 500, Total: 2125620\n",
      "INFO:lightrag:Processing file: Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 247/247 [00:10<00:00, 22.95entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 202/202 [00:00<00:00, 13224.22relationship/s]\n",
      "INFO:lightrag:Inserting 247 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  12%|█▎        | 1/8 [00:01<00:07,  1.12s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  25%|██▌       | 2/8 [00:01<00:03,  1.64batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:57<00:00,  7.19s/batch]\n",
      "INFO:lightrag:Inserting 202 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  14%|█▍        | 1/7 [00:01<00:06,  1.01s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:03<00:00,  2.31batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt. Total tokens used: 2125620\n",
      "INFO:lightrag:Writing graph with 1763 nodes, 1262 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 2125620\n",
      "INFO:lightrag:Processed: US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt. Total tokens used: 2125620\n",
      "INFO:lightrag:[New Chunks] inserting 33 chunks\n",
      "INFO:lightrag:Inserting 33 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US5-26960522I_38e85743-0e01-3206-96fb-8f9aed7887c5_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.67batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.31s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 22355, Output: 22355, Total: 2170330\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/33 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 119, Total: 2173548\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 155, Total: 2176802\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 180, Total: 2180082\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 266, Total: 2183448\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 299, Total: 2186847\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 267, Total: 2190213\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2678, Output: 356, Total: 2193247\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 350, Total: 2196696\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 429, Total: 2200224\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 407, Total: 2203730\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 548, Total: 2207377\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 474, Total: 2210950\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3245, Output: 268, Total: 2214463\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 6 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/33 [00:10<05:32, 10.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 434, Total: 2217996\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3307, Output: 299, Total: 2221602\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/33 [00:12<02:54,  5.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3674, Output: 178, Total: 2225454\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 24 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/33 [00:13<01:47,  3.58s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 598, Total: 2229151\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3555, Output: 256, Total: 2232962\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 36 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▏        | 4/33 [00:15<01:17,  2.68s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3476, Output: 308, Total: 2236746\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 44 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 271, Total: 2240117\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3281, Output: 578, Total: 2243976\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 61 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  18%|█▊        | 6/33 [00:15<00:38,  1.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3061, Output: 487, Total: 2247524\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 70 entities(duplicated), 32 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  21%|██        | 7/33 [00:16<00:29,  1.12s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3426, Output: 485, Total: 2251435\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 80 entities(duplicated), 41 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  24%|██▍       | 8/33 [00:16<00:23,  1.08chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 739, Total: 2255273\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3393, Output: 599, Total: 2259265\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 92 entities(duplicated), 48 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  27%|██▋       | 9/33 [00:18<00:28,  1.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3560, Output: 286, Total: 2263111\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 100 entities(duplicated), 55 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  30%|███       | 10/33 [00:18<00:21,  1.07chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3533, Output: 410, Total: 2267054\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 115 entities(duplicated), 61 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 11/33 [00:19<00:16,  1.30chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3393, Output: 488, Total: 2270935\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 117 entities(duplicated), 65 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▋      | 12/33 [00:19<00:12,  1.73chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3600, Output: 450, Total: 2274985\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 133 entities(duplicated), 70 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▉      | 13/33 [00:19<00:10,  1.89chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 591, Total: 2278675\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3724, Output: 499, Total: 2282898\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 148 entities(duplicated), 81 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 14/33 [00:22<00:22,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 446, Total: 2286443\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3865, Output: 297, Total: 2290605\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 166 entities(duplicated), 89 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  45%|████▌     | 15/33 [00:23<00:19,  1.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3398, Output: 625, Total: 2294628\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 184 entities(duplicated), 91 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  48%|████▊     | 16/33 [00:24<00:19,  1.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 582, Total: 2298309\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 321, Total: 2301729\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 232, Total: 2305060\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 611, Total: 2308770\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 571, Total: 2312440\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3717, Output: 364, Total: 2316521\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 202 entities(duplicated), 98 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  52%|█████▏    | 17/33 [00:26<00:23,  1.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3572, Output: 263, Total: 2320356\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 213 entities(duplicated), 102 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  55%|█████▍    | 18/33 [00:28<00:23,  1.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3697, Output: 181, Total: 2324234\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 225 entities(duplicated), 108 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 19/33 [00:30<00:21,  1.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 571, Total: 2327904\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 484, Total: 2331487\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3096, Output: 898, Total: 2335481\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 613, Total: 2339192\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 849, Total: 2343141\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 949, Total: 2347189\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 545, Total: 2350832\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3737, Output: 494, Total: 2355063\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 245 entities(duplicated), 114 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 20/33 [00:33<00:27,  2.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3708, Output: 296, Total: 2359067\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 260 entities(duplicated), 120 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  64%|██████▎   | 21/33 [00:34<00:20,  1.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3447, Output: 674, Total: 2363188\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 273 entities(duplicated), 131 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 22/33 [00:34<00:14,  1.29s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 515, Total: 2366802\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 955, Total: 2370856\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3610, Output: 373, Total: 2374839\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 285 entities(duplicated), 139 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  70%|██████▉   | 23/33 [00:39<00:25,  2.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3358, Output: 661, Total: 2378858\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 298 entities(duplicated), 147 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  73%|███████▎  | 24/33 [00:41<00:20,  2.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3641, Output: 299, Total: 2382798\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 312 entities(duplicated), 152 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3670, Output: 613, Total: 2387081\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 327 entities(duplicated), 158 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  79%|███████▉  | 26/33 [00:43<00:11,  1.68s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3976, Output: 632, Total: 2391689\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 346 entities(duplicated), 176 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  82%|████████▏ | 27/33 [00:45<00:09,  1.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3738, Output: 463, Total: 2395890\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 366 entities(duplicated), 183 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  85%|████████▍ | 28/33 [00:45<00:06,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3697, Output: 542, Total: 2400129\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 379 entities(duplicated), 195 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 29/33 [00:47<00:05,  1.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4075, Output: 570, Total: 2404774\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 379 entities(duplicated), 212 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 30/33 [00:48<00:04,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4021, Output: 684, Total: 2409479\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 401 entities(duplicated), 239 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 31/33 [00:51<00:03,  1.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4081, Output: 885, Total: 2414445\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 424 entities(duplicated), 261 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 32/33 [00:58<00:03,  3.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 518, Total: 2418062\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3644, Output: 642, Total: 2422348\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 437 entities(duplicated), 271 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 33/33 [02:30<00:00,  4.56s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/287 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 699, Output: 459, Total: 2423506\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 285/287 [00:09<00:00, 30.67entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 659, Output: 500, Total: 2424665\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1189, Output: 500, Total: 2426354\n",
      "INFO:lightrag:Processing file: Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 287/287 [00:12<00:00, 22.14entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 224/224 [00:00<00:00, 18504.77relationship/s]\n",
      "INFO:lightrag:Inserting 287 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  11%|█         | 1/9 [00:01<00:10,  1.30s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  44%|████▍     | 4/9 [00:01<00:01,  3.29batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:03<00:00,  2.77batch/s]\n",
      "INFO:lightrag:Inserting 224 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.37batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt. Total tokens used: 2426354\n",
      "INFO:lightrag:Writing graph with 2017 nodes, 1485 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 2426354\n",
      "INFO:lightrag:Processed: US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt. Total tokens used: 2426354\n",
      "INFO:lightrag:[New Chunks] inserting 32 chunks\n",
      "INFO:lightrag:Inserting 32 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US134172551_7e5d91fb-d789-364d-94c2-7ed21d52cf88_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.37s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 21581, Output: 21581, Total: 2469516\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/32 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 165, Total: 2472781\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 187, Total: 2476067\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 326, Total: 2479492\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 286, Total: 2482876\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3313, Output: 22, Total: 2486211\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 1 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/32 [00:07<04:00,  7.77s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 291, Total: 2489602\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 249, Total: 2492950\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 303, Total: 2496352\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 322, Total: 2499773\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 380, Total: 2503253\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 445, Total: 2506797\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3448, Output: 95, Total: 2510340\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 8 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/32 [00:11<02:39,  5.33s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 543, Total: 2513982\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 574, Total: 2517654\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 456, Total: 2521209\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3375, Output: 216, Total: 2524800\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 18 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/32 [00:14<02:05,  4.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 759, Total: 2528658\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3452, Output: 462, Total: 2532572\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 35 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▎        | 4/32 [00:15<01:24,  3.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 571, Total: 2536242\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 882, Total: 2540223\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3429, Output: 370, Total: 2544022\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 48 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/32 [00:18<01:21,  3.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3292, Output: 555, Total: 2547869\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 56 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 6/32 [00:19<00:59,  2.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3699, Output: 408, Total: 2551976\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 69 entities(duplicated), 32 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 7/32 [00:19<00:42,  1.68s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3669, Output: 498, Total: 2556143\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 89 entities(duplicated), 39 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 8/32 [00:20<00:33,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3507, Output: 556, Total: 2560206\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 99 entities(duplicated), 48 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 9/32 [00:23<00:41,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 640, Total: 2563945\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 516, Total: 2567559\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3766, Output: 30, Total: 2571355\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 107 entities(duplicated), 55 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 10/32 [00:24<00:35,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3411, Output: 962, Total: 2575728\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 124 entities(duplicated), 71 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 11/32 [00:25<00:26,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3418, Output: 633, Total: 2579779\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 138 entities(duplicated), 76 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3885, Output: 496, Total: 2584160\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 153 entities(duplicated), 90 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 13/32 [00:25<00:15,  1.27chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 512, Total: 2587771\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3582, Output: 590, Total: 2591943\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 166 entities(duplicated), 102 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 14/32 [00:26<00:13,  1.36chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3697, Output: 594, Total: 2596234\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 180 entities(duplicated), 114 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 15/32 [00:28<00:19,  1.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3571, Output: 670, Total: 2600475\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 195 entities(duplicated), 127 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 16/32 [00:29<00:19,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 154, Total: 2603727\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2480, Output: 740, Total: 2606947\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 302, Total: 2610347\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 607, Total: 2614053\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 693, Total: 2617846\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 477, Total: 2621423\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 463, Total: 2624986\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 746, Total: 2628831\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 239, Total: 2632168\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3247, Output: 222, Total: 2635637\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 208 entities(duplicated), 135 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 17/32 [00:35<00:36,  2.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3279, Output: 428, Total: 2639344\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 219 entities(duplicated), 136 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▋    | 18/32 [00:37<00:34,  2.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3641, Output: 736, Total: 2643721\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 235 entities(duplicated), 151 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 19/32 [00:38<00:23,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3820, Output: 348, Total: 2647889\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 250 entities(duplicated), 158 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▎   | 20/32 [00:38<00:17,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3590, Output: 279, Total: 2651758\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 262 entities(duplicated), 163 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 21/32 [00:39<00:12,  1.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4008, Output: 602, Total: 2656368\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 282 entities(duplicated), 180 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 22/32 [00:40<00:11,  1.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3638, Output: 733, Total: 2660739\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 299 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 23/32 [00:40<00:07,  1.14chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3604, Output: 407, Total: 2664750\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 311 entities(duplicated), 198 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 24/32 [00:41<00:06,  1.19chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3364, Output: 352, Total: 2668466\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 322 entities(duplicated), 200 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 25/32 [00:41<00:05,  1.39chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3733, Output: 425, Total: 2672624\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 335 entities(duplicated), 212 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 877, Total: 2676600\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3427, Output: 606, Total: 2680633\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 347 entities(duplicated), 223 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 27/32 [00:42<00:03,  1.62chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1074, Total: 2684806\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3872, Output: 677, Total: 2689355\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 365 entities(duplicated), 238 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 28/32 [00:45<00:04,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4200, Output: 230, Total: 2693785\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 383 entities(duplicated), 250 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 29/32 [00:48<00:04,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4003, Output: 349, Total: 2698137\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 402 entities(duplicated), 260 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 30/32 [00:51<00:03,  1.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 950, Total: 2702186\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4076, Output: 596, Total: 2706858\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 431 entities(duplicated), 272 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 31/32 [01:03<00:04,  4.96s/chunk]INFO:openai._base_client:Retrying request to /chat/completions in 0.414606 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 754, Total: 2710711\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3880, Output: 615, Total: 2715206\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 447 entities(duplicated), 287 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 32/32 [10:49<00:00, 20.31s/chunk] \n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/270 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1457, Output: 348, Total: 2717011\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 268/270 [00:07<00:00, 36.47entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 942, Output: 500, Total: 2718453\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 719, Output: 500, Total: 2719672\n",
      "INFO:lightrag:Processing file: Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 270/270 [00:10<00:00, 26.92entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 200/200 [00:00<00:00, 3671.82relationship/s]\n",
      "INFO:lightrag:Inserting 270 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.63batch/s]\n",
      "INFO:lightrag:Inserting 200 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.26batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt. Total tokens used: 2719672\n",
      "INFO:lightrag:Writing graph with 2219 nodes, 1682 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 2719672\n",
      "INFO:lightrag:Processed: US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt. Total tokens used: 2719672\n",
      "INFO:lightrag:[New Chunks] inserting 31 chunks\n",
      "INFO:lightrag:Inserting 31 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US472989869_447ab6ea-210d-3e4e-8495-7949f167b63d_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.19s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 21103, Output: 21103, Total: 2761878\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/31 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 85, Total: 2765062\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 158, Total: 2768319\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2715, Output: 334, Total: 2771368\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3211, Output: 247, Total: 2774826\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/31 [00:07<03:40,  7.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 387, Total: 2778311\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 234, Total: 2781645\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 458, Total: 2785202\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 454, Total: 2788755\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 466, Total: 2792319\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 532, Total: 2795950\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 548, Total: 2799598\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 568, Total: 2803264\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 674, Total: 2807037\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3284, Output: 506, Total: 2810827\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/31 [00:12<02:59,  6.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 200, Total: 2814539\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 29 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  10%|▉         | 3/31 [00:13<01:43,  3.68s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3658, Output: 376, Total: 2818573\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 43 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  13%|█▎        | 4/31 [00:16<01:32,  3.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 971, Total: 2822643\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3361, Output: 524, Total: 2826528\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 51 entities(duplicated), 22 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/31 [00:17<01:02,  2.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3591, Output: 469, Total: 2830588\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 68 entities(duplicated), 27 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 6/31 [00:17<00:41,  1.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1008, Total: 2834695\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4134, Output: 23, Total: 2838852\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 79 entities(duplicated), 37 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  23%|██▎       | 7/31 [00:19<00:40,  1.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3584, Output: 447, Total: 2842883\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 96 entities(duplicated), 42 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▌       | 8/31 [00:19<00:27,  1.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3675, Output: 360, Total: 2846918\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 106 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  29%|██▉       | 9/31 [00:19<00:21,  1.05chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3693, Output: 243, Total: 2850854\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 111 entities(duplicated), 60 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 10/31 [00:19<00:14,  1.41chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 788, Total: 2854741\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 684, Total: 2858524\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3800, Output: 408, Total: 2862732\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 118 entities(duplicated), 66 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  35%|███▌      | 11/31 [00:22<00:24,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3580, Output: 457, Total: 2866769\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 130 entities(duplicated), 77 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▊      | 12/31 [00:22<00:19,  1.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4097, Output: 303, Total: 2871169\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 151 entities(duplicated), 89 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 13/31 [00:23<00:16,  1.11chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3076, Output: 508, Total: 2874753\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 161 entities(duplicated), 97 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  45%|████▌     | 14/31 [00:24<00:15,  1.12chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 639, Total: 2878491\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 368, Total: 2881957\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 331, Total: 2885387\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3493, Output: 24, Total: 2888904\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 165 entities(duplicated), 100 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  48%|████▊     | 15/31 [00:26<00:18,  1.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 460, Total: 2892463\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3914, Output: 440, Total: 2896817\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 178 entities(duplicated), 112 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  52%|█████▏    | 16/31 [00:27<00:18,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 856, Total: 2900772\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 536, Total: 2904407\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 103, Total: 2907608\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 545, Total: 2911252\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3765, Output: 321, Total: 2915338\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 193 entities(duplicated), 119 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  55%|█████▍    | 17/31 [00:31<00:28,  2.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 785, Total: 2919222\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 548, Total: 2922870\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 692, Total: 2926660\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 840, Total: 2930599\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3675, Output: 51, Total: 2934325\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 200 entities(duplicated), 125 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 18/31 [00:34<00:30,  2.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3810, Output: 449, Total: 2938584\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 211 entities(duplicated), 132 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████▏   | 19/31 [00:34<00:20,  1.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3586, Output: 486, Total: 2942656\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 222 entities(duplicated), 142 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  65%|██████▍   | 20/31 [00:35<00:16,  1.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3966, Output: 110, Total: 2946732\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 233 entities(duplicated), 150 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 21/31 [00:36<00:14,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3662, Output: 485, Total: 2950879\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 241 entities(duplicated), 155 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████   | 22/31 [00:37<00:09,  1.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 498, Total: 2954476\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 771, Total: 2958346\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3911, Output: 398, Total: 2962655\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 258 entities(duplicated), 162 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▍  | 23/31 [00:39<00:11,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3457, Output: 487, Total: 2966599\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 269 entities(duplicated), 170 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  77%|███████▋  | 24/31 [00:39<00:07,  1.11s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3982, Output: 565, Total: 2971146\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 279 entities(duplicated), 179 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 25/31 [00:40<00:05,  1.05chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3817, Output: 398, Total: 2975361\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 296 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 26/31 [00:41<00:04,  1.17chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3228, Output: 399, Total: 2978988\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 302 entities(duplicated), 189 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  87%|████████▋ | 27/31 [00:41<00:03,  1.24chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3671, Output: 512, Total: 2983171\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 309 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  90%|█████████ | 28/31 [00:41<00:01,  1.59chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3897, Output: 402, Total: 2987470\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 328 entities(duplicated), 202 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▎| 29/31 [00:45<00:03,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3624, Output: 467, Total: 2991561\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 342 entities(duplicated), 212 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 30/31 [00:45<00:01,  1.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 496, Total: 2995155\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3621, Output: 538, Total: 2999314\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 356 entities(duplicated), 219 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 31/31 [02:00<00:00,  3.88s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   1%|          | 1/199 [00:00<00:53,  3.68entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 806, Output: 237, Total: 3000357\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "Inserting entities:  97%|█████████▋| 194/199 [00:06<00:00, 31.43entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 715, Output: 254, Total: 3001326\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 721, Output: 325, Total: 3002372\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 682, Output: 400, Total: 3003454\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 197/199 [00:08<00:00, 20.62entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 782, Output: 500, Total: 3004736\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 748, Output: 500, Total: 3005984\n",
      "INFO:lightrag:Processing file: Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 199/199 [00:12<00:00, 16.13entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 174/174 [00:00<00:00, 15179.37relationship/s]\n",
      "INFO:lightrag:Inserting 199 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:01<00:00,  3.65batch/s]\n",
      "INFO:lightrag:Inserting 174 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/6 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  17%|█▋        | 1/6 [00:01<00:07,  1.42s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:02<00:00,  2.88batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt. Total tokens used: 3005984\n",
      "INFO:lightrag:Writing graph with 2374 nodes, 1855 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 3005984\n",
      "INFO:lightrag:Processed: US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt. Total tokens used: 3005984\n",
      "INFO:lightrag:[New Chunks] inserting 35 chunks\n",
      "INFO:lightrag:Inserting 35 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US900406406_dd11416d-2166-367f-acd9-7d4b7245ea72_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.14batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.17s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 24674, Output: 24674, Total: 3055332\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/35 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 386, Total: 3058817\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 504, Total: 3062420\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 637, Total: 3066157\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 298, Total: 3069967\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/35 [00:13<07:38, 13.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 737, Total: 3073803\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 810, Total: 3077712\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 704, Total: 3081515\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 417, Total: 3085032\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 759, Total: 3088888\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 460, Total: 3092446\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 961, Total: 3096506\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3764, Output: 273, Total: 3100543\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/35 [00:17<04:15,  7.75s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3630, Output: 489, Total: 3104662\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 30 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▊         | 3/35 [00:17<02:24,  4.52s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 539, Total: 3108299\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1007, Total: 3112405\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3830, Output: 244, Total: 3116479\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 43 entities(duplicated), 28 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█▏        | 4/35 [00:19<01:46,  3.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3936, Output: 281, Total: 3120696\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 59 entities(duplicated), 36 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/35 [00:19<01:07,  2.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3883, Output: 349, Total: 3124928\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 81 entities(duplicated), 44 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/35 [00:21<00:59,  2.05s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 757, Total: 3128784\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 154, Total: 3132037\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 870, Total: 3136007\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 243, Total: 3139349\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 928, Total: 3143376\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3585, Output: 449, Total: 3147410\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 94 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  20%|██        | 7/35 [00:25<01:18,  2.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4054, Output: 26, Total: 3151490\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 105 entities(duplicated), 61 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  23%|██▎       | 8/35 [00:26<00:57,  2.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4087, Output: 615, Total: 3156192\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 121 entities(duplicated), 76 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▌       | 9/35 [00:27<00:43,  1.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 559, Total: 3159849\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3863, Output: 581, Total: 3164293\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 139 entities(duplicated), 87 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  29%|██▊       | 10/35 [00:31<01:01,  2.47s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3544, Output: 439, Total: 3168276\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 149 entities(duplicated), 96 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 11/35 [00:32<00:45,  1.91s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3997, Output: 253, Total: 3172526\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 162 entities(duplicated), 106 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 12/35 [00:32<00:35,  1.55s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3883, Output: 221, Total: 3176630\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 174 entities(duplicated), 112 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  37%|███▋      | 13/35 [00:33<00:30,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3369, Output: 530, Total: 3180529\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 185 entities(duplicated), 119 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  40%|████      | 14/35 [00:34<00:26,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 772, Total: 3184400\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4133, Output: 885, Total: 3189418\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 205 entities(duplicated), 136 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  43%|████▎     | 15/35 [00:35<00:20,  1.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 395, Total: 3192912\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3280, Output: 826, Total: 3197018\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 205 entities(duplicated), 136 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  46%|████▌     | 16/35 [00:37<00:26,  1.37s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 437, Total: 3200553\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 268, Total: 3203920\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 934, Total: 3207953\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 1137, Total: 3212190\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 424, Total: 3215713\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 715, Total: 3219527\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3684, Output: 487, Total: 3223698\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 219 entities(duplicated), 147 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  49%|████▊     | 17/35 [00:44<00:57,  3.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 605, Total: 3227402\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3898, Output: 287, Total: 3231587\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 235 entities(duplicated), 154 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  51%|█████▏    | 18/35 [00:46<00:45,  2.68s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 422, Total: 3235108\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4264, Output: 204, Total: 3239576\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 248 entities(duplicated), 164 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  54%|█████▍    | 19/35 [00:47<00:34,  2.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3562, Output: 546, Total: 3243684\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 266 entities(duplicated), 168 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  57%|█████▋    | 20/35 [00:48<00:28,  1.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3521, Output: 534, Total: 3247739\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 278 entities(duplicated), 176 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  60%|██████    | 21/35 [00:49<00:23,  1.65s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 916, Total: 3251754\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 739, Total: 3255592\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 265, Total: 3258956\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3731, Output: 237, Total: 3262924\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 289 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  63%|██████▎   | 22/35 [00:52<00:27,  2.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3550, Output: 423, Total: 3266897\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 302 entities(duplicated), 192 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 23/35 [00:53<00:19,  1.65s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3664, Output: 748, Total: 3271309\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 317 entities(duplicated), 208 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▊   | 24/35 [00:53<00:14,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 519, Total: 3274928\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3841, Output: 566, Total: 3279335\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 341 entities(duplicated), 216 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████▏  | 25/35 [00:54<00:12,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 772, Total: 3283206\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3391, Output: 319, Total: 3286916\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 348 entities(duplicated), 221 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▍  | 26/35 [00:57<00:14,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3865, Output: 300, Total: 3291081\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 362 entities(duplicated), 228 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3898, Output: 390, Total: 3295369\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 381 entities(duplicated), 236 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  80%|████████  | 28/35 [01:01<00:12,  1.81s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3646, Output: 403, Total: 3299418\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 392 entities(duplicated), 246 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 29/35 [01:02<00:08,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4060, Output: 892, Total: 3304370\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 408 entities(duplicated), 254 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 30/35 [01:03<00:07,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3548, Output: 542, Total: 3308460\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 421 entities(duplicated), 262 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▊ | 31/35 [01:05<00:06,  1.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3394, Output: 396, Total: 3312250\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 429 entities(duplicated), 267 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████▏| 32/35 [01:11<00:08,  2.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4042, Output: 392, Total: 3316684\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 447 entities(duplicated), 276 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 33/35 [01:12<00:04,  2.22s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2525, Output: 554, Total: 3319763\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3106, Output: 335, Total: 3323204\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 462 entities(duplicated), 282 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 34/35 [01:50<00:12, 12.69s/chunk]INFO:openai._base_client:Retrying request to /chat/completions in 0.474238 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 622, Total: 3326924\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3747, Output: 527, Total: 3331198\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 482 entities(duplicated), 287 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 35/35 [11:08<00:00, 19.10s/chunk] \n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/245 [00:00<01:28,  2.76entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 731, Output: 152, Total: 3332081\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 241/245 [00:03<00:00, 62.73entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 734, Output: 333, Total: 3333148\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 665, Output: 495, Total: 3334308\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1074, Output: 353, Total: 3335735\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 677, Output: 500, Total: 3336912\n",
      "INFO:lightrag:Processing file: Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 245/245 [00:10<00:00, 22.46entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 200/200 [00:00<00:00, 11568.10relationship/s]\n",
      "INFO:lightrag:Inserting 245 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.64batch/s]\n",
      "INFO:lightrag:Inserting 200 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  14%|█▍        | 1/7 [00:00<00:05,  1.07batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.25batch/s]\n",
      "INFO:lightrag:Finished processing Recon/CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt. Total tokens used: 3336912\n",
      "INFO:lightrag:Writing graph with 2582 nodes, 2055 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 3336912\n",
      "INFO:lightrag:Processed: CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt. Total tokens used: 3336912\n",
      "INFO:lightrag:[New Chunks] inserting 34 chunks\n",
      "INFO:lightrag:Inserting 34 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: CA332670371L_71f9d261-3b01-33a3-b891-754ee2fcb88b_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.64batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.02s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 22722, Output: 22722, Total: 3382356\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/34 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2006, Output: 135, Total: 3384497\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 190, Total: 3387785\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 214, Total: 3391097\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 162, Total: 3394358\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 196, Total: 3397653\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 419, Total: 3401171\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 433, Total: 3404703\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 436, Total: 3408238\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3339, Output: 285, Total: 3411862\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/34 [00:08<04:46,  8.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3288, Output: 377, Total: 3415527\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/34 [00:11<02:44,  5.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 623, Total: 3419247\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 299, Total: 3422645\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 482, Total: 3426226\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2168, Output: 370, Total: 3428764\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 21 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/34 [00:13<01:50,  3.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 523, Total: 3432385\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 361, Total: 3435845\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 750, Total: 3439694\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 318, Total: 3443112\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3322, Output: 545, Total: 3446979\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 29 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▏        | 4/34 [00:15<01:30,  3.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3545, Output: 377, Total: 3450901\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 38 entities(duplicated), 29 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  15%|█▍        | 5/34 [00:15<00:57,  2.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 221, Total: 3454220\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 558, Total: 3457877\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3562, Output: 475, Total: 3461914\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 48 entities(duplicated), 37 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  18%|█▊        | 6/34 [00:17<00:57,  2.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3608, Output: 321, Total: 3465843\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 62 entities(duplicated), 42 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  21%|██        | 7/34 [00:19<00:50,  1.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3876, Output: 247, Total: 3469966\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 78 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  24%|██▎       | 8/34 [00:19<00:36,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3559, Output: 553, Total: 3474078\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 88 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 342, Total: 3477518\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3648, Output: 368, Total: 3481534\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 96 entities(duplicated), 65 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  29%|██▉       | 10/34 [00:22<00:35,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3747, Output: 649, Total: 3485930\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 108 entities(duplicated), 75 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 11/34 [00:24<00:36,  1.58s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 389, Total: 3489418\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3425, Output: 684, Total: 3493527\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 119 entities(duplicated), 84 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  35%|███▌      | 12/34 [00:26<00:38,  1.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3487, Output: 655, Total: 3497669\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 128 entities(duplicated), 91 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 13/34 [00:27<00:30,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3684, Output: 733, Total: 3502086\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 144 entities(duplicated), 104 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 14/34 [00:27<00:22,  1.11s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 669, Total: 3505854\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 615, Total: 3509568\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 407, Total: 3513074\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 835, Total: 3517008\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3445, Output: 488, Total: 3520941\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 152 entities(duplicated), 110 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 15/34 [00:31<00:38,  2.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 678, Total: 3524718\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3467, Output: 384, Total: 3528569\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 165 entities(duplicated), 113 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 16/34 [00:35<00:45,  2.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3101, Output: 142, Total: 3531812\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 563, Total: 3535474\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3533, Output: 280, Total: 3539287\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 176 entities(duplicated), 117 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 17/34 [00:38<00:42,  2.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 423, Total: 3542808\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 577, Total: 3546484\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3741, Output: 476, Total: 3550701\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 187 entities(duplicated), 127 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 18/34 [00:39<00:33,  2.12s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3804, Output: 227, Total: 3554732\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 195 entities(duplicated), 133 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 19/34 [00:40<00:29,  1.98s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3315, Output: 670, Total: 3558717\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 205 entities(duplicated), 142 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 20/34 [00:41<00:20,  1.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3795, Output: 500, Total: 3563012\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 220 entities(duplicated), 147 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▏   | 21/34 [00:41<00:14,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 291, Total: 3566403\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3346, Output: 493, Total: 3570242\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 230 entities(duplicated), 153 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  65%|██████▍   | 22/34 [00:42<00:13,  1.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3515, Output: 709, Total: 3574466\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 243 entities(duplicated), 164 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 23/34 [00:43<00:10,  1.05chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3270, Output: 434, Total: 3578170\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 251 entities(duplicated), 168 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████   | 24/34 [00:46<00:17,  1.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3961, Output: 710, Total: 3582841\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 272 entities(duplicated), 174 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▎  | 25/34 [00:47<00:11,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 827, Total: 3586767\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 392, Total: 3590257\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3548, Output: 616, Total: 3594421\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 284 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  76%|███████▋  | 26/34 [00:52<00:21,  2.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3689, Output: 699, Total: 3598809\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 300 entities(duplicated), 196 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  79%|███████▉  | 27/34 [00:53<00:14,  2.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3418, Output: 523, Total: 3602750\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 315 entities(duplicated), 199 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  82%|████████▏ | 28/34 [00:54<00:10,  1.77s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 730, Total: 3606580\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3953, Output: 745, Total: 3611278\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 336 entities(duplicated), 214 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  85%|████████▌ | 29/34 [00:58<00:12,  2.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3703, Output: 855, Total: 3615836\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 354 entities(duplicated), 231 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 30/34 [00:59<00:07,  1.81s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1041, Total: 3619976\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3517, Output: 587, Total: 3624080\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 354 entities(duplicated), 240 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 31/34 [01:06<00:10,  3.52s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3857, Output: 356, Total: 3628293\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 375 entities(duplicated), 246 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 32/34 [01:06<00:05,  2.55s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4167, Output: 453, Total: 3632913\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 388 entities(duplicated), 262 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 33/34 [01:21<00:06,  6.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.396915 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1071, Total: 3637083\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4197, Output: 448, Total: 3641728\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 401 entities(duplicated), 273 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 34/34 [08:08<00:00, 14.35s/chunk] \n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/265 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 663, Output: 211, Total: 3642602\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 261/265 [00:05<00:00, 43.51entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 644, Output: 284, Total: 3643530\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 676, Output: 302, Total: 3644508\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 653, Output: 500, Total: 3645661\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 819, Output: 500, Total: 3646980\n",
      "INFO:lightrag:Processing file: Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 265/265 [00:13<00:00, 20.11entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 249/249 [00:00<00:00, 7404.49relationship/s]\n",
      "INFO:lightrag:Inserting 265 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  33%|███▎      | 3/9 [00:01<00:02,  2.37batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  89%|████████▉ | 8/9 [00:02<00:00,  4.69batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:05<00:00,  1.59batch/s]\n",
      "INFO:lightrag:Inserting 249 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.31batch/s]\n",
      "INFO:lightrag:Finished processing Recon/GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt. Total tokens used: 3646980\n",
      "INFO:lightrag:Writing graph with 2790 nodes, 2304 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 3646980\n",
      "INFO:lightrag:Processed: GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt. Total tokens used: 3646980\n",
      "INFO:lightrag:[New Chunks] inserting 36 chunks\n",
      "INFO:lightrag:Inserting 36 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: GB01003142_3f7eb441-13f1-316c-9289-2ec5ea84eb24_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:01<00:01,  1.10s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.13batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 24994, Output: 24994, Total: 3696968\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/36 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 212, Total: 3700278\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 222, Total: 3703599\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 242, Total: 3706940\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 184, Total: 3710222\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 292, Total: 3713613\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 487, Total: 3717199\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 584, Total: 3720882\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 651, Total: 3724632\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3348, Output: 398, Total: 3728378\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/36 [00:11<06:59, 11.98s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 247, Total: 3731724\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3368, Output: 453, Total: 3735545\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/36 [00:13<03:15,  5.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3337, Output: 489, Total: 3739371\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 23 entities(duplicated), 18 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 736, Total: 3743205\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 857, Total: 3747161\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3418, Output: 574, Total: 3751153\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 32 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 4/36 [00:16<01:35,  3.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 820, Total: 3755072\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3777, Output: 274, Total: 3759123\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 46 entities(duplicated), 33 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/36 [00:17<01:14,  2.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1080, Total: 3763302\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3309, Output: 693, Total: 3767304\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 57 entities(duplicated), 40 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/36 [00:18<01:05,  2.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 272, Total: 3770675\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3946, Output: 235, Total: 3774856\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 72 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 7/36 [00:22<01:13,  2.53s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3983, Output: 399, Total: 3779238\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 92 entities(duplicated), 58 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 8/36 [00:23<00:58,  2.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.488878 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3710, Output: 307, Total: 3783255\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 102 entities(duplicated), 64 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 9/36 [00:24<00:45,  1.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 318, Total: 3786672\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3613, Output: 920, Total: 3791205\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 113 entities(duplicated), 74 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 10/36 [00:25<00:43,  1.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 371, Total: 3794675\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 692, Total: 3798466\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4206, Output: 344, Total: 3803016\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 136 entities(duplicated), 85 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███       | 11/36 [00:32<01:22,  3.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 636, Total: 3806750\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3398, Output: 763, Total: 3810911\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 148 entities(duplicated), 96 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 12/36 [00:35<01:16,  3.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 399, Total: 3814410\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3861, Output: 765, Total: 3819036\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 169 entities(duplicated), 115 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▌      | 13/36 [00:35<00:52,  2.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3444, Output: 546, Total: 3823026\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 180 entities(duplicated), 125 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 376, Total: 3826501\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 741, Total: 3830341\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3526, Output: 39, Total: 3833906\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 184 entities(duplicated), 129 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 15/36 [00:38<00:37,  1.77s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 314, Total: 3837319\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 130, Total: 3840548\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1909, Total: 3845556\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 162, Total: 3848816\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3373, Output: 748, Total: 3852937\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 195 entities(duplicated), 139 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 16/36 [00:42<00:50,  2.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 467, Total: 3856503\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3497, Output: 694, Total: 3860694\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 209 entities(duplicated), 151 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 17/36 [00:43<00:38,  2.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3761, Output: 374, Total: 3864829\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 219 entities(duplicated), 159 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 18/36 [00:45<00:34,  1.92s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 1112, Total: 3869039\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3440, Output: 376, Total: 3872855\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 226 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 19/36 [00:45<00:26,  1.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 5035, Output: 360, Total: 3878250\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 256 entities(duplicated), 188 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 20/36 [00:46<00:22,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 587, Total: 3881936\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 526, Total: 3885561\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3818, Output: 554, Total: 3889933\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 277 entities(duplicated), 195 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 21/36 [00:49<00:24,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3502, Output: 389, Total: 3893824\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 288 entities(duplicated), 205 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 22/36 [00:49<00:17,  1.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 626, Total: 3897548\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2100, Output: 202, Total: 3899850\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4237, Output: 271, Total: 3904358\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 311 entities(duplicated), 218 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  64%|██████▍   | 23/36 [00:52<00:23,  1.78s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 206, Total: 3907663\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 826, Total: 3911588\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 194, Total: 3914880\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3256, Output: 520, Total: 3918656\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 320 entities(duplicated), 226 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 24/36 [00:54<00:20,  1.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3713, Output: 293, Total: 3922662\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 333 entities(duplicated), 232 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 25/36 [00:56<00:21,  1.99s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3867, Output: 477, Total: 3927006\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 355 entities(duplicated), 240 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 26/36 [00:57<00:17,  1.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2329, Output: 189, Total: 3929524\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 361 entities(duplicated), 244 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 27/36 [00:57<00:11,  1.25s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3593, Output: 518, Total: 3933635\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 374 entities(duplicated), 255 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 694, Total: 3937427\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3652, Output: 784, Total: 3941863\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 389 entities(duplicated), 269 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 29/36 [01:00<00:08,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 605, Total: 3945567\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3819, Output: 302, Total: 3949688\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 405 entities(duplicated), 277 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 30/36 [01:06<00:14,  2.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3287, Output: 640, Total: 3953615\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 416 entities(duplicated), 284 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 31/36 [01:08<00:11,  2.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3952, Output: 668, Total: 3958235\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 435 entities(duplicated), 303 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 32/36 [01:10<00:08,  2.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3731, Output: 444, Total: 3962410\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 453 entities(duplicated), 309 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  92%|█████████▏| 33/36 [01:11<00:05,  1.89s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3319, Output: 670, Total: 3966399\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 474 entities(duplicated), 311 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 34/36 [01:11<00:02,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3751, Output: 613, Total: 3970763\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 489 entities(duplicated), 325 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 35/36 [01:12<00:01,  1.32s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3332, Output: 788, Total: 3974883\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 36 chunks, 502 entities(duplicated), 337 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 36/36 [01:27<00:00,  2.42s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/287 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 898, Output: 383, Total: 3976164\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "Inserting entities:  99%|█████████▊| 283/287 [00:06<00:00, 41.10entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 640, Output: 312, Total: 3977116\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1004, Output: 360, Total: 3978480\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 665, Output: 500, Total: 3979645\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 668, Output: 311, Total: 3980624\n",
      "INFO:lightrag:Processing file: Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 287/287 [00:09<00:00, 30.94entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 250/250 [00:00<00:00, 9357.69relationship/s]\n",
      "INFO:lightrag:Inserting 287 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.37batch/s]\n",
      "INFO:lightrag:Inserting 250 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  12%|█▎        | 1/8 [00:01<00:11,  1.59s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.01batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt. Total tokens used: 3980624\n",
      "INFO:lightrag:Writing graph with 3006 nodes, 2553 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 3980624\n",
      "INFO:lightrag:Processed: US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt. Total tokens used: 3980624\n",
      "INFO:lightrag:[New Chunks] inserting 36 chunks\n",
      "INFO:lightrag:Inserting 36 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US912197729_f0ba5dc8-8453-3bed-b654-efaa3a856933_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:01<00:01,  1.32s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.15s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 24186, Output: 24186, Total: 4028996\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/36 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1904, Output: 56, Total: 4030956\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1987, Output: 60, Total: 4033003\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 0 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/36 [00:03<02:06,  3.62s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 171, Total: 4036274\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 268, Total: 4039641\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 323, Total: 4043064\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 256, Total: 4046419\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 364, Total: 4049882\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 354, Total: 4053334\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 532, Total: 4056965\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 528, Total: 4060592\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 523, Total: 4064214\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 738, Total: 4068051\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 557, Total: 4071707\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3298, Output: 477, Total: 4075482\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 7 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/36 [00:13<03:58,  7.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3382, Output: 421, Total: 4079285\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 15 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Updated token count - Input: 3099, Output: 706, Total: 4083090\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3490, Output: 225, Total: 4086805\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 24 entities(duplicated), 18 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 4/36 [00:13<01:32,  2.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 765, Total: 4090669\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 817, Total: 4094585\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3832, Output: 34, Total: 4098451\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 32 entities(duplicated), 25 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/36 [00:14<01:07,  2.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3394, Output: 590, Total: 4102435\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 44 entities(duplicated), 33 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/36 [00:15<00:56,  1.87s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 841, Total: 4106375\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3683, Output: 245, Total: 4110303\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 56 entities(duplicated), 39 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 7/36 [00:16<00:48,  1.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 758, Total: 4114160\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3891, Output: 177, Total: 4118228\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 73 entities(duplicated), 45 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 8/36 [00:17<00:36,  1.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3450, Output: 760, Total: 4122438\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 84 entities(duplicated), 55 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 9/36 [00:19<00:41,  1.55s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3479, Output: 505, Total: 4126422\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 93 entities(duplicated), 58 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 10/36 [00:20<00:36,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3943, Output: 350, Total: 4130715\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 108 entities(duplicated), 67 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███       | 11/36 [00:20<00:26,  1.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3864, Output: 412, Total: 4134991\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 123 entities(duplicated), 73 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting entities from chunks:  33%|███▎      | 12/36 [00:22<00:26,  1.11s/chunk]INFO:lightrag:Updated token count - Input: 3649, Output: 421, Total: 4139061\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 135 entities(duplicated), 79 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 135, Total: 4142295\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3004, Output: 444, Total: 4145743\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3658, Output: 751, Total: 4150152\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 147 entities(duplicated), 92 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▉      | 14/36 [00:22<00:15,  1.39chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 253, Total: 4153505\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3967, Output: 343, Total: 4157815\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 162 entities(duplicated), 106 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 15/36 [00:23<00:18,  1.16chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3654, Output: 702, Total: 4162171\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 175 entities(duplicated), 118 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 16/36 [00:24<00:18,  1.10chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 373, Total: 4165642\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 647, Total: 4169389\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 171, Total: 4172660\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 562, Total: 4176320\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 353, Total: 4179772\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3687, Output: 17, Total: 4183476\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 182 entities(duplicated), 125 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 17/36 [00:28<00:32,  1.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 816, Total: 4187391\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3884, Output: 698, Total: 4191973\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 203 entities(duplicated), 142 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 18/36 [00:31<00:37,  2.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 452, Total: 4195524\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3261, Output: 430, Total: 4199215\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 210 entities(duplicated), 148 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 19/36 [00:32<00:28,  1.65s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3774, Output: 420, Total: 4203409\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 222 entities(duplicated), 159 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 20/36 [00:33<00:23,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 618, Total: 4207125\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3475, Output: 523, Total: 4211123\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 237 entities(duplicated), 170 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 21/36 [00:33<00:18,  1.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 571, Total: 4214793\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3942, Output: 256, Total: 4218991\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 253 entities(duplicated), 179 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 22/36 [00:36<00:21,  1.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3298, Output: 515, Total: 4222804\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 260 entities(duplicated), 182 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  64%|██████▍   | 23/36 [00:36<00:14,  1.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 627, Total: 4226530\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3479, Output: 474, Total: 4230483\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 269 entities(duplicated), 190 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 24/36 [00:38<00:17,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 418, Total: 4234000\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3380, Output: 610, Total: 4237990\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 283 entities(duplicated), 191 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 25/36 [00:39<00:13,  1.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3753, Output: 142, Total: 4241885\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 294 entities(duplicated), 197 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 26/36 [00:42<00:17,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 436, Total: 4245420\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3743, Output: 583, Total: 4249746\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 300 entities(duplicated), 203 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 27/36 [00:43<00:14,  1.60s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 547, Total: 4253392\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3498, Output: 791, Total: 4257681\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 313 entities(duplicated), 215 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 28/36 [00:46<00:14,  1.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3578, Output: 562, Total: 4261821\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 325 entities(duplicated), 227 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 29/36 [00:46<00:10,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 618, Total: 4265537\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3697, Output: 695, Total: 4269929\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 339 entities(duplicated), 242 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 30/36 [00:47<00:07,  1.29s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 723, Total: 4273751\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3544, Output: 523, Total: 4277818\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 349 entities(duplicated), 251 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 31/36 [00:49<00:07,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1127, Total: 4282044\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3849, Output: 334, Total: 4286227\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 361 entities(duplicated), 262 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 32/36 [00:56<00:12,  3.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3673, Output: 522, Total: 4290422\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 373 entities(duplicated), 273 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  92%|█████████▏| 33/36 [00:56<00:07,  2.37s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3562, Output: 628, Total: 4294612\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 387 entities(duplicated), 276 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 34/36 [00:58<00:04,  2.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3743, Output: 973, Total: 4299328\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 408 entities(duplicated), 296 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 35/36 [01:07<00:04,  4.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4253, Output: 477, Total: 4304058\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 36 chunks, 438 entities(duplicated), 308 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 36/36 [01:09<00:00,  1.94s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/263 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 638, Output: 289, Total: 4304985\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 259/263 [00:06<00:00, 39.51entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 727, Output: 500, Total: 4306212\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 654, Output: 314, Total: 4307180\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 668, Output: 339, Total: 4308187\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1533, Output: 384, Total: 4310104\n",
      "INFO:lightrag:Processing file: Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 263/263 [00:10<00:00, 24.15entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 224/224 [00:00<00:00, 16123.63relationship/s]\n",
      "INFO:lightrag:Inserting 263 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  11%|█         | 1/9 [00:02<00:19,  2.43s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  22%|██▏       | 2/9 [00:02<00:08,  1.18s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  44%|████▍     | 4/9 [00:02<00:02,  2.11batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:03<00:00,  2.32batch/s]\n",
      "INFO:lightrag:Inserting 224 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  86%|████████▌ | 6/7 [00:02<00:00,  4.17batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:04<00:00,  1.64batch/s]\n",
      "INFO:lightrag:Finished processing Recon/AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt. Total tokens used: 4310104\n",
      "INFO:lightrag:Writing graph with 3216 nodes, 2775 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 4310104\n",
      "INFO:lightrag:Processed: AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt. Total tokens used: 4310104\n",
      "INFO:lightrag:[New Chunks] inserting 32 chunks\n",
      "INFO:lightrag:Inserting 32 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: AU004028077_19bd023f-72b0-3795-b22c-09b4f38d4e5e_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.03s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 21709, Output: 21709, Total: 4353522\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/32 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 167, Total: 4356789\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 231, Total: 4360118\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 319, Total: 4363536\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 340, Total: 4366975\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 323, Total: 4370397\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 378, Total: 4373874\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 423, Total: 4377395\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3294, Output: 253, Total: 4380942\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/32 [00:09<04:55,  9.53s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3358, Output: 232, Total: 4384532\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 582, Total: 4388213\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 515, Total: 4391827\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 618, Total: 4395543\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2818, Output: 601, Total: 4398962\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 471, Total: 4402532\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3453, Output: 360, Total: 4406345\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 26 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/32 [00:15<02:11,  4.52s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 586, Total: 4410030\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 943, Total: 4414072\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 405, Total: 4417576\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 74, Total: 4420750\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3449, Output: 546, Total: 4424745\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 38 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▎        | 4/32 [00:17<01:46,  3.80s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3641, Output: 338, Total: 4428724\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 48 entities(duplicated), 25 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/32 [00:18<01:15,  2.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1037, Total: 4432860\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3201, Output: 66, Total: 4436127\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 48 entities(duplicated), 25 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 6/32 [00:19<00:58,  2.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3504, Output: 484, Total: 4440115\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 60 entities(duplicated), 31 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 7/32 [00:19<00:43,  1.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3708, Output: 407, Total: 4444230\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 75 entities(duplicated), 36 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 8/32 [00:20<00:29,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3548, Output: 716, Total: 4448494\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 87 entities(duplicated), 45 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 9/32 [00:21<00:31,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1171, Total: 4452764\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3452, Output: 332, Total: 4456548\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 103 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 10/32 [00:22<00:26,  1.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3743, Output: 477, Total: 4460768\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 117 entities(duplicated), 62 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 11/32 [00:23<00:25,  1.22s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3712, Output: 444, Total: 4464924\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 134 entities(duplicated), 68 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 12/32 [00:24<00:21,  1.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3466, Output: 926, Total: 4469316\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 146 entities(duplicated), 79 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 13/32 [00:25<00:20,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4069, Output: 379, Total: 4473764\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 163 entities(duplicated), 87 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 14/32 [00:26<00:17,  1.05chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3597, Output: 632, Total: 4477993\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 178 entities(duplicated), 101 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 15/32 [00:27<00:18,  1.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 975, Total: 4482067\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3535, Output: 659, Total: 4486261\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 189 entities(duplicated), 111 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 16/32 [00:28<00:17,  1.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4297, Output: 458, Total: 4491016\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 207 entities(duplicated), 120 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 17/32 [00:30<00:17,  1.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 27, Total: 4494142\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4163, Output: 688, Total: 4498993\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 228 entities(duplicated), 141 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▋    | 18/32 [00:31<00:15,  1.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 350, Total: 4502442\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 663, Total: 4506204\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3153, Output: 50, Total: 4509407\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 228 entities(duplicated), 141 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 19/32 [00:32<00:16,  1.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 699, Total: 4513205\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 543, Total: 4516847\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 622, Total: 4520567\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 423, Total: 4524088\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 713, Total: 4527900\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 557, Total: 4531556\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 697, Total: 4535352\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 741, Total: 4539193\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 361, Total: 4542653\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 540, Total: 4546292\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3789, Output: 452, Total: 4550533\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 245 entities(duplicated), 147 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▎   | 20/32 [00:40<00:37,  3.11s/chunk]INFO:lightrag:Updated token count - Input: 3476, Output: 428, Total: 4554437\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 255 entities(duplicated), 154 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3833, Output: 456, Total: 4558726\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 269 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 22/32 [00:41<00:18,  1.89s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3554, Output: 366, Total: 4562646\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 284 entities(duplicated), 170 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 23/32 [00:42<00:16,  1.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3672, Output: 337, Total: 4566655\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 297 entities(duplicated), 175 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 24/32 [00:46<00:19,  2.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3487, Output: 574, Total: 4570716\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 305 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 25/32 [00:47<00:12,  1.81s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3669, Output: 742, Total: 4575127\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 323 entities(duplicated), 196 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3754, Output: 428, Total: 4579309\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 341 entities(duplicated), 201 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 27/32 [00:47<00:05,  1.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3830, Output: 616, Total: 4583755\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 356 entities(duplicated), 216 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 28/32 [00:47<00:03,  1.06chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3683, Output: 579, Total: 4588017\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 368 entities(duplicated), 226 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 29/32 [00:49<00:03,  1.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3848, Output: 688, Total: 4592553\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 390 entities(duplicated), 232 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 30/32 [00:50<00:02,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3876, Output: 813, Total: 4597242\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 406 entities(duplicated), 247 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 31/32 [00:55<00:02,  2.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4101, Output: 764, Total: 4602107\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 424 entities(duplicated), 264 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 32/32 [01:04<00:00,  2.01s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/258 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 732, Output: 322, Total: 4603161\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 254/258 [00:05<00:00, 43.32entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 680, Output: 276, Total: 4604117\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 732, Output: 378, Total: 4605227\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 852, Output: 380, Total: 4606459\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 737, Output: 500, Total: 4607696\n",
      "INFO:lightrag:Processing file: Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 258/258 [00:11<00:00, 22.78entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 226/226 [00:00<00:00, 15373.97relationship/s]\n",
      "INFO:lightrag:Inserting 258 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  11%|█         | 1/9 [00:01<00:09,  1.19s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.66batch/s]\n",
      "INFO:lightrag:Inserting 226 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  12%|█▎        | 1/8 [00:00<00:06,  1.02batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 4/8 [00:01<00:01,  3.20batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  2.94batch/s]\n",
      "INFO:lightrag:Finished processing Recon/SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt. Total tokens used: 4607696\n",
      "INFO:lightrag:Writing graph with 3403 nodes, 2991 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 4607696\n",
      "INFO:lightrag:Processed: SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt. Total tokens used: 4607696\n",
      "INFO:lightrag:[New Chunks] inserting 32 chunks\n",
      "INFO:lightrag:Inserting 32 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: SG201017488D_73f9a55a-2165-3a63-9a88-745537b1f513_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.51s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 22866, Output: 22866, Total: 4653428\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/32 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 259, Total: 4656786\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 205, Total: 4660090\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2637, Output: 276, Total: 4663003\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 302, Total: 4666405\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 460, Total: 4669964\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 494, Total: 4673557\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 321, Total: 4676976\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 331, Total: 4680406\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2940, Output: 200, Total: 4683546\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 9 entities(duplicated), 3 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/32 [00:09<04:56,  9.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 455, Total: 4687100\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 370, Total: 4690568\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3385, Output: 414, Total: 4694367\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/32 [00:10<02:22,  4.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 456, Total: 4697922\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 424, Total: 4701446\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 173, Total: 4704718\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3446, Output: 246, Total: 4708410\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 27 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3495, Output: 282, Total: 4712187\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 34 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/32 [00:15<02:17,  4.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3586, Output: 545, Total: 4716318\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 50 entities(duplicated), 32 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/32 [00:16<01:01,  2.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3331, Output: 635, Total: 4720284\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 70 entities(duplicated), 37 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 769, Total: 4724151\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 841, Total: 4728091\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3429, Output: 559, Total: 4732079\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 83 entities(duplicated), 43 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 7/32 [00:20<00:56,  2.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3581, Output: 453, Total: 4736113\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 95 entities(duplicated), 52 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3620, Output: 385, Total: 4740118\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 112 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 9/32 [00:21<00:34,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 413, Total: 4743630\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 891, Total: 4747620\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 221, Total: 4750940\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3582, Output: 626, Total: 4755148\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 125 entities(duplicated), 69 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 10/32 [00:24<00:41,  1.89s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3551, Output: 311, Total: 4759010\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 133 entities(duplicated), 77 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 11/32 [00:25<00:31,  1.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 465, Total: 4762573\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1090, Total: 4766762\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3457, Output: 506, Total: 4770725\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 144 entities(duplicated), 85 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 12/32 [00:26<00:29,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 727, Total: 4774551\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3967, Output: 313, Total: 4778831\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 167 entities(duplicated), 90 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 13/32 [00:27<00:24,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 136, Total: 4782067\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3299, Output: 1000, Total: 4786366\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 183 entities(duplicated), 101 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 14/32 [00:28<00:24,  1.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 780, Total: 4790244\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 556, Total: 4793900\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3894, Output: 393, Total: 4798187\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 196 entities(duplicated), 113 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 15/32 [00:33<00:37,  2.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3262, Output: 205, Total: 4801654\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 202 entities(duplicated), 115 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 16/32 [00:33<00:27,  1.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3347, Output: 490, Total: 4805491\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 217 entities(duplicated), 117 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 17/32 [00:34<00:20,  1.35s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4016, Output: 394, Total: 4809901\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 238 entities(duplicated), 126 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▋    | 18/32 [00:34<00:16,  1.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3590, Output: 618, Total: 4814109\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 251 entities(duplicated), 138 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3853, Output: 514, Total: 4818476\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 269 entities(duplicated), 152 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 19/32 [00:35<00:12,  1.06chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 480, Total: 4822055\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3683, Output: 225, Total: 4825963\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 278 entities(duplicated), 160 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 21/32 [00:37<00:10,  1.02chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3606, Output: 200, Total: 4829769\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 290 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 22/32 [00:39<00:13,  1.37s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3539, Output: 573, Total: 4833881\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 308 entities(duplicated), 168 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 23/32 [00:40<00:10,  1.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 594, Total: 4837574\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 370, Total: 4841043\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1020, Total: 4845162\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4216, Output: 654, Total: 4850032\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 327 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 24/32 [00:43<00:12,  1.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3720, Output: 20, Total: 4853772\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 334 entities(duplicated), 191 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 25/32 [00:43<00:09,  1.32s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 770, Total: 4857641\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 671, Total: 4861410\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4146, Output: 107, Total: 4865663\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 345 entities(duplicated), 201 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████▏ | 26/32 [00:47<00:11,  1.94s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 697, Total: 4869459\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3905, Output: 757, Total: 4874121\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 369 entities(duplicated), 209 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 27/32 [00:50<00:10,  2.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3496, Output: 424, Total: 4878041\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 379 entities(duplicated), 218 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 28/32 [00:52<00:09,  2.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3823, Output: 244, Total: 4882108\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 392 entities(duplicated), 225 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 29/32 [00:52<00:05,  1.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3796, Output: 339, Total: 4886243\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 403 entities(duplicated), 234 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 30/32 [00:54<00:03,  1.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 871, Total: 4890213\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3896, Output: 783, Total: 4894892\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 405 entities(duplicated), 234 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 31/32 [01:01<00:03,  3.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3997, Output: 411, Total: 4899300\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 421 entities(duplicated), 249 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 32/32 [01:02<00:00,  1.96s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/294 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1294, Output: 394, Total: 4900988\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 292/294 [00:07<00:00, 39.95entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 632, Output: 407, Total: 4902027\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 668, Output: 500, Total: 4903195\n",
      "INFO:lightrag:Processing file: Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 294/294 [00:10<00:00, 27.48entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 210/210 [00:00<00:00, 9569.07relationship/s]\n",
      "INFO:lightrag:Inserting 294 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/10 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  10%|█         | 1/10 [00:00<00:07,  1.15batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  20%|██        | 2/10 [00:01<00:05,  1.52batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:02<00:00,  4.18batch/s]\n",
      "INFO:lightrag:Inserting 210 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  86%|████████▌ | 6/7 [00:02<00:00,  2.40batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:06<00:00,  1.08batch/s]\n",
      "INFO:lightrag:Finished processing Recon/GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt. Total tokens used: 4903195\n",
      "INFO:lightrag:Writing graph with 3635 nodes, 3201 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 4903195\n",
      "INFO:lightrag:Processed: GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt. Total tokens used: 4903195\n",
      "INFO:lightrag:[New Chunks] inserting 33 chunks\n",
      "INFO:lightrag:Inserting 33 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: GBSC036386_b80d267a-6fa2-3e4d-b318-bc7e1f8f73b6_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.09batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:03<00:00,  1.58s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 23076, Output: 23076, Total: 4949347\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/33 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2172, Output: 239, Total: 4951758\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 370, Total: 4955226\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 627, Total: 4958952\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 402, Total: 4962452\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 395, Total: 4965945\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 439, Total: 4969483\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 506, Total: 4973088\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2438, Output: 223, Total: 4975749\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/33 [00:12<06:44, 12.65s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 507, Total: 4979355\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 787, Total: 4983239\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 576, Total: 4986914\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 573, Total: 4990585\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 598, Total: 4994282\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1042, Total: 4998423\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3520, Output: 218, Total: 5002161\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/33 [00:16<03:56,  7.64s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3565, Output: 244, Total: 5005970\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 30 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/33 [00:17<02:16,  4.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 756, Total: 5009825\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 225, Total: 5013149\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3527, Output: 312, Total: 5016988\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 38 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▏        | 4/33 [00:18<01:32,  3.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 63, Total: 5020150\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3495, Output: 403, Total: 5024048\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 52 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  15%|█▌        | 5/33 [00:19<01:02,  2.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3725, Output: 148, Total: 5027921\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 64 entities(duplicated), 24 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3911, Output: 307, Total: 5032139\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 81 entities(duplicated), 31 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  21%|██        | 7/33 [00:21<00:43,  1.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3632, Output: 434, Total: 5036205\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 98 entities(duplicated), 36 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  24%|██▍       | 8/33 [00:21<00:31,  1.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4168, Output: 375, Total: 5040748\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 108 entities(duplicated), 47 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  27%|██▋       | 9/33 [00:23<00:33,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3351, Output: 295, Total: 5044394\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 109 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  30%|███       | 10/33 [00:25<00:37,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3882, Output: 307, Total: 5048583\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 125 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 11/33 [00:27<00:35,  1.62s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 408, Total: 5052090\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3753, Output: 858, Total: 5056701\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 143 entities(duplicated), 74 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▋      | 12/33 [00:28<00:29,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 388, Total: 5060188\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3702, Output: 614, Total: 5064504\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 161 entities(duplicated), 87 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▉      | 13/33 [00:29<00:28,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 406, Total: 5068010\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1284, Total: 5072393\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 182, Total: 5075674\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3633, Output: 774, Total: 5080081\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 177 entities(duplicated), 98 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 14/33 [00:32<00:35,  1.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3189, Output: 570, Total: 5083840\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 192 entities(duplicated), 98 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  45%|████▌     | 15/33 [00:32<00:25,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3698, Output: 727, Total: 5088265\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 209 entities(duplicated), 111 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 1405, Total: 5092768\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "Extracting entities from chunks:  48%|████▊     | 16/33 [00:33<00:17,  1.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 490, Total: 5096356\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3514, Output: 221, Total: 5100091\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 215 entities(duplicated), 116 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  52%|█████▏    | 17/33 [00:34<00:17,  1.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 580, Total: 5103770\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 522, Total: 5107391\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 370, Total: 5110860\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4530, Output: 307, Total: 5115697\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 241 entities(duplicated), 133 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  55%|█████▍    | 18/33 [00:38<00:28,  1.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 744, Total: 5119539\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3536, Output: 474, Total: 5123549\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 246 entities(duplicated), 142 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 19/33 [00:40<00:29,  2.11s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 279, Total: 5126928\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 486, Total: 5130513\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 637, Total: 5134248\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3533, Output: 476, Total: 5138257\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 255 entities(duplicated), 150 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3615, Output: 289, Total: 5142161\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 268 entities(duplicated), 155 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 20/33 [00:42<00:25,  1.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3496, Output: 352, Total: 5146009\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 280 entities(duplicated), 158 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 22/33 [00:47<00:25,  2.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3762, Output: 242, Total: 5150013\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 294 entities(duplicated), 165 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  70%|██████▉   | 23/33 [00:48<00:18,  1.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 569, Total: 5153681\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3308, Output: 571, Total: 5157560\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 302 entities(duplicated), 172 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  73%|███████▎  | 24/33 [00:49<00:15,  1.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4410, Output: 656, Total: 5162626\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 327 entities(duplicated), 196 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  76%|███████▌  | 25/33 [00:50<00:11,  1.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3406, Output: 326, Total: 5166358\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 334 entities(duplicated), 202 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  79%|███████▉  | 26/33 [00:50<00:08,  1.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 662, Total: 5170119\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3706, Output: 686, Total: 5174511\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 346 entities(duplicated), 214 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  82%|████████▏ | 27/33 [00:54<00:11,  1.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3869, Output: 552, Total: 5178932\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 356 entities(duplicated), 222 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  85%|████████▍ | 28/33 [00:55<00:08,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3695, Output: 359, Total: 5182986\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 367 entities(duplicated), 231 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 29/33 [00:56<00:05,  1.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 889, Total: 5186974\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3648, Output: 900, Total: 5191522\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 383 entities(duplicated), 246 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 30/33 [00:58<00:04,  1.64s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4015, Output: 186, Total: 5195723\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 396 entities(duplicated), 255 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 31/33 [01:01<00:03,  1.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3612, Output: 786, Total: 5200121\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 410 entities(duplicated), 268 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 32/33 [01:01<00:01,  1.53s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3788, Output: 640, Total: 5204549\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 424 entities(duplicated), 281 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 33/33 [01:02<00:00,  1.89s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/256 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 670, Output: 164, Total: 5205383\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "Inserting entities:  97%|█████████▋| 249/256 [00:04<00:00, 62.17entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 633, Output: 191, Total: 5206207\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 742, Output: 347, Total: 5207296\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 694, Output: 385, Total: 5208375\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 661, Output: 399, Total: 5209435\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 668, Output: 395, Total: 5210498\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1485, Output: 468, Total: 5212451\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 713, Output: 394, Total: 5213558\n",
      "INFO:lightrag:Processing file: Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 256/256 [00:19<00:00, 13.41entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 194/194 [00:00<00:00, 11694.38relationship/s]\n",
      "INFO:lightrag:Inserting 256 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  12%|█▎        | 1/8 [00:01<00:10,  1.57s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.11batch/s]\n",
      "INFO:lightrag:Inserting 194 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  14%|█▍        | 1/7 [00:00<00:04,  1.36batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.27batch/s]\n",
      "INFO:lightrag:Finished processing Recon/FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt. Total tokens used: 5213558\n",
      "INFO:lightrag:Writing graph with 3834 nodes, 3394 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 5213558\n",
      "INFO:lightrag:Processed: FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt. Total tokens used: 5213558\n",
      "INFO:lightrag:[New Chunks] inserting 32 chunks\n",
      "INFO:lightrag:Inserting 32 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: FR811891670_216d74d0-dded-390d-b829-f281d5faf540_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:02<00:00,  2.24s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 21847, Output: 21847, Total: 5257252\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/32 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 215, Total: 5260566\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 325, Total: 5263989\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 342, Total: 5267431\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 271, Total: 5270802\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 363, Total: 5274264\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 404, Total: 5277767\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 518, Total: 5281384\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 574, Total: 5285057\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2145, Output: 305, Total: 5287507\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 410, Total: 5291016\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3469, Output: 280, Total: 5294765\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/32 [00:11<06:04, 11.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 427, Total: 5298291\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 630, Total: 5302020\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2477, Output: 228, Total: 5304725\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 15 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/32 [00:14<03:14,  6.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3644, Output: 323, Total: 5308692\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 30 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/32 [00:15<01:53,  3.91s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 937, Total: 5312728\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3450, Output: 557, Total: 5316735\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 43 entities(duplicated), 27 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▎        | 4/32 [00:16<01:16,  2.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 919, Total: 5320753\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3489, Output: 411, Total: 5324653\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 54 entities(duplicated), 36 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/32 [00:17<01:00,  2.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3341, Output: 454, Total: 5328448\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 63 entities(duplicated), 43 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3398, Output: 668, Total: 5332514\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 74 entities(duplicated), 53 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 7/32 [00:18<00:31,  1.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 371, Total: 5335984\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 247, Total: 5339331\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3756, Output: 501, Total: 5343588\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 95 entities(duplicated), 58 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 8/32 [00:21<00:44,  1.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3530, Output: 761, Total: 5347879\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 108 entities(duplicated), 70 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 329, Total: 5351307\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4063, Output: 324, Total: 5355694\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 127 entities(duplicated), 78 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 10/32 [00:22<00:28,  1.29s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3700, Output: 720, Total: 5360114\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 141 entities(duplicated), 91 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 11/32 [00:26<00:37,  1.78s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 465, Total: 5363678\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 532, Total: 5367309\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3553, Output: 758, Total: 5371620\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 155 entities(duplicated), 102 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 12/32 [00:28<00:39,  1.98s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 339, Total: 5375058\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 912, Total: 5379069\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4045, Output: 513, Total: 5383627\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 177 entities(duplicated), 112 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 13/32 [00:29<00:32,  1.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3536, Output: 465, Total: 5387628\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 182 entities(duplicated), 116 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 14/32 [00:31<00:29,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 846, Total: 5391573\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3455, Output: 644, Total: 5395672\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 195 entities(duplicated), 125 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 15/32 [00:34<00:33,  1.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 814, Total: 5399585\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 972, Total: 5403657\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 556, Total: 5407311\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3374, Output: 622, Total: 5411307\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 207 entities(duplicated), 133 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 16/32 [00:37<00:37,  2.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 271, Total: 5414677\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 681, Total: 5418457\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3497, Output: 700, Total: 5422654\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 222 entities(duplicated), 145 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 17/32 [00:38<00:29,  2.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4038, Output: 400, Total: 5427092\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 242 entities(duplicated), 155 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▋    | 18/32 [00:40<00:28,  2.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 557, Total: 5430748\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3591, Output: 561, Total: 5434900\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 255 entities(duplicated), 165 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 19/32 [00:41<00:21,  1.62s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3658, Output: 537, Total: 5439095\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 270 entities(duplicated), 180 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 762, Total: 5442955\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 814, Total: 5446868\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3465, Output: 561, Total: 5450894\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 287 entities(duplicated), 183 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 21/32 [00:43<00:15,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4099, Output: 439, Total: 5455432\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 308 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 22/32 [00:45<00:14,  1.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3940, Output: 553, Total: 5459925\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 324 entities(duplicated), 209 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 23/32 [00:45<00:10,  1.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3972, Output: 794, Total: 5464691\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 343 entities(duplicated), 223 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 24/32 [00:48<00:12,  1.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3683, Output: 407, Total: 5468781\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 359 entities(duplicated), 229 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 25/32 [00:48<00:08,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3887, Output: 345, Total: 5473013\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 379 entities(duplicated), 239 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████▏ | 26/32 [00:48<00:05,  1.03chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3940, Output: 374, Total: 5477327\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 398 entities(duplicated), 249 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 27/32 [00:48<00:03,  1.36chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3807, Output: 615, Total: 5481749\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 414 entities(duplicated), 263 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 28/32 [00:49<00:02,  1.78chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3397, Output: 344, Total: 5485490\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 426 entities(duplicated), 265 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 29/32 [00:49<00:01,  2.23chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 467, Total: 5489057\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3681, Output: 766, Total: 5493504\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 445 entities(duplicated), 278 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 30/32 [00:53<00:03,  1.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 1028, Total: 5497632\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3594, Output: 272, Total: 5501498\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 454 entities(duplicated), 286 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 31/32 [00:55<00:01,  1.61s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4155, Output: 707, Total: 5506360\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 469 entities(duplicated), 308 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 32/32 [01:05<00:00,  2.04s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/260 [00:00<00:26,  9.69entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 637, Output: 171, Total: 5507168\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "Inserting entities:  97%|█████████▋| 252/260 [00:04<00:00, 53.89entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 972, Output: 293, Total: 5508433\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 635, Output: 310, Total: 5509378\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 772, Output: 360, Total: 5510510\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 779, Output: 363, Total: 5511652\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 256/260 [00:08<00:00, 26.28entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 713, Output: 472, Total: 5512837\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 686, Output: 306, Total: 5513829\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 820, Output: 430, Total: 5515079\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 259/260 [00:13<00:00, 12.38entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 730, Output: 500, Total: 5516309\n",
      "INFO:lightrag:Processing file: Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 260/260 [00:15<00:00, 16.71entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 223/223 [00:00<00:00, 27082.75relationship/s]\n",
      "INFO:lightrag:Inserting 260 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.91batch/s]\n",
      "INFO:lightrag:Inserting 223 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  14%|█▍        | 1/7 [00:01<00:07,  1.23s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.28batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt. Total tokens used: 5516309\n",
      "INFO:lightrag:Writing graph with 4011 nodes, 3614 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 5516309\n",
      "INFO:lightrag:Processed: US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt. Total tokens used: 5516309\n",
      "INFO:lightrag:[New Chunks] inserting 31 chunks\n",
      "INFO:lightrag:Inserting 31 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US366477695L_2cd488e3-f200-3506-8385-987e14d14cb8_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.92s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 21370, Output: 21370, Total: 5559049\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/31 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 109, Total: 5562257\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2662, Output: 269, Total: 5565188\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 417, Total: 5568704\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 382, Total: 5572185\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 451, Total: 5575735\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 431, Total: 5579265\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3557, Output: 35, Total: 5582857\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 5 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/31 [00:12<06:18, 12.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 586, Total: 5586542\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2958, Output: 224, Total: 5589724\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 13 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/31 [00:14<03:04,  6.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 595, Total: 5593418\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 357, Total: 5596873\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 647, Total: 5600619\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 709, Total: 5604426\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 506, Total: 5608031\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 678, Total: 5611808\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 703, Total: 5615610\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 792, Total: 5619500\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3235, Output: 686, Total: 5623421\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 24 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  10%|▉         | 3/31 [00:21<03:09,  6.78s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3543, Output: 486, Total: 5627450\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 45 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  13%|█▎        | 4/31 [00:23<02:05,  4.67s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 993, Total: 5631541\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3508, Output: 866, Total: 5635915\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 65 entities(duplicated), 30 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 5/31 [00:25<01:39,  3.83s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 194, Total: 5639208\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3577, Output: 364, Total: 5643149\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 74 entities(duplicated), 34 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 6/31 [00:26<01:10,  2.83s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3482, Output: 506, Total: 5647137\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 94 entities(duplicated), 37 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  23%|██▎       | 7/31 [00:26<00:47,  1.99s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3773, Output: 601, Total: 5651511\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 109 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▌       | 8/31 [00:28<00:40,  1.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3721, Output: 558, Total: 5655790\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 125 entities(duplicated), 65 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 896, Total: 5659785\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3632, Output: 413, Total: 5663830\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 143 entities(duplicated), 71 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 10/31 [00:29<00:27,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3834, Output: 554, Total: 5668218\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 168 entities(duplicated), 79 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  35%|███▌      | 11/31 [00:31<00:27,  1.35s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3917, Output: 620, Total: 5672755\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 196 entities(duplicated), 89 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▊      | 12/31 [00:31<00:22,  1.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3804, Output: 526, Total: 5677085\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 210 entities(duplicated), 100 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 13/31 [00:32<00:16,  1.07chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 485, Total: 5680668\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 281, Total: 5684048\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3829, Output: 647, Total: 5688524\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 228 entities(duplicated), 115 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  45%|████▌     | 14/31 [00:32<00:14,  1.16chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 739, Total: 5692362\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3610, Output: 39, Total: 5696011\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 234 entities(duplicated), 120 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  48%|████▊     | 15/31 [00:33<00:14,  1.07chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 441, Total: 5699551\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 426, Total: 5703077\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 145, Total: 5706322\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4118, Output: 433, Total: 5710873\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 244 entities(duplicated), 128 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  52%|█████▏    | 16/31 [00:35<00:18,  1.25s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3712, Output: 743, Total: 5715328\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 258 entities(duplicated), 141 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  55%|█████▍    | 17/31 [00:38<00:21,  1.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4022, Output: 557, Total: 5719907\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 276 entities(duplicated), 158 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3320, Output: 538, Total: 5723765\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 285 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████▏   | 19/31 [00:38<00:10,  1.12chunk/s]INFO:lightrag:Updated token count - Input: 3099, Output: 640, Total: 5727504\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 344, Total: 5730947\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 572, Total: 5734618\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 422, Total: 5738139\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3698, Output: 29, Total: 5741866\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 288 entities(duplicated), 172 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  65%|██████▍   | 20/31 [00:41<00:14,  1.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 397, Total: 5745362\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3553, Output: 355, Total: 5749270\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 298 entities(duplicated), 179 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 21/31 [00:42<00:13,  1.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3407, Output: 592, Total: 5753269\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 312 entities(duplicated), 187 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████   | 22/31 [00:44<00:13,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3272, Output: 406, Total: 5756947\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 321 entities(duplicated), 192 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▍  | 23/31 [00:45<00:10,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3567, Output: 451, Total: 5760965\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 336 entities(duplicated), 196 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3548, Output: 349, Total: 5764862\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 348 entities(duplicated), 199 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 25/31 [00:47<00:07,  1.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 767, Total: 5768728\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3865, Output: 781, Total: 5773374\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 359 entities(duplicated), 211 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 26/31 [00:49<00:07,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3766, Output: 473, Total: 5777613\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 375 entities(duplicated), 226 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  87%|████████▋ | 27/31 [00:51<00:05,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3523, Output: 504, Total: 5781640\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 385 entities(duplicated), 236 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  90%|█████████ | 28/31 [00:52<00:04,  1.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1145, Total: 5785884\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3470, Output: 465, Total: 5789819\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 397 entities(duplicated), 239 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▎| 29/31 [01:05<00:09,  4.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3893, Output: 853, Total: 5794565\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 418 entities(duplicated), 257 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 30/31 [01:10<00:04,  4.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4271, Output: 712, Total: 5799548\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 449 entities(duplicated), 265 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 31/31 [01:12<00:00,  2.32s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/293 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 682, Output: 334, Total: 5800564\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 288/293 [00:07<00:00, 39.66entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 832, Output: 391, Total: 5801787\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1254, Output: 386, Total: 5803427\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 700, Output: 357, Total: 5804484\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 722, Output: 500, Total: 5805706\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 292/293 [00:10<00:00, 25.26entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 698, Output: 400, Total: 5806804\n",
      "INFO:lightrag:Processing file: Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 293/293 [00:11<00:00, 25.32entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 213/213 [00:00<00:00, 15334.74relationship/s]\n",
      "INFO:lightrag:Inserting 293 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/10 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  10%|█         | 1/10 [00:01<00:11,  1.27s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  70%|███████   | 7/10 [00:02<00:00,  5.94batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:02<00:00,  4.30batch/s]\n",
      "INFO:lightrag:Inserting 213 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.50batch/s]\n",
      "INFO:lightrag:Finished processing Recon/RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt. Total tokens used: 5806804\n",
      "INFO:lightrag:Writing graph with 4227 nodes, 3823 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 5806804\n",
      "INFO:lightrag:Processed: RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt. Total tokens used: 5806804\n",
      "INFO:lightrag:[New Chunks] inserting 32 chunks\n",
      "INFO:lightrag:Inserting 32 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: RU82118850_e02df5bb-ae76-3cf9-970d-f5c17ff6552a_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.94s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 21002, Output: 21002, Total: 5848808\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/32 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 116, Total: 5852023\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 252, Total: 5855375\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 279, Total: 5858753\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 311, Total: 5862163\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 330, Total: 5865590\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 408, Total: 5869097\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 544, Total: 5872739\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 463, Total: 5876301\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 511, Total: 5879910\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 531, Total: 5883539\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 649, Total: 5887287\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 550, Total: 5890935\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 687, Total: 5894721\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3379, Output: 431, Total: 5898531\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 13 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/32 [00:12<06:17, 12.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3437, Output: 313, Total: 5902281\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 23 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▋         | 2/32 [00:12<02:44,  5.47s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3242, Output: 577, Total: 5906100\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 32 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/32 [00:13<01:36,  3.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 808, Total: 5910005\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3669, Output: 240, Total: 5913914\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 43 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▎        | 4/32 [00:14<00:59,  2.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3534, Output: 332, Total: 5917780\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 56 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3454, Output: 495, Total: 5921729\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 67 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 6/32 [00:15<00:34,  1.32s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 810, Total: 5925636\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3589, Output: 315, Total: 5929540\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 76 entities(duplicated), 34 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 7/32 [00:15<00:25,  1.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3656, Output: 322, Total: 5933518\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 87 entities(duplicated), 41 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 8/32 [00:15<00:19,  1.23chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3812, Output: 234, Total: 5937564\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 99 entities(duplicated), 48 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 9/32 [00:16<00:20,  1.12chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3636, Output: 239, Total: 5941439\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 110 entities(duplicated), 53 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 10/32 [00:17<00:17,  1.25chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3405, Output: 596, Total: 5945440\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 120 entities(duplicated), 60 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3675, Output: 354, Total: 5949469\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 136 entities(duplicated), 66 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 12/32 [00:18<00:12,  1.57chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3932, Output: 222, Total: 5953623\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 150 entities(duplicated), 76 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 187, Total: 5956910\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 610, Total: 5960619\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 371, Total: 5964090\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 222, Total: 5967410\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 387, Total: 5970897\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 154, Total: 5974150\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3775, Output: 502, Total: 5978427\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 163 entities(duplicated), 82 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 14/32 [00:22<00:21,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 514, Total: 5982040\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 360, Total: 5985499\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 576, Total: 5989174\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3934, Output: 560, Total: 5993668\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 175 entities(duplicated), 93 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 15/32 [00:23<00:21,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3498, Output: 303, Total: 5997469\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 180 entities(duplicated), 99 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 795, Total: 6001363\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3702, Output: 18, Total: 6005083\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 187 entities(duplicated), 104 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 17/32 [00:25<00:15,  1.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 426, Total: 6008608\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3736, Output: 362, Total: 6012706\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 197 entities(duplicated), 113 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▋    | 18/32 [00:25<00:13,  1.06chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3514, Output: 268, Total: 6016488\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 208 entities(duplicated), 118 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 19/32 [00:26<00:10,  1.30chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 157, Total: 6019744\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3314, Output: 631, Total: 6023689\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 217 entities(duplicated), 126 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▎   | 20/32 [00:26<00:09,  1.23chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2478, Output: 757, Total: 6026924\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 292, Total: 6030316\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 676, Total: 6034091\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3921, Output: 410, Total: 6038422\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 230 entities(duplicated), 137 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 21/32 [00:30<00:16,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3640, Output: 437, Total: 6042499\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 246 entities(duplicated), 142 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 22/32 [00:31<00:12,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3280, Output: 513, Total: 6046292\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 254 entities(duplicated), 149 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 23/32 [00:31<00:09,  1.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3283, Output: 375, Total: 6049950\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 260 entities(duplicated), 154 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 24/32 [00:31<00:05,  1.34chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3486, Output: 369, Total: 6053805\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 275 entities(duplicated), 158 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 25/32 [00:31<00:04,  1.66chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3347, Output: 629, Total: 6057781\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 283 entities(duplicated), 168 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████▏ | 26/32 [00:31<00:02,  2.06chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3262, Output: 317, Total: 6061360\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 300 entities(duplicated), 178 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 27/32 [00:32<00:02,  2.00chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 439, Total: 6064896\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 1002, Total: 6068995\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3802, Output: 401, Total: 6073198\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 315 entities(duplicated), 183 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 28/32 [00:35<00:04,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3419, Output: 371, Total: 6076988\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 322 entities(duplicated), 189 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 29/32 [00:36<00:03,  1.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3552, Output: 801, Total: 6081341\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 337 entities(duplicated), 200 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 30/32 [00:41<00:04,  2.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3563, Output: 483, Total: 6085387\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 347 entities(duplicated), 209 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 31/32 [00:44<00:02,  2.71s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4126, Output: 409, Total: 6089922\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 367 entities(duplicated), 220 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 32/32 [00:50<00:00,  1.57s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/223 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 709, Output: 237, Total: 6090868\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 218/223 [00:05<00:00, 41.92entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 727, Output: 292, Total: 6091887\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 768, Output: 371, Total: 6093026\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 705, Output: 455, Total: 6094186\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 663, Output: 500, Total: 6095349\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 619, Output: 210, Total: 6096178\n",
      "INFO:lightrag:Processing file: Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 223/223 [00:16<00:00, 13.70entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 185/185 [00:00<00:00, 20984.00relationship/s]\n",
      "INFO:lightrag:Inserting 223 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:01<00:00,  3.53batch/s]\n",
      "INFO:lightrag:Inserting 185 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/6 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  83%|████████▎ | 5/6 [00:01<00:00,  4.08batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:05<00:00,  1.20batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt. Total tokens used: 6096178\n",
      "INFO:lightrag:Writing graph with 4383 nodes, 4005 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 6096178\n",
      "INFO:lightrag:Processed: US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt. Total tokens used: 6096178\n",
      "INFO:lightrag:[New Chunks] inserting 35 chunks\n",
      "INFO:lightrag:Inserting 35 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US870442441_9fafbe23-2fda-3798-b376-89acc47ae8aa_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:01<00:01,  1.02s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.12batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 24780, Output: 24780, Total: 6145738\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/35 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2366, Output: 267, Total: 6148371\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 376, Total: 6151846\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 465, Total: 6155410\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 490, Total: 6158999\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 484, Total: 6162580\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 412, Total: 6166090\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 504, Total: 6169694\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 510, Total: 6173303\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3591, Output: 204, Total: 6177098\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/35 [00:11<06:46, 11.95s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 656, Total: 6180852\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 542, Total: 6184493\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 671, Total: 6188262\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3796, Output: 28, Total: 6192086\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/35 [00:14<03:41,  6.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 742, Total: 6195927\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 601, Total: 6199627\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2660, Output: 498, Total: 6202785\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 28 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▊         | 3/35 [00:15<02:03,  3.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 641, Total: 6206525\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3537, Output: 341, Total: 6210403\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 42 entities(duplicated), 23 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█▏        | 4/35 [00:17<01:33,  3.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 786, Total: 6214288\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 755, Total: 6218142\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3636, Output: 274, Total: 6222052\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 55 entities(duplicated), 27 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/35 [00:17<01:03,  2.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3502, Output: 483, Total: 6226037\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 64 entities(duplicated), 35 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/35 [00:18<00:50,  1.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3616, Output: 499, Total: 6230152\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 81 entities(duplicated), 39 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  20%|██        | 7/35 [00:19<00:41,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 404, Total: 6233655\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3608, Output: 565, Total: 6237828\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 92 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  23%|██▎       | 8/35 [00:20<00:38,  1.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3868, Output: 212, Total: 6241908\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 106 entities(duplicated), 56 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▌       | 9/35 [00:21<00:32,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3881, Output: 264, Total: 6246053\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 118 entities(duplicated), 62 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  29%|██▊       | 10/35 [00:21<00:22,  1.09chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3668, Output: 443, Total: 6250164\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 133 entities(duplicated), 62 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 11/35 [00:23<00:24,  1.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 422, Total: 6253685\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3631, Output: 520, Total: 6257836\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 145 entities(duplicated), 73 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 12/35 [00:25<00:30,  1.33s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 196, Total: 6261130\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 766, Total: 6264995\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 328, Total: 6268422\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3781, Output: 500, Total: 6272703\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 160 entities(duplicated), 86 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  37%|███▋      | 13/35 [00:27<00:34,  1.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3912, Output: 513, Total: 6277128\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 174 entities(duplicated), 101 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  40%|████      | 14/35 [00:28<00:31,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3530, Output: 351, Total: 6281009\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 185 entities(duplicated), 104 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  43%|████▎     | 15/35 [00:28<00:22,  1.11s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3727, Output: 533, Total: 6285269\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 199 entities(duplicated), 114 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 779, Total: 6289146\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 107, Total: 6292352\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 431, Total: 6295882\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3454, Output: 391, Total: 6299727\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 212 entities(duplicated), 117 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  49%|████▊     | 17/35 [00:33<00:28,  1.58s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3548, Output: 282, Total: 6303557\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 214 entities(duplicated), 117 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  51%|█████▏    | 18/35 [00:33<00:20,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3767, Output: 628, Total: 6307952\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 228 entities(duplicated), 128 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  54%|█████▍    | 19/35 [00:33<00:15,  1.04chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 695, Total: 6311747\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 401, Total: 6315245\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 271, Total: 6318614\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 557, Total: 6322269\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3321, Output: 599, Total: 6326189\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 237 entities(duplicated), 135 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  57%|█████▋    | 20/35 [00:35<00:18,  1.22s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 520, Total: 6329808\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3233, Output: 345, Total: 6333386\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 244 entities(duplicated), 135 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  60%|██████    | 21/35 [00:38<00:23,  1.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 773, Total: 6337258\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3904, Output: 509, Total: 6341671\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 261 entities(duplicated), 141 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  63%|██████▎   | 22/35 [00:39<00:19,  1.49s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3892, Output: 562, Total: 6346125\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 278 entities(duplicated), 157 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 23/35 [00:39<00:13,  1.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 353, Total: 6349577\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3822, Output: 317, Total: 6353716\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 290 entities(duplicated), 162 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▊   | 24/35 [00:41<00:14,  1.35s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 392, Total: 6357207\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3396, Output: 419, Total: 6361022\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 298 entities(duplicated), 169 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████▏  | 25/35 [00:43<00:14,  1.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1034, Total: 6365155\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3557, Output: 575, Total: 6369287\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 308 entities(duplicated), 176 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▍  | 26/35 [00:43<00:09,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3525, Output: 685, Total: 6373497\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 315 entities(duplicated), 184 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  77%|███████▋  | 27/35 [00:44<00:07,  1.04chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3682, Output: 437, Total: 6377616\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 333 entities(duplicated), 188 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  80%|████████  | 28/35 [00:45<00:06,  1.03chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 609, Total: 6381324\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3646, Output: 631, Total: 6385601\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 343 entities(duplicated), 197 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 29/35 [00:48<00:10,  1.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 697, Total: 6389396\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3899, Output: 413, Total: 6393708\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 356 entities(duplicated), 210 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 30/35 [00:51<00:09,  1.94s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3518, Output: 379, Total: 6397605\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 363 entities(duplicated), 217 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▊ | 31/35 [00:51<00:05,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4160, Output: 691, Total: 6402456\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 390 entities(duplicated), 228 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████▏| 32/35 [00:55<00:06,  2.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3735, Output: 441, Total: 6406632\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 402 entities(duplicated), 238 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3822, Output: 546, Total: 6411000\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 423 entities(duplicated), 244 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 34/35 [00:59<00:02,  2.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3479, Output: 930, Total: 6415409\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 445 entities(duplicated), 247 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 35/35 [01:00<00:00,  1.72s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/266 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 663, Output: 300, Total: 6416372\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 261/266 [00:06<00:00, 43.30entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 726, Output: 343, Total: 6417441\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1821, Output: 404, Total: 6419666\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 690, Output: 461, Total: 6420817\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 694, Output: 500, Total: 6422011\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 851, Output: 472, Total: 6423334\n",
      "INFO:lightrag:Processing file: Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 266/266 [00:12<00:00, 20.51entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 184/184 [00:00<00:00, 15885.23relationship/s]\n",
      "INFO:lightrag:Inserting 266 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.91batch/s]\n",
      "INFO:lightrag:Inserting 184 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/6 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:02<00:00,  2.84batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt. Total tokens used: 6423334\n",
      "INFO:lightrag:Writing graph with 4585 nodes, 4186 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 6423334\n",
      "INFO:lightrag:Processed: US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt. Total tokens used: 6423334\n",
      "INFO:lightrag:[New Chunks] inserting 37 chunks\n",
      "INFO:lightrag:Inserting 37 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US306243050L_a1b38526-3f1d-3a60-b7d5-be73be8fba54_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:01<00:01,  1.24s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.06batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 24357, Output: 24357, Total: 6472048\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/37 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 188, Total: 6475335\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 205, Total: 6478638\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 137, Total: 6481874\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 296, Total: 6485270\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 215, Total: 6488584\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 262, Total: 6491945\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 215, Total: 6495258\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 666, Total: 6499024\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3314, Output: 305, Total: 6502643\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/37 [00:11<06:46, 11.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3423, Output: 335, Total: 6506401\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 18 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Updated token count - Input: 3388, Output: 249, Total: 6510038\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 25 entities(duplicated), 8 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 660, Total: 6513797\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 604, Total: 6517500\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 730, Total: 6521329\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 80, Total: 6524508\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3263, Output: 409, Total: 6528180\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 32 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 4/37 [00:13<01:33,  2.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 473, Total: 6531752\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3340, Output: 254, Total: 6535346\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 38 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▎        | 5/37 [00:14<01:06,  2.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 634, Total: 6539079\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 706, Total: 6542884\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 790, Total: 6546772\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3341, Output: 798, Total: 6550911\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 51 entities(duplicated), 29 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  16%|█▌        | 6/37 [00:17<01:14,  2.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 352, Total: 6554361\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3330, Output: 472, Total: 6558163\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 58 entities(duplicated), 35 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 7/37 [00:18<01:01,  2.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 868, Total: 6562130\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 283, Total: 6565512\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3793, Output: 492, Total: 6569797\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 80 entities(duplicated), 43 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 8/37 [00:20<00:56,  1.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3786, Output: 480, Total: 6574063\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 98 entities(duplicated), 48 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  24%|██▍       | 9/37 [00:21<00:51,  1.83s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3856, Output: 479, Total: 6578398\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 123 entities(duplicated), 52 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3599, Output: 528, Total: 6582525\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 135 entities(duplicated), 62 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  30%|██▉       | 11/37 [00:23<00:35,  1.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3760, Output: 477, Total: 6586762\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 149 entities(duplicated), 75 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 12/37 [00:23<00:29,  1.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 305, Total: 6590166\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 329, Total: 6593593\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3994, Output: 344, Total: 6597931\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 165 entities(duplicated), 82 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  35%|███▌      | 13/37 [00:26<00:36,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3915, Output: 533, Total: 6602379\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 177 entities(duplicated), 94 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 14/37 [00:27<00:35,  1.52s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3206, Output: 772, Total: 6606357\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 187 entities(duplicated), 103 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 15/37 [00:28<00:30,  1.37s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1132, Total: 6610588\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3477, Output: 589, Total: 6614654\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 198 entities(duplicated), 111 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  43%|████▎     | 16/37 [00:30<00:27,  1.29s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3832, Output: 435, Total: 6618921\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 208 entities(duplicated), 119 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  46%|████▌     | 17/37 [00:30<00:21,  1.06s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3730, Output: 650, Total: 6623301\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 222 entities(duplicated), 132 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  49%|████▊     | 18/37 [00:30<00:15,  1.22chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 474, Total: 6626873\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 227, Total: 6630200\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 379, Total: 6633678\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3431, Output: 451, Total: 6637560\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 231 entities(duplicated), 140 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  51%|█████▏    | 19/37 [00:32<00:18,  1.05s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 652, Total: 6641310\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3409, Output: 607, Total: 6645326\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 245 entities(duplicated), 149 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  54%|█████▍    | 20/37 [00:33<00:17,  1.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2194, Output: 275, Total: 6647795\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 514, Total: 6651408\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3354, Output: 383, Total: 6655145\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 252 entities(duplicated), 155 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  57%|█████▋    | 21/37 [00:37<00:33,  2.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 930, Total: 6659174\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 768, Total: 6663041\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 702, Total: 6666842\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3599, Output: 424, Total: 6670865\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 261 entities(duplicated), 164 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 22/37 [00:40<00:32,  2.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4258, Output: 440, Total: 6675563\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 287 entities(duplicated), 178 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▏   | 23/37 [00:41<00:27,  1.93s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 225, Total: 6678887\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3454, Output: 510, Total: 6682851\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 297 entities(duplicated), 186 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  65%|██████▍   | 24/37 [00:42<00:20,  1.59s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 682, Total: 6686632\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3505, Output: 780, Total: 6690917\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 307 entities(duplicated), 195 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 25/37 [00:43<00:15,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 417, Total: 6694432\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 483, Total: 6698013\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4056, Output: 290, Total: 6702359\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 326 entities(duplicated), 205 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  70%|███████   | 26/37 [00:45<00:16,  1.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3777, Output: 660, Total: 6706796\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 341 entities(duplicated), 218 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 613, Total: 6710508\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2496, Output: 492, Total: 6713496\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 351 entities(duplicated), 226 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  76%|███████▌  | 28/37 [00:46<00:09,  1.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3640, Output: 272, Total: 6717408\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 367 entities(duplicated), 231 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 29/37 [00:46<00:06,  1.19chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3828, Output: 474, Total: 6721710\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 389 entities(duplicated), 239 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 30/37 [00:48<00:08,  1.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3808, Output: 409, Total: 6725927\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 407 entities(duplicated), 246 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  84%|████████▍ | 31/37 [00:50<00:07,  1.32s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3894, Output: 575, Total: 6730396\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 407 entities(duplicated), 259 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▋ | 32/37 [00:50<00:05,  1.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3351, Output: 477, Total: 6734224\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 416 entities(duplicated), 267 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 33/37 [00:51<00:04,  1.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3542, Output: 488, Total: 6738254\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 425 entities(duplicated), 275 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  92%|█████████▏| 34/37 [00:52<00:03,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3608, Output: 587, Total: 6742449\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 438 entities(duplicated), 284 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  95%|█████████▍| 35/37 [00:54<00:02,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 958, Total: 6746506\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3739, Output: 470, Total: 6750715\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 36 chunks, 451 entities(duplicated), 293 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 36/37 [01:00<00:02,  2.64s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4084, Output: 290, Total: 6755089\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 37 chunks, 464 entities(duplicated), 302 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 37/37 [01:04<00:00,  1.73s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/301 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 683, Output: 363, Total: 6756135\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "Inserting entities:  99%|█████████▊| 297/301 [00:06<00:00, 42.51entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1695, Output: 359, Total: 6758189\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 661, Output: 500, Total: 6759350\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 718, Output: 367, Total: 6760435\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 753, Output: 442, Total: 6761630\n",
      "INFO:lightrag:Processing file: Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 301/301 [00:15<00:00, 19.06entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 227/227 [00:00<00:00, 10384.21relationship/s]\n",
      "INFO:lightrag:Inserting 301 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/10 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 10/10 [00:03<00:00,  2.75batch/s]\n",
      "INFO:lightrag:Inserting 227 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  38%|███▊      | 3/8 [00:01<00:01,  2.90batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.47batch/s]\n",
      "INFO:lightrag:Finished processing Recon/KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt. Total tokens used: 6761630\n",
      "INFO:lightrag:Writing graph with 4796 nodes, 4404 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 6761630\n",
      "INFO:lightrag:Processed: KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt. Total tokens used: 6761630\n",
      "INFO:lightrag:[New Chunks] inserting 28 chunks\n",
      "INFO:lightrag:Inserting 28 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: KEBN142514_4924c6a7-a5d0-32fa-95f6-c4fe98ad5631_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.81s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 20188, Output: 20188, Total: 6802006\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/28 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 358, Total: 6805464\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 198, Total: 6808760\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 348, Total: 6812207\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 430, Total: 6815735\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 471, Total: 6819305\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 587, Total: 6822991\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 390, Total: 6826481\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 548, Total: 6830128\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3555, Output: 26, Total: 6833709\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 5 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   4%|▎         | 1/28 [00:12<05:41, 12.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 584, Total: 6837391\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 780, Total: 6841270\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 590, Total: 6844959\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 784, Total: 6848842\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 640, Total: 6852581\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 222, Total: 6855903\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 659, Total: 6859660\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 879, Total: 6863637\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3517, Output: 354, Total: 6867508\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   7%|▋         | 2/28 [00:20<04:17,  9.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3713, Output: 351, Total: 6871572\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 30 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 3/28 [00:20<02:15,  5.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3474, Output: 661, Total: 6875707\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 42 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 4/28 [00:22<01:32,  3.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3485, Output: 561, Total: 6879753\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 55 entities(duplicated), 28 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  18%|█▊        | 5/28 [00:22<01:02,  2.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3716, Output: 297, Total: 6883766\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 67 entities(duplicated), 33 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  21%|██▏       | 6/28 [00:22<00:40,  1.84s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3906, Output: 580, Total: 6888252\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 84 entities(duplicated), 45 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 7/28 [00:23<00:29,  1.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3709, Output: 411, Total: 6892372\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 95 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting entities from chunks:  29%|██▊       | 8/28 [00:24<00:25,  1.27s/chunk]INFO:lightrag:Updated token count - Input: 3099, Output: 180, Total: 6895651\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3674, Output: 483, Total: 6899808\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 115 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 9/28 [00:25<00:20,  1.07s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3323, Output: 640, Total: 6903771\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 133 entities(duplicated), 59 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▌      | 10/28 [00:25<00:16,  1.09chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 895, Total: 6907765\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4004, Output: 298, Total: 6912067\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 150 entities(duplicated), 69 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▉      | 11/28 [00:27<00:19,  1.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3766, Output: 480, Total: 6916313\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 162 entities(duplicated), 77 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  43%|████▎     | 12/28 [00:29<00:20,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3597, Output: 630, Total: 6920540\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 175 entities(duplicated), 89 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  46%|████▋     | 13/28 [00:30<00:18,  1.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 263, Total: 6923902\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3349, Output: 471, Total: 6927722\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 182 entities(duplicated), 95 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 14/28 [00:31<00:17,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 700, Total: 6931521\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 540, Total: 6935159\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 220, Total: 6938478\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 637, Total: 6942215\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4021, Output: 507, Total: 6946743\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 200 entities(duplicated), 102 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  54%|█████▎    | 15/28 [00:37<00:36,  2.78s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 608, Total: 6950450\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 597, Total: 6954146\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2805, Output: 780, Total: 6957731\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1155, Total: 6961985\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3389, Output: 519, Total: 6965893\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 209 entities(duplicated), 109 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  57%|█████▋    | 16/28 [00:40<00:32,  2.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3784, Output: 703, Total: 6970380\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 230 entities(duplicated), 122 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 17/28 [00:40<00:21,  1.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 580, Total: 6974059\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3910, Output: 982, Total: 6978951\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 248 entities(duplicated), 139 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  64%|██████▍   | 18/28 [00:42<00:19,  1.92s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3764, Output: 334, Total: 6983049\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 261 entities(duplicated), 143 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 19/28 [00:44<00:17,  1.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3306, Output: 663, Total: 6987018\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 272 entities(duplicated), 150 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████▏  | 20/28 [00:44<00:11,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3826, Output: 553, Total: 6991397\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 286 entities(duplicated), 163 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 21/28 [00:45<00:08,  1.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3665, Output: 377, Total: 6995439\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 298 entities(duplicated), 172 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  79%|███████▊  | 22/28 [00:46<00:06,  1.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3734, Output: 343, Total: 6999516\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 312 entities(duplicated), 177 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  82%|████████▏ | 23/28 [00:46<00:04,  1.25chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3346, Output: 456, Total: 7003318\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 321 entities(duplicated), 183 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 24/28 [00:48<00:05,  1.39s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4281, Output: 538, Total: 7008137\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 346 entities(duplicated), 193 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 25/28 [00:51<00:04,  1.62s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3612, Output: 591, Total: 7012340\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 360 entities(duplicated), 206 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  93%|█████████▎| 26/28 [00:51<00:02,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3706, Output: 654, Total: 7016700\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 373 entities(duplicated), 217 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  96%|█████████▋| 27/28 [00:53<00:01,  1.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3723, Output: 628, Total: 7021051\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 383 entities(duplicated), 230 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 28/28 [00:53<00:00,  1.91s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/255 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 638, Output: 259, Total: 7021948\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 251/255 [00:08<00:00, 29.89entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 823, Output: 288, Total: 7023059\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 694, Output: 414, Total: 7024167\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 682, Output: 500, Total: 7025349\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 254/255 [00:18<00:00, 10.86entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 706, Output: 468, Total: 7026523\n",
      "INFO:lightrag:Processing file: Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 255/255 [00:19<00:00, 13.27entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 197/197 [00:00<00:00, 18301.54relationship/s]\n",
      "INFO:lightrag:Inserting 255 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  12%|█▎        | 1/8 [00:01<00:09,  1.40s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.47batch/s]\n",
      "INFO:lightrag:Inserting 197 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  43%|████▎     | 3/7 [00:01<00:01,  2.20batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.89batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt. Total tokens used: 7026523\n",
      "INFO:lightrag:Writing graph with 4976 nodes, 4600 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 7026523\n",
      "INFO:lightrag:Processed: US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt. Total tokens used: 7026523\n",
      "INFO:lightrag:[New Chunks] inserting 34 chunks\n",
      "INFO:lightrag:Inserting 34 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US129823734L_2d128f34-d154-391b-80e8-f9149d119c04_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.17batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 23164, Output: 23164, Total: 7072851\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/34 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 87, Total: 7076037\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 162, Total: 7079298\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 424, Total: 7082821\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 252, Total: 7086172\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 394, Total: 7089665\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 402, Total: 7093166\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3213, Output: 270, Total: 7096649\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/34 [00:09<04:57,  9.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 436, Total: 7100184\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 483, Total: 7103766\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3288, Output: 423, Total: 7107477\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 13 entities(duplicated), 5 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/34 [00:10<02:28,  4.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 410, Total: 7110986\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 579, Total: 7114663\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 648, Total: 7118410\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 319, Total: 7121829\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 566, Total: 7125494\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3528, Output: 277, Total: 7129299\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 21 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/34 [00:14<02:17,  4.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 375, Total: 7132773\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3520, Output: 280, Total: 7136573\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 31 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▏        | 4/34 [00:15<01:30,  3.02s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3609, Output: 348, Total: 7140530\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 46 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  15%|█▍        | 5/34 [00:16<01:06,  2.29s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 886, Total: 7144515\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3536, Output: 246, Total: 7148297\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 56 entities(duplicated), 25 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  18%|█▊        | 6/34 [00:17<00:47,  1.71s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3378, Output: 400, Total: 7152075\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 63 entities(duplicated), 31 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  21%|██        | 7/34 [00:18<00:39,  1.47s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3562, Output: 299, Total: 7155936\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 73 entities(duplicated), 34 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  24%|██▎       | 8/34 [00:18<00:29,  1.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 957, Total: 7159992\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3550, Output: 450, Total: 7163992\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 82 entities(duplicated), 36 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▋       | 9/34 [00:18<00:21,  1.14chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2371, Output: 379, Total: 7166742\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3704, Output: 451, Total: 7170897\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 98 entities(duplicated), 41 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  29%|██▉       | 10/34 [00:22<00:42,  1.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 710, Total: 7174706\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 458, Total: 7178263\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3446, Output: 410, Total: 7182119\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 106 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 11/34 [00:26<00:55,  2.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4083, Output: 306, Total: 7186508\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 119 entities(duplicated), 64 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  35%|███▌      | 12/34 [00:28<00:47,  2.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 373, Total: 7189980\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 448, Total: 7193527\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3692, Output: 555, Total: 7197774\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 132 entities(duplicated), 73 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 13/34 [00:29<00:40,  1.92s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4012, Output: 574, Total: 7202360\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 155 entities(duplicated), 83 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 14/34 [00:30<00:31,  1.58s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2777, Output: 515, Total: 7205652\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 164 entities(duplicated), 91 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 15/34 [00:30<00:24,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 98, Total: 7208850\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 477, Total: 7212427\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3836, Output: 359, Total: 7216622\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 175 entities(duplicated), 102 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 16/34 [00:32<00:22,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 356, Total: 7220076\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3501, Output: 630, Total: 7224207\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 187 entities(duplicated), 114 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 17/34 [00:33<00:21,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3584, Output: 389, Total: 7228180\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 202 entities(duplicated), 119 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 18/34 [00:34<00:19,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 225, Total: 7231504\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 223, Total: 7234824\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3574, Output: 336, Total: 7238734\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 213 entities(duplicated), 127 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 19/34 [00:36<00:23,  1.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3225, Output: 303, Total: 7242262\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 220 entities(duplicated), 127 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 20/34 [00:37<00:17,  1.22s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3774, Output: 687, Total: 7246723\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 237 entities(duplicated), 142 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▏   | 21/34 [00:38<00:15,  1.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 513, Total: 7250335\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 720, Total: 7254154\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3481, Output: 452, Total: 7258087\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 248 entities(duplicated), 148 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Updated token count - Input: 3099, Output: 535, Total: 7261721\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Extracting entities from chunks:  65%|██████▍   | 22/34 [00:41<00:20,  1.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 784, Total: 7265604\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 561, Total: 7269265\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3351, Output: 313, Total: 7272929\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 253 entities(duplicated), 152 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 23/34 [00:43<00:19,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 801, Total: 7276829\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3639, Output: 299, Total: 7280767\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 266 entities(duplicated), 158 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████   | 24/34 [00:45<00:19,  1.92s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 455, Total: 7284321\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 530, Total: 7287950\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3661, Output: 424, Total: 7292035\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 279 entities(duplicated), 163 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Updated token count - Input: 3604, Output: 553, Total: 7296192\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 297 entities(duplicated), 167 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▎  | 25/34 [00:49<00:23,  2.64s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3846, Output: 537, Total: 7300575\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 311 entities(duplicated), 181 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  79%|███████▉  | 27/34 [00:50<00:11,  1.58s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3499, Output: 877, Total: 7304951\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 327 entities(duplicated), 193 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  82%|████████▏ | 28/34 [00:51<00:09,  1.53s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3927, Output: 454, Total: 7309332\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 339 entities(duplicated), 203 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  85%|████████▌ | 29/34 [00:53<00:07,  1.54s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3656, Output: 222, Total: 7313210\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 351 entities(duplicated), 209 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 30/34 [00:53<00:04,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3910, Output: 598, Total: 7317718\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 374 entities(duplicated), 217 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 31/34 [00:57<00:05,  1.94s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3688, Output: 700, Total: 7322106\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 387 entities(duplicated), 230 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 32/34 [00:58<00:03,  1.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3581, Output: 691, Total: 7326378\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 401 entities(duplicated), 240 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 33/34 [01:13<00:05,  5.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3347, Output: 1338, Total: 7331063\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 417 entities(duplicated), 255 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 34/34 [01:21<00:00,  2.39s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/266 [00:00<00:34,  7.72entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 675, Output: 279, Total: 7332017\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Inserting entities:  97%|█████████▋| 258/266 [00:10<00:00, 24.07entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 642, Output: 336, Total: 7332995\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 830, Output: 342, Total: 7334167\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1081, Output: 356, Total: 7335604\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 261/266 [00:11<00:00, 21.36entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 758, Output: 467, Total: 7336829\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 262/266 [00:13<00:00, 16.26entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 698, Output: 500, Total: 7338027\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 263/266 [00:14<00:00, 14.70entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 652, Output: 404, Total: 7339083\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 853, Output: 463, Total: 7340399\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 265/266 [00:14<00:00, 14.19entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 677, Output: 403, Total: 7341479\n",
      "INFO:lightrag:Processing file: Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 266/266 [00:15<00:00, 17.49entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 208/208 [00:00<00:00, 16165.12relationship/s]\n",
      "INFO:lightrag:Inserting 266 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  11%|█         | 1/9 [00:01<00:08,  1.01s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  89%|████████▉ | 8/9 [00:02<00:00,  6.29batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:03<00:00,  2.41batch/s]\n",
      "INFO:lightrag:Inserting 208 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  14%|█▍        | 1/7 [00:01<00:06,  1.03s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  29%|██▊       | 2/7 [00:01<00:03,  1.57batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.04batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt. Total tokens used: 7341479\n",
      "INFO:lightrag:Writing graph with 5152 nodes, 4802 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 7341479\n",
      "INFO:lightrag:Processed: US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt. Total tokens used: 7341479\n",
      "INFO:lightrag:[New Chunks] inserting 35 chunks\n",
      "INFO:lightrag:Inserting 35 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US710415188_99025ce0-2a27-343c-ac0f-ffefa5fa2ad3_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.01batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:01<00:00,  1.05batch/s]\n",
      "INFO:lightrag:Updated token count - Input: 24209, Output: 24209, Total: 7389897\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/35 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 243, Total: 7393240\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 359, Total: 7396698\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 388, Total: 7400185\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 405, Total: 7403688\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 462, Total: 7407249\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 451, Total: 7410799\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 415, Total: 7414312\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 480, Total: 7417889\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 521, Total: 7421509\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 532, Total: 7425139\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2780, Output: 610, Total: 7428529\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 614, Total: 7432241\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3370, Output: 339, Total: 7435950\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 2 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/35 [00:13<07:46, 13.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3514, Output: 246, Total: 7439710\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 22 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Updated token count - Input: 3588, Output: 205, Total: 7443503\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 31 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/35 [00:14<03:23,  6.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 714, Total: 7447315\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3647, Output: 185, Total: 7451147\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 32 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█▏        | 4/35 [00:15<01:22,  2.65s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 733, Total: 7454979\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3577, Output: 369, Total: 7458925\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 44 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/35 [00:18<01:17,  2.57s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3540, Output: 388, Total: 7462853\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 52 entities(duplicated), 23 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/35 [00:18<00:53,  1.83s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 926, Total: 7466879\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3485, Output: 466, Total: 7470830\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 66 entities(duplicated), 27 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  20%|██        | 7/35 [00:18<00:39,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3417, Output: 345, Total: 7474592\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 81 entities(duplicated), 35 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  23%|██▎       | 8/35 [00:19<00:36,  1.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4053, Output: 28, Total: 7478673\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 87 entities(duplicated), 50 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Updated token count - Input: 3739, Output: 365, Total: 7482777\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 104 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▌       | 9/35 [00:20<00:25,  1.00chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3604, Output: 487, Total: 7486868\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 116 entities(duplicated), 67 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███▏      | 11/35 [00:20<00:16,  1.44chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3530, Output: 657, Total: 7491055\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 128 entities(duplicated), 78 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  34%|███▍      | 12/35 [00:21<00:15,  1.51chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 606, Total: 7494760\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3839, Output: 390, Total: 7498989\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 141 entities(duplicated), 90 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  37%|███▋      | 13/35 [00:24<00:31,  1.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 387, Total: 7502474\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3657, Output: 730, Total: 7506861\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 157 entities(duplicated), 103 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  40%|████      | 14/35 [00:25<00:23,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 236, Total: 7510195\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 1220, Total: 7514512\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 302, Total: 7517913\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3361, Output: 31, Total: 7521305\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 160 entities(duplicated), 105 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  43%|████▎     | 15/35 [00:27<00:30,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 740, Total: 7525144\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 348, Total: 7528590\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 523, Total: 7532212\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 305, Total: 7535615\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3732, Output: 279, Total: 7539626\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 170 entities(duplicated), 114 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  46%|████▌     | 16/35 [00:31<00:40,  2.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 495, Total: 7543220\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 756, Total: 7547075\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3859, Output: 741, Total: 7551675\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 185 entities(duplicated), 128 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  49%|████▊     | 17/35 [00:33<00:39,  2.20s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 522, Total: 7555296\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3649, Output: 325, Total: 7559270\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 199 entities(duplicated), 133 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  51%|█████▏    | 18/35 [00:36<00:41,  2.42s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 205, Total: 7562572\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3866, Output: 536, Total: 7566974\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 215 entities(duplicated), 149 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  54%|█████▍    | 19/35 [00:37<00:30,  1.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3473, Output: 365, Total: 7570812\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 223 entities(duplicated), 156 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  57%|█████▋    | 20/35 [00:38<00:26,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3430, Output: 379, Total: 7574621\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 234 entities(duplicated), 161 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  60%|██████    | 21/35 [00:39<00:19,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4344, Output: 542, Total: 7579507\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 249 entities(duplicated), 177 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  63%|██████▎   | 22/35 [00:39<00:14,  1.11s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 893, Total: 7583499\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3512, Output: 519, Total: 7587530\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 264 entities(duplicated), 184 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  66%|██████▌   | 23/35 [00:40<00:12,  1.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 526, Total: 7591154\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 332, Total: 7594585\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3329, Output: 346, Total: 7598260\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 275 entities(duplicated), 186 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▊   | 24/35 [00:43<00:16,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3428, Output: 635, Total: 7602323\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 290 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  71%|███████▏  | 25/35 [00:43<00:10,  1.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 183, Total: 7605605\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3648, Output: 349, Total: 7609602\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 306 entities(duplicated), 200 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▍  | 26/35 [00:44<00:09,  1.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3882, Output: 476, Total: 7613960\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 323 entities(duplicated), 208 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3621, Output: 503, Total: 7618084\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 334 entities(duplicated), 218 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  80%|████████  | 28/35 [00:45<00:06,  1.09chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4019, Output: 287, Total: 7622390\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 351 entities(duplicated), 227 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 29/35 [00:48<00:07,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 374, Total: 7625863\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3651, Output: 342, Total: 7629856\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 364 entities(duplicated), 232 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 30/35 [00:49<00:05,  1.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 808, Total: 7633763\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 1093, Total: 7637954\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3458, Output: 559, Total: 7641971\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 374 entities(duplicated), 241 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▊ | 31/35 [00:52<00:07,  1.91s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3309, Output: 463, Total: 7645743\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 381 entities(duplicated), 247 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████▏| 32/35 [00:54<00:05,  1.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4218, Output: 455, Total: 7650416\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 403 entities(duplicated), 262 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 33/35 [01:00<00:05,  2.94s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3934, Output: 679, Total: 7655029\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 421 entities(duplicated), 279 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 34/35 [01:01<00:02,  2.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3500, Output: 628, Total: 7659157\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 435 entities(duplicated), 286 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 35/35 [01:04<00:00,  1.86s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/276 [00:00<00:58,  4.74entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 812, Output: 348, Total: 7660317\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "Inserting entities:  99%|█████████▊| 272/276 [00:08<00:00, 31.90entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1036, Output: 416, Total: 7661769\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 729, Output: 430, Total: 7662928\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 649, Output: 282, Total: 7663859\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 275/276 [00:11<00:00, 21.06entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 712, Output: 500, Total: 7665071\n",
      "INFO:lightrag:Processing file: Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 276/276 [00:20<00:00, 13.37entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 231/231 [00:00<00:00, 18372.35relationship/s]\n",
      "INFO:lightrag:Inserting 276 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.89batch/s]\n",
      "INFO:lightrag:Inserting 231 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 4/8 [00:01<00:01,  3.73batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.92batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt. Total tokens used: 7665071\n",
      "INFO:lightrag:Writing graph with 5335 nodes, 5031 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 7665071\n",
      "INFO:lightrag:Processed: US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt. Total tokens used: 7665071\n",
      "INFO:lightrag:[New Chunks] inserting 36 chunks\n",
      "INFO:lightrag:Inserting 36 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US299971055L_3daa0ba5-4714-3210-92d2-f8706d2aa0a3_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:01<00:01,  1.17s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.36s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 24317, Output: 24317, Total: 7713705\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/36 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 335, Total: 7717139\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 259, Total: 7720498\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 282, Total: 7723879\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 308, Total: 7727286\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 424, Total: 7730809\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 323, Total: 7734231\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 346, Total: 7737676\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 388, Total: 7741163\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 426, Total: 7744686\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 636, Total: 7748421\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 651, Total: 7752170\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3550, Output: 256, Total: 7755976\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 11 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/36 [00:14<08:44, 14.98s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 714, Total: 7759789\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 565, Total: 7763453\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 556, Total: 7767108\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 800, Total: 7771007\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3408, Output: 339, Total: 7774754\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 19 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/36 [00:18<04:49,  8.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3386, Output: 443, Total: 7778583\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 33 entities(duplicated), 13 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   8%|▊         | 3/36 [00:19<02:41,  4.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3449, Output: 326, Total: 7782358\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 42 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3461, Output: 557, Total: 7786376\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 54 entities(duplicated), 25 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/36 [00:21<01:21,  2.64s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3550, Output: 334, Total: 7790260\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 64 entities(duplicated), 31 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/36 [00:21<00:59,  1.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3514, Output: 439, Total: 7794213\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 76 entities(duplicated), 34 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 7/36 [00:23<00:52,  1.80s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3682, Output: 252, Total: 7798147\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 87 entities(duplicated), 39 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 8/36 [00:23<00:42,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3472, Output: 477, Total: 7802096\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 101 entities(duplicated), 42 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 9/36 [00:24<00:30,  1.15s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3926, Output: 261, Total: 7806283\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 114 entities(duplicated), 49 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 10/36 [00:24<00:22,  1.13chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3434, Output: 541, Total: 7810258\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 124 entities(duplicated), 55 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███       | 11/36 [00:24<00:17,  1.44chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2102, Output: 210, Total: 7812570\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3776, Output: 417, Total: 7816763\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 139 entities(duplicated), 60 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 12/36 [00:25<00:18,  1.28chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 547, Total: 7820409\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3691, Output: 432, Total: 7824532\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 152 entities(duplicated), 64 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▌      | 13/36 [00:27<00:25,  1.12s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3762, Output: 505, Total: 7828799\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 167 entities(duplicated), 75 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3840, Output: 469, Total: 7833108\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 181 entities(duplicated), 82 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 15/36 [00:31<00:29,  1.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 347, Total: 7836553\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 463, Total: 7840115\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1276, Total: 7844490\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2339, Output: 361, Total: 7847190\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 189 entities(duplicated), 88 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 16/36 [00:33<00:34,  1.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 418, Total: 7850707\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 545, Total: 7854351\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 756, Total: 7858205\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 461, Total: 7861766\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3673, Output: 385, Total: 7865824\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 203 entities(duplicated), 93 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 17/36 [00:36<00:39,  2.09s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 266, Total: 7869189\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 400, Total: 7872687\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 461, Total: 7876247\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3589, Output: 279, Total: 7880115\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 214 entities(duplicated), 97 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 18/36 [00:39<00:38,  2.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3472, Output: 366, Total: 7883953\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 226 entities(duplicated), 100 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 19/36 [00:39<00:28,  1.70s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4402, Output: 257, Total: 7888612\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 246 entities(duplicated), 114 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 20/36 [00:41<00:27,  1.74s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 368, Total: 7892080\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 827, Total: 7896006\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3525, Output: 204, Total: 7899735\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 256 entities(duplicated), 118 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 21/36 [00:44<00:29,  1.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3545, Output: 436, Total: 7903716\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 267 entities(duplicated), 127 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 22/36 [00:44<00:20,  1.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3881, Output: 550, Total: 7908147\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 286 entities(duplicated), 133 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  64%|██████▍   | 23/36 [00:44<00:14,  1.14s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3588, Output: 529, Total: 7912264\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 297 entities(duplicated), 141 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 24/36 [00:45<00:13,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3671, Output: 607, Total: 7916542\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 311 entities(duplicated), 151 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 25/36 [00:47<00:12,  1.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 834, Total: 7920475\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3392, Output: 423, Total: 7924290\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 312 entities(duplicated), 156 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 26/36 [00:47<00:09,  1.01chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 438, Total: 7927827\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 565, Total: 7931492\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 759, Total: 7935349\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3587, Output: 541, Total: 7939477\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 323 entities(duplicated), 164 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 27/36 [00:52<00:19,  2.18s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 673, Total: 7943249\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3960, Output: 294, Total: 7947503\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 323 entities(duplicated), 164 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 28/36 [00:54<00:17,  2.17s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 929, Total: 7951529\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 599, Total: 7955228\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3564, Output: 457, Total: 7959249\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 340 entities(duplicated), 168 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 29/36 [00:57<00:16,  2.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4053, Output: 182, Total: 7963484\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 358 entities(duplicated), 175 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 30/36 [00:57<00:10,  1.76s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3953, Output: 523, Total: 7967960\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 376 entities(duplicated), 190 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 31/36 [01:00<00:09,  1.99s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3498, Output: 530, Total: 7971988\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 389 entities(duplicated), 197 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 32/36 [01:00<00:05,  1.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3799, Output: 462, Total: 7976249\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 409 entities(duplicated), 203 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  92%|█████████▏| 33/36 [01:01<00:03,  1.21s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3692, Output: 576, Total: 7980517\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 422 entities(duplicated), 213 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 34/36 [01:02<00:02,  1.30s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3726, Output: 384, Total: 7984627\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 434 entities(duplicated), 224 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 35/36 [01:05<00:01,  1.60s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3884, Output: 696, Total: 7989207\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 36 chunks, 461 entities(duplicated), 231 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 36/36 [01:08<00:00,  1.89s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/258 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 905, Output: 286, Total: 7990398\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 254/258 [00:10<00:00, 24.10entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 775, Output: 238, Total: 7991411\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 669, Output: 428, Total: 7992508\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 680, Output: 500, Total: 7993688\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 257/258 [00:17<00:00, 12.82entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 675, Output: 465, Total: 7994828\n",
      "INFO:lightrag:Processing file: Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 258/258 [00:20<00:00, 12.87entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 186/186 [00:00<00:00, 19829.71relationship/s]\n",
      "INFO:lightrag:Inserting 258 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  11%|█         | 1/9 [00:00<00:06,  1.24batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  22%|██▏       | 2/9 [00:01<00:03,  1.84batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  4.18batch/s]\n",
      "INFO:lightrag:Inserting 186 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/6 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  83%|████████▎ | 5/6 [00:01<00:00,  4.64batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 6/6 [00:06<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Finished processing Recon/SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt. Total tokens used: 7994828\n",
      "INFO:lightrag:Writing graph with 5538 nodes, 5216 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 7994828\n",
      "INFO:lightrag:Processed: SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt. Total tokens used: 7994828\n",
      "INFO:lightrag:[New Chunks] inserting 36 chunks\n",
      "INFO:lightrag:Inserting 36 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: SA0000262507_e304b357-5156-36fa-b62f-84353fa78985_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.05batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.10s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 25221, Output: 25221, Total: 8045270\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/36 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 77, Total: 8048446\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3203, Output: 59, Total: 8051708\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 0 entities(duplicated), 0 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/36 [00:04<02:49,  4.85s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 245, Total: 8055052\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 399, Total: 8058550\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 346, Total: 8061994\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 426, Total: 8065518\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 454, Total: 8069070\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 502, Total: 8072671\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 539, Total: 8076309\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 721, Total: 8080129\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 615, Total: 8083842\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 537, Total: 8087476\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 620, Total: 8091195\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 690, Total: 8094985\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3371, Output: 492, Total: 8098848\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 0 entities(duplicated), 7 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/36 [00:16<05:02,  8.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3551, Output: 401, Total: 8102800\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 16 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   8%|▊         | 3/36 [00:16<02:42,  4.92s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 318, Total: 8106217\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 778, Total: 8110094\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3525, Output: 309, Total: 8113928\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 28 entities(duplicated), 15 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 4/36 [00:18<02:03,  3.86s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3471, Output: 360, Total: 8117759\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 36 entities(duplicated), 19 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/36 [00:19<01:22,  2.65s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 973, Total: 8121831\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3739, Output: 454, Total: 8126024\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 49 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/36 [00:20<01:07,  2.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3096, Output: 901, Total: 8130021\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3847, Output: 463, Total: 8134331\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 63 entities(duplicated), 39 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 7/36 [00:23<01:09,  2.38s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 258, Total: 8137687\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3579, Output: 654, Total: 8141920\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 77 entities(duplicated), 51 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 8/36 [00:23<00:47,  1.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3665, Output: 601, Total: 8146186\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 94 entities(duplicated), 60 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 9/36 [00:24<00:35,  1.32s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3904, Output: 322, Total: 8150412\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 108 entities(duplicated), 68 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 10/36 [00:26<00:37,  1.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 502 Bad Gateway\"\n",
      "INFO:openai._base_client:Retrying request to /chat/completions in 0.463499 seconds\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 323, Total: 8153834\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 447, Total: 8157380\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4024, Output: 244, Total: 8161648\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 123 entities(duplicated), 75 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███       | 11/36 [00:26<00:31,  1.26s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3628, Output: 701, Total: 8165977\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 136 entities(duplicated), 75 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 12/36 [00:28<00:30,  1.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3746, Output: 506, Total: 8170229\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 151 entities(duplicated), 88 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▌      | 13/36 [00:28<00:23,  1.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 190, Total: 8173518\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3817, Output: 329, Total: 8177664\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 167 entities(duplicated), 96 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▉      | 14/36 [00:29<00:20,  1.08chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4099, Output: 523, Total: 8182286\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 183 entities(duplicated), 110 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 15/36 [00:29<00:16,  1.28chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 276, Total: 8185661\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 676, Total: 8189436\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 361, Total: 8192896\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 626, Total: 8196621\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3573, Output: 420, Total: 8200614\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 199 entities(duplicated), 113 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 16/36 [00:34<00:40,  2.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3444, Output: 524, Total: 8204582\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 209 entities(duplicated), 122 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 17/36 [00:38<00:46,  2.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 593, Total: 8208274\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3661, Output: 959, Total: 8212894\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 225 entities(duplicated), 137 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 18/36 [00:39<00:37,  2.11s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 713, Total: 8216706\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 593, Total: 8220398\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3752, Output: 485, Total: 8224635\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 245 entities(duplicated), 143 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 19/36 [00:41<00:34,  2.01s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 326, Total: 8228058\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3316, Output: 552, Total: 8231926\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 262 entities(duplicated), 144 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 20/36 [00:44<00:36,  2.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 596, Total: 8235620\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3402, Output: 608, Total: 8239630\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 277 entities(duplicated), 151 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 21/36 [00:44<00:26,  1.77s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3383, Output: 783, Total: 8243796\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 289 entities(duplicated), 160 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 22/36 [00:45<00:21,  1.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3839, Output: 293, Total: 8247928\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 307 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3488, Output: 629, Total: 8252045\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 319 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 24/36 [00:47<00:15,  1.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3449, Output: 792, Total: 8256286\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 330 entities(duplicated), 177 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 25/36 [00:48<00:11,  1.05s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 806, Total: 8260192\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3450, Output: 231, Total: 8263873\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 339 entities(duplicated), 180 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 26/36 [00:48<00:09,  1.01chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3802, Output: 647, Total: 8268322\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 354 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1110, Total: 8272531\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 383, Total: 8276013\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3721, Output: 234, Total: 8279968\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 365 entities(duplicated), 199 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 28/36 [00:51<00:08,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3719, Output: 555, Total: 8284242\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 380 entities(duplicated), 212 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 29/36 [00:53<00:09,  1.34s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 974, Total: 8288315\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3933, Output: 402, Total: 8292650\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 394 entities(duplicated), 214 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 30/36 [00:58<00:13,  2.22s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3719, Output: 719, Total: 8297088\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 401 entities(duplicated), 220 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 31/36 [01:01<00:12,  2.47s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2943, Output: 911, Total: 8300942\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 793, Total: 8304833\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3882, Output: 266, Total: 8308981\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 417 entities(duplicated), 229 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 32/36 [01:12<00:19,  4.89s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4236, Output: 1110, Total: 8314327\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 455 entities(duplicated), 241 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  92%|█████████▏| 33/36 [01:14<00:11,  3.82s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3509, Output: 554, Total: 8318390\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 466 entities(duplicated), 249 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 34/36 [01:14<00:05,  2.95s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4100, Output: 698, Total: 8323188\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 485 entities(duplicated), 267 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 35/36 [01:18<00:03,  3.13s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3918, Output: 649, Total: 8327755\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 36 chunks, 501 entities(duplicated), 281 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 36/36 [01:20<00:00,  2.25s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/326 [00:00<00:49,  6.51entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 760, Output: 285, Total: 8328800\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 318/326 [00:07<00:00, 42.56entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 696, Output: 364, Total: 8329860\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 901, Output: 384, Total: 8331145\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 681, Output: 421, Total: 8332247\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 321/326 [00:09<00:00, 32.04entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 761, Output: 474, Total: 8333482\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 321/326 [00:25<00:00, 32.04entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 723, Output: 397, Total: 8334602\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 323/326 [00:45<00:00,  3.88entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 786, Output: 412, Total: 8335800\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 324/326 [00:45<00:00,  3.86entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 758, Output: 330, Total: 8336888\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 773, Output: 498, Total: 8338159\n",
      "INFO:lightrag:Processing file: Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 326/326 [00:51<00:00,  6.29entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 247/247 [00:00<00:00, 10663.41relationship/s]\n",
      "INFO:lightrag:Inserting 326 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/11 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:   9%|▉         | 1/11 [00:01<00:18,  1.85s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  18%|█▊        | 2/11 [00:01<00:07,  1.19batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  45%|████▌     | 5/11 [00:02<00:01,  3.83batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  91%|█████████ | 10/11 [00:03<00:00,  5.46batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 11/11 [00:04<00:00,  2.64batch/s]\n",
      "INFO:lightrag:Inserting 247 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  88%|████████▊ | 7/8 [00:02<00:00,  4.35batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:04<00:00,  1.68batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt. Total tokens used: 8338159\n",
      "INFO:lightrag:Writing graph with 5740 nodes, 5452 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 8338159\n",
      "INFO:lightrag:Processed: US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt. Total tokens used: 8338159\n",
      "INFO:lightrag:[New Chunks] inserting 36 chunks\n",
      "INFO:lightrag:Inserting 36 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US367117358L_7244c133-2dd8-34f6-bc9b-d5e491fc68a5_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:01<00:01,  1.16s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.12s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 24785, Output: 24785, Total: 8387729\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/36 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 158, Total: 8390986\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 138, Total: 8394224\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 261, Total: 8397584\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 320, Total: 8401003\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 349, Total: 8404451\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 364, Total: 8407914\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 342, Total: 8411354\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 406, Total: 8414859\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 440, Total: 8418397\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3284, Output: 265, Total: 8421946\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/36 [00:12<07:09, 12.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 467, Total: 8425512\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 481, Total: 8429093\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 513, Total: 8432705\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 652, Total: 8436456\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 671, Total: 8440226\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3467, Output: 374, Total: 8444067\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 20 entities(duplicated), 4 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/36 [00:17<04:37,  8.16s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 581, Total: 8447747\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3490, Output: 301, Total: 8451538\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 28 entities(duplicated), 11 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   8%|▊         | 3/36 [00:18<02:36,  4.73s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3265, Output: 477, Total: 8455280\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 35 entities(duplicated), 17 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  11%|█         | 4/36 [00:19<01:45,  3.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3565, Output: 535, Total: 8459380\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 47 entities(duplicated), 28 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  14%|█▍        | 5/36 [00:19<01:10,  2.28s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3639, Output: 340, Total: 8463359\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 60 entities(duplicated), 33 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  17%|█▋        | 6/36 [00:20<00:57,  1.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3608, Output: 471, Total: 8467438\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 72 entities(duplicated), 43 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  19%|█▉        | 7/36 [00:22<00:48,  1.66s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3446, Output: 404, Total: 8471288\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 82 entities(duplicated), 50 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  22%|██▏       | 8/36 [00:24<00:49,  1.77s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 139, Total: 8474525\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3387, Output: 513, Total: 8478425\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 91 entities(duplicated), 59 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  25%|██▌       | 9/36 [00:25<00:43,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 220, Total: 8481745\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 273, Total: 8485117\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3532, Output: 401, Total: 8489050\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 91 entities(duplicated), 59 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  28%|██▊       | 10/36 [00:26<00:39,  1.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3475, Output: 499, Total: 8493024\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 101 entities(duplicated), 68 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  31%|███       | 11/36 [00:28<00:36,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3593, Output: 504, Total: 8497121\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 110 entities(duplicated), 80 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  33%|███▎      | 12/36 [00:29<00:35,  1.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 1013, Total: 8501232\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3797, Output: 269, Total: 8505298\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 123 entities(duplicated), 87 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  36%|███▌      | 13/36 [00:30<00:30,  1.31s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3347, Output: 409, Total: 8509054\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 135 entities(duplicated), 89 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  39%|███▉      | 14/36 [00:30<00:21,  1.04chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3778, Output: 495, Total: 8513327\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 147 entities(duplicated), 100 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  42%|████▏     | 15/36 [00:30<00:16,  1.30chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 687, Total: 8517113\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 180, Total: 8520392\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 122, Total: 8523613\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3264, Output: 724, Total: 8527601\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 159 entities(duplicated), 109 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 16/36 [00:33<00:25,  1.27s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3707, Output: 650, Total: 8531958\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 180 entities(duplicated), 119 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 17/36 [00:35<00:26,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4138, Output: 377, Total: 8536473\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 200 entities(duplicated), 131 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 18/36 [00:35<00:18,  1.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 517, Total: 8540089\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 382, Total: 8543570\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3813, Output: 613, Total: 8547996\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 219 entities(duplicated), 141 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 19/36 [00:40<00:40,  2.38s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 724, Total: 8551820\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3508, Output: 195, Total: 8555523\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 228 entities(duplicated), 145 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 20/36 [00:41<00:30,  1.88s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 758, Total: 8559380\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 465, Total: 8562944\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 435, Total: 8566478\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 668, Total: 8570245\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 1747, Total: 8575091\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 327, Total: 8578517\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 409, Total: 8582025\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 488, Total: 8585611\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 748, Total: 8589458\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3643, Output: 395, Total: 8593496\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 240 entities(duplicated), 156 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  58%|█████▊    | 21/36 [00:48<00:52,  3.47s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3884, Output: 408, Total: 8597788\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 261 entities(duplicated), 166 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  61%|██████    | 22/36 [00:49<00:38,  2.75s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2141, Output: 327, Total: 8600256\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3399, Output: 521, Total: 8604176\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 262 entities(duplicated), 170 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  64%|██████▍   | 23/36 [00:51<00:31,  2.45s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3306, Output: 642, Total: 8608124\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 264 entities(duplicated), 171 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  67%|██████▋   | 24/36 [00:52<00:24,  2.05s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3453, Output: 408, Total: 8611985\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 273 entities(duplicated), 178 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  69%|██████▉   | 25/36 [00:52<00:16,  1.48s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 858, Total: 8615942\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3613, Output: 266, Total: 8619821\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 289 entities(duplicated), 184 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  72%|███████▏  | 26/36 [00:54<00:15,  1.51s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3248, Output: 637, Total: 8623706\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 299 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  75%|███████▌  | 27/36 [00:54<00:09,  1.10s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2495, Output: 259, Total: 8626460\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 305 entities(duplicated), 200 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  78%|███████▊  | 28/36 [00:55<00:07,  1.07chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3874, Output: 295, Total: 8630629\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 318 entities(duplicated), 206 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  81%|████████  | 29/36 [00:55<00:05,  1.30chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4873, Output: 363, Total: 8635865\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 347 entities(duplicated), 230 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  83%|████████▎ | 30/36 [00:55<00:03,  1.55chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3851, Output: 596, Total: 8640312\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 356 entities(duplicated), 238 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  86%|████████▌ | 31/36 [00:58<00:06,  1.25s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3535, Output: 691, Total: 8644538\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 369 entities(duplicated), 250 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  89%|████████▉ | 32/36 [01:03<00:09,  2.43s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3561, Output: 1133, Total: 8649232\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 385 entities(duplicated), 265 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  92%|█████████▏| 33/36 [01:03<00:05,  1.75s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3794, Output: 602, Total: 8653628\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 399 entities(duplicated), 279 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3984, Output: 390, Total: 8658002\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 35 chunks, 419 entities(duplicated), 288 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 35/36 [01:04<00:01,  1.04s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3591, Output: 794, Total: 8662387\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 36 chunks, 436 entities(duplicated), 303 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 36/36 [01:05<00:00,  1.81s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/252 [00:00<00:25,  9.74entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 653, Output: 155, Total: 8663195\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "Inserting entities:  97%|█████████▋| 245/252 [00:06<00:00, 40.72entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1513, Output: 247, Total: 8664955\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 675, Output: 414, Total: 8666044\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 812, Output: 419, Total: 8667275\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 248/252 [00:08<00:00, 27.10entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 876, Output: 500, Total: 8668651\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 708, Output: 288, Total: 8669647\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 250/252 [00:10<00:00, 19.08entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 633, Output: 334, Total: 8670614\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 679, Output: 318, Total: 8671611\n",
      "INFO:lightrag:Processing file: Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 252/252 [00:11<00:00, 21.09entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 203/203 [00:00<00:00, 11886.69relationship/s]\n",
      "INFO:lightrag:Inserting 252 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/8 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 8/8 [00:02<00:00,  3.85batch/s]\n",
      "INFO:lightrag:Inserting 203 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  3.22batch/s]\n",
      "INFO:lightrag:Finished processing Recon/US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt. Total tokens used: 8671611\n",
      "INFO:lightrag:Writing graph with 5911 nodes, 5654 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 8671611\n",
      "INFO:lightrag:Processed: US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n",
      "INFO:lightrag:Processing folder: Recon\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:lightrag:Inserting content from Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt. Total tokens used: 8671611\n",
      "INFO:lightrag:[New Chunks] inserting 34 chunks\n",
      "INFO:lightrag:Inserting 34 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: US851144904_61f6f73b-ae7d-3985-a063-bfe86d515a73_monitoring.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/2 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  50%|█████     | 1/2 [00:00<00:00,  1.26batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 2/2 [00:02<00:00,  1.27s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 24296, Output: 24296, Total: 8720203\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/34 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 174, Total: 8723476\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 462, Total: 8727037\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 260, Total: 8730397\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2726, Output: 260, Total: 8733383\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 239, Total: 8736721\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3097, Output: 462, Total: 8740280\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 587, Total: 8743966\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 436, Total: 8747500\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 529, Total: 8751128\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 626, Total: 8754853\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 491, Total: 8758442\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3300, Output: 485, Total: 8762227\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 7 entities(duplicated), 6 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   3%|▎         | 1/34 [00:15<08:37, 15.69s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 462, Total: 8765787\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3561, Output: 222, Total: 8769570\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 17 entities(duplicated), 10 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   6%|▌         | 2/34 [00:16<03:44,  7.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 592, Total: 8773261\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 3585, Output: 425, Total: 8777271\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 33 entities(duplicated), 14 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 3/34 [00:17<02:14,  4.33s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 614, Total: 8780984\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 829, Total: 8784912\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3365, Output: 568, Total: 8788845\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 36 entities(duplicated), 16 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  12%|█▏        | 4/34 [00:20<01:46,  3.56s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3588, Output: 369, Total: 8792802\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 49 entities(duplicated), 21 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  15%|█▍        | 5/34 [00:21<01:22,  2.83s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3718, Output: 140, Total: 8796660\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 58 entities(duplicated), 26 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  18%|█▊        | 6/34 [00:22<00:55,  2.00s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3013, Output: 727, Total: 8800400\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 70 entities(duplicated), 38 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  21%|██        | 7/34 [00:23<00:48,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 965, Total: 8804465\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3740, Output: 240, Total: 8808445\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 83 entities(duplicated), 44 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  24%|██▎       | 8/34 [00:25<00:50,  1.96s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3713, Output: 619, Total: 8812777\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 97 entities(duplicated), 48 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  26%|██▋       | 9/34 [00:25<00:35,  1.40s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3752, Output: 546, Total: 8817075\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 115 entities(duplicated), 54 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  29%|██▉       | 10/34 [00:26<00:29,  1.24s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3655, Output: 629, Total: 8821359\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 11 chunks, 130 entities(duplicated), 64 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  32%|███▏      | 11/34 [00:26<00:21,  1.09chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 399, Total: 8824857\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3587, Output: 472, Total: 8828916\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 12 chunks, 140 entities(duplicated), 73 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  35%|███▌      | 12/34 [00:27<00:19,  1.11chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 291, Total: 8832305\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 528, Total: 8835932\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3616, Output: 629, Total: 8840177\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 13 chunks, 153 entities(duplicated), 85 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  38%|███▊      | 13/34 [00:31<00:34,  1.63s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3955, Output: 493, Total: 8844625\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 14 chunks, 169 entities(duplicated), 95 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  41%|████      | 14/34 [00:31<00:27,  1.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 168, Total: 8847891\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4092, Output: 287, Total: 8852270\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 15 chunks, 185 entities(duplicated), 104 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  44%|████▍     | 15/34 [00:32<00:19,  1.03s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 245, Total: 8855614\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 753, Total: 8859466\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 536, Total: 8863101\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3653, Output: 308, Total: 8867062\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 16 chunks, 197 entities(duplicated), 109 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  47%|████▋     | 16/34 [00:36<00:34,  1.93s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3525, Output: 302, Total: 8870889\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 17 chunks, 209 entities(duplicated), 113 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  50%|█████     | 17/34 [00:36<00:26,  1.53s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 334, Total: 8874322\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3387, Output: 895, Total: 8878604\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 18 chunks, 223 entities(duplicated), 125 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  53%|█████▎    | 18/34 [00:37<00:19,  1.23s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 636, Total: 8882338\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 620, Total: 8886056\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 157, Total: 8889312\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 325, Total: 8892735\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3371, Output: 524, Total: 8896630\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 19 chunks, 233 entities(duplicated), 131 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  56%|█████▌    | 19/34 [00:42<00:36,  2.41s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3879, Output: 333, Total: 8900842\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 20 chunks, 257 entities(duplicated), 138 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  59%|█████▉    | 20/34 [00:42<00:24,  1.72s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3460, Output: 395, Total: 8904697\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 21 chunks, 265 entities(duplicated), 146 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  62%|██████▏   | 21/34 [00:43<00:19,  1.50s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 390, Total: 8908186\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 656, Total: 8911941\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3098, Output: 745, Total: 8915784\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 747, Total: 8919630\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3745, Output: 385, Total: 8923760\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 22 chunks, 277 entities(duplicated), 156 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  65%|██████▍   | 22/34 [00:50<00:38,  3.19s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3293, Output: 472, Total: 8927525\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 23 chunks, 285 entities(duplicated), 162 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  68%|██████▊   | 23/34 [00:52<00:28,  2.64s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3761, Output: 575, Total: 8931861\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 24 chunks, 298 entities(duplicated), 174 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3100, Output: 788, Total: 8935749\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3416, Output: 867, Total: 8940032\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 25 chunks, 310 entities(duplicated), 185 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  74%|███████▎  | 25/34 [00:53<00:15,  1.71s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3450, Output: 572, Total: 8944054\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 26 chunks, 320 entities(duplicated), 194 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  76%|███████▋  | 26/34 [00:53<00:11,  1.38s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3662, Output: 762, Total: 8948478\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 27 chunks, 337 entities(duplicated), 210 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  79%|███████▉  | 27/34 [00:56<00:12,  1.79s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 678, Total: 8952255\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3870, Output: 579, Total: 8956704\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 28 chunks, 347 entities(duplicated), 218 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  82%|████████▏ | 28/34 [00:58<00:11,  1.93s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3873, Output: 382, Total: 8960959\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 29 chunks, 365 entities(duplicated), 227 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  85%|████████▌ | 29/34 [01:02<00:12,  2.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3516, Output: 619, Total: 8965094\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 30 chunks, 375 entities(duplicated), 236 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  88%|████████▊ | 30/34 [01:03<00:08,  2.08s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3283, Output: 878, Total: 8969255\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 31 chunks, 396 entities(duplicated), 240 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  91%|█████████ | 31/34 [01:08<00:08,  2.78s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3915, Output: 631, Total: 8973801\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 32 chunks, 418 entities(duplicated), 247 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  94%|█████████▍| 32/34 [01:09<00:04,  2.38s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3782, Output: 757, Total: 8978340\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 33 chunks, 433 entities(duplicated), 261 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  97%|█████████▋| 33/34 [01:10<00:01,  1.89s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3804, Output: 488, Total: 8982632\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 34 chunks, 433 entities(duplicated), 273 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 34/34 [01:20<00:00,  2.36s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 1/272 [00:00<00:32,  8.42entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 655, Output: 224, Total: 8983511\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "Inserting entities:  96%|█████████▋| 262/272 [00:05<00:00, 50.37entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 649, Output: 224, Total: 8984384\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 1504, Output: 434, Total: 8986322\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 647, Output: 374, Total: 8987343\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 740, Output: 408, Total: 8988491\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:lightrag:Updated token count - Input: 657, Output: 393, Total: 8989541\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "Inserting entities:  98%|█████████▊| 266/272 [00:08<00:00, 25.62entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 738, Output: 434, Total: 8990713\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "Inserting entities:  99%|█████████▊| 268/272 [00:09<00:00, 23.58entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 647, Output: 374, Total: 8991734\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 721, Output: 476, Total: 8992931\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "Inserting entities:  99%|█████████▉| 270/272 [00:10<00:00, 18.80entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 795, Output: 370, Total: 8994096\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "Inserting entities: 100%|█████████▉| 271/272 [00:11<00:00, 14.80entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 667, Output: 500, Total: 8995263\n",
      "INFO:lightrag:Processing file: Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n",
      "Inserting entities: 100%|██████████| 272/272 [00:12<00:00, 21.28entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 217/217 [00:00<00:00, 15875.05relationship/s]\n",
      "INFO:lightrag:Inserting 272 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/9 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  33%|███▎      | 3/9 [00:01<00:02,  2.37batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 9/9 [00:02<00:00,  3.54batch/s]\n",
      "INFO:lightrag:Inserting 217 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/7 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  14%|█▍        | 1/7 [00:01<00:08,  1.37s/batch]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  57%|█████▋    | 4/7 [00:01<00:00,  3.44batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 7/7 [00:02<00:00,  2.92batch/s]\n",
      "INFO:lightrag:Finished processing Recon/BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt. Total tokens used: 8995263\n",
      "INFO:lightrag:Writing graph with 6073 nodes, 5869 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 8995263\n",
      "INFO:lightrag:Processed: BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: BR01838723049991_40847a1c-bc6a-34fa-8a68-85f38957f29e_monitoring.txt\n"
     ]
    }
   ],
   "source": [
    "recon_file_path = \"/Users/arthurj/Library/CloudStorage/OneDrive-moodys.com/Desktop/LightRag_Data/KG_data/Recon\"\n",
    "\n",
    "process_files_in_folder(recon_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightrag:Processing folder: Earnings_Call\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:lightrag:Inserting content from Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt. Total tokens used: 8995263\n",
      "INFO:lightrag:[New Chunks] inserting 10 chunks\n",
      "INFO:lightrag:Inserting 10 vectors to chunks\n",
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.39s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 9768, Output: 9768, Total: 9014799\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/10 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2817, Output: 346, Total: 9017962\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 596, Total: 9021657\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 602, Total: 9025358\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 623, Total: 9029080\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 727, Total: 9032906\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 770, Total: 9036775\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 552, Total: 9040426\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3190, Output: 540, Total: 9044156\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 12 entities(duplicated), 9 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  10%|█         | 1/10 [00:17<02:41, 17.95s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 967, Total: 9048222\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 989, Total: 9052310\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3099, Output: 729, Total: 9056138\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3728, Output: 449, Total: 9060315\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠹ Processed 2 chunks, 27 entities(duplicated), 20 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  20%|██        | 2/10 [00:21<01:15,  9.44s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3722, Output: 484, Total: 9064521\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠸ Processed 3 chunks, 47 entities(duplicated), 31 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  30%|███       | 3/10 [00:21<00:37,  5.36s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3896, Output: 339, Total: 9068756\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠼ Processed 4 chunks, 63 entities(duplicated), 43 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting entities from chunks:  40%|████      | 4/10 [00:22<00:20,  3.35s/chunk]INFO:lightrag:Updated token count - Input: 3853, Output: 413, Total: 9073022\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠴ Processed 5 chunks, 83 entities(duplicated), 52 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3678, Output: 282, Total: 9076982\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠦ Processed 6 chunks, 94 entities(duplicated), 57 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  60%|██████    | 6/10 [00:23<00:07,  1.90s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3855, Output: 340, Total: 9081177\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠧ Processed 7 chunks, 111 entities(duplicated), 69 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  70%|███████   | 7/10 [00:27<00:07,  2.47s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 3749, Output: 779, Total: 9085705\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠇ Processed 8 chunks, 126 entities(duplicated), 82 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  80%|████████  | 8/10 [00:28<00:03,  1.97s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4093, Output: 629, Total: 9090427\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠏ Processed 9 chunks, 143 entities(duplicated), 100 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:  90%|█████████ | 9/10 [00:31<00:02,  2.46s/chunk]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 4115, Output: 986, Total: 9095528\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Processed 10 chunks, 181 entities(duplicated), 116 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 10/10 [00:39<00:00,  3.93s/chunk]\n",
      "INFO:lightrag:Inserting entities into storage...\n",
      "Inserting entities:   0%|          | 0/129 [00:00<?, ?entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 647, Output: 275, Total: 9096450\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "Inserting entities:  98%|█████████▊| 127/129 [00:06<00:00, 19.62entity/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 640, Output: 430, Total: 9097520\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 712, Output: 461, Total: 9098693\n",
      "INFO:lightrag:Processing file: Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "Inserting entities: 100%|██████████| 129/129 [00:11<00:00, 11.66entity/s]\n",
      "INFO:lightrag:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 100/100 [00:00<00:00, 14015.59relationship/s]\n",
      "INFO:lightrag:Inserting 129 vectors to entities\n",
      "Generating embeddings:   0%|          | 0/5 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  20%|██        | 1/5 [00:00<00:02,  1.59batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  80%|████████  | 4/5 [00:02<00:00,  2.47batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 5/5 [00:05<00:00,  1.03s/batch]\n",
      "INFO:lightrag:Inserting 100 vectors to relationships\n",
      "Generating embeddings:   0%|          | 0/4 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings:  25%|██▌       | 1/4 [00:00<00:02,  1.13batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 4/4 [00:01<00:00,  2.32batch/s]\n",
      "INFO:lightrag:Finished processing Earnings_Call/Coca-Cola Q3 2023 Earnings Call Transcript.txt. Total tokens used: 9098693\n",
      "INFO:lightrag:Writing graph with 6175 nodes, 5969 edges\n",
      "INFO:lightrag:Total tokens used after knowledge graph creation: 9098693\n",
      "INFO:lightrag:Processed: Coca-Cola Q3 2023 Earnings Call Transcript.txt\n",
      "INFO:lightrag:Processing folder: Earnings_Call\n",
      "INFO:lightrag:Processing file: Earnings_Call/Abbott Laboratories Q2 2024 Earnings Call Transcript.txt\n",
      "INFO:lightrag:Inserting content from Earnings_Call/Abbott Laboratories Q2 2024 Earnings Call Transcript.txt\n",
      "INFO:lightrag:[New Docs] inserting 1 docs\n",
      "INFO:lightrag:Finished processing Earnings_Call/Abbott Laboratories Q2 2024 Earnings Call Transcript.txt. Total tokens used: 9098693\n",
      "INFO:lightrag:[New Chunks] inserting 11 chunks\n",
      "INFO:lightrag:Inserting 11 vectors to chunks\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: Coca-Cola Q3 2023 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings:   0%|          | 0/1 [00:00<?, ?batch/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:01<00:00,  1.12s/batch]\n",
      "INFO:lightrag:Updated token count - Input: 10208, Output: 10208, Total: 9119109\n",
      "INFO:lightrag:Processing file: Earnings_Call/Abbott Laboratories Q2 2024 Earnings Call Transcript.txt\n",
      "INFO:lightrag:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/11 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2172, Output: 168, Total: 9121449\n",
      "INFO:lightrag:Processing file: Earnings_Call/Abbott Laboratories Q2 2024 Earnings Call Transcript.txt\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:lightrag:Updated token count - Input: 2367, Output: 251, Total: 9124067\n",
      "INFO:lightrag:Processing file: Earnings_Call/Abbott Laboratories Q2 2024 Earnings Call Transcript.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 8 entities(duplicated), 1 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks:   9%|▉         | 1/11 [00:08<01:23,  8.35s/chunk]"
     ]
    }
   ],
   "source": [
    "recon_file_path = \"/Users/arthurj/Library/CloudStorage/OneDrive-moodys.com/Desktop/LightRag_Data/KG_data/Earnings_Call\"\n",
    "\n",
    "process_files_in_folder(recon_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenk_file_path = \"/Users/arthurj/Library/CloudStorage/OneDrive-moodys.com/Desktop/LightRag_Data/KG_data/10K\"\n",
    "\n",
    "process_files_in_folder(tenk_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenq_file_path = \"/Users/arthurj/Library/CloudStorage/OneDrive-moodys.com/Desktop/LightRag_Data/KG_data/10Q\"\n",
    "\n",
    "process_files_in_folder(tenq_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization of Graph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory/knowledge_graph.html\n",
      "Interactive knowledge graph saved to: /Users/arthurj/Git_Repos/LightRAG/lightrag_expriments/notebooks/SnP_directory/knowledge_graph.html\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from pyvis.network import Network\n",
    "\n",
    "graph_path = os.path.join(WORKING_DIR, 'graph_chunk_entity_relation.graphml')\n",
    "G = nx.read_graphml(graph_path)\n",
    "\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\")\n",
    "net.from_nx(G)\n",
    "output_file = os.path.join(WORKING_DIR, 'knowledge_graph.html')\n",
    "net.show(output_file)\n",
    "\n",
    "print(f\"Interactive knowledge graph saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_file_path = \"/Users/arthurj/Git_Repos/ma-cpg-genai-research/graphrag-playground/lightrag/notebooks/example_queries.json\"\n",
    "output_file = os.path.join(WORKING_DIR, \"../sales_documents/output_response.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(output_text):\n",
    "   with open(output_file, \"a\", encoding=\"utf-8\") as file:\n",
    "       file.write(output_text + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries_from_json(json_path):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        queries_data = json.load(file)\n",
    "    return queries_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_queries_from_json(json_path):\n",
    "    queries_data = load_queries_from_json(json_path)\n",
    "    \n",
    "    for item in queries_data:  \n",
    "        query_number = item[\"example_number\"]\n",
    "        query_text = item[\"query\"]\n",
    "        \n",
    "        for mode in [\"hybrid\"]: #\"naive\", \"local\", \"global\"\n",
    "            response = rag.query(query_text, param=QueryParam(mode=mode))\n",
    "            output_text = (\n",
    "                f\"Example Number: {query_number}, Mode: {mode}\\n\"\n",
    "                f\"Query: {query_text}\\n\"\n",
    "                f\"Response: {response}\\n\"\n",
    "                \"------------------------------------\\n\"\n",
    "            )\n",
    "            write_to_file(output_text)\n",
    "            print(f\"Processed Example Number: {query_number}, Mode: {mode}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_queries_from_json(query_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalutation method "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
